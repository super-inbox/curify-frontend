{
  "aiPlatform": {
    "title": "рдордзреНрдпрдо рдЖрдХрд╛рд░ рдХреА рдХрдВрдкрдирд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП AI рд╕рдлрд▓рддрд╛ рдХрд╛ рдорд╛рд░реНрдЧрджрд░реНрд╢рдХ",
    "subtitle": "рдПрдХ рд╕реНрдХреЗрд▓реЗрдмрд▓ AI рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдХреИрд╕реЗ рдмрдирд╛рдПрдВ рдЬреЛ рдмрдЬрдЯ рдХреЛ рдмрд░реНрдмрд╛рдж рдХрд┐рдП рдмрд┐рдирд╛ рдмрдврд╝реЗ",
    "intro": {
      "p1": "рдЫреЛрдЯреА рд╕реЗ рдордзреНрдпрдо рдЖрдХрд╛рд░ рдХреА рдЯреЗрдХ рдХрдВрдкрдирд┐рдпреЛрдВ рдореЗрдВ, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд▓рд╛рдн рдмрдбрд╝реЗ рдореЙрдбрд▓реЛрдВ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдореЗрдВ рдирд╣реАрдВ рд╣реИ - рдпрд╣ рдПрдХ рдРрд╕реЗ AI рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдХреЗ рдирд┐рд░реНрдорд╛рдг рдореЗрдВ рд╣реИ рдЬреЛ рд╣рд░ рдХрд┐рд╕реА рдХреЛ рдЗрдВрдЯреЗрд▓рд┐рдЬреЗрдВрдЯ рдлреАрдЪрд░реНрд╕ рдмрдирд╛рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдмрдирд╛рддрд╛ рд╣реИред рдпрд╣реА рд╣реИ рдХрд┐ рдЖрдк рдЪреБрд╕реНрддреА рдХреЛ рдкреНрд░рднрд╛рд╡ рдореЗрдВ рдХреИрд╕реЗ рдмрджрд▓рддреЗ рд╣реИрдВред",
      "p2": "рдпрд╣рд╛рдВ рдПрдХ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ, рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рдмреНрд▓реВрдкреНрд░рд┐рдВрдЯ рд╣реИ рдЬрд┐рд╕реЗ рд╣рдордиреЗ рд╡рд┐рддреНрдд, рдХрд╛рдиреВрдиреА, рдЧреНрд░рд╛рд╣рдХ рд╕рд╣рд╛рдпрддрд╛ рдФрд░ рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ рдореЗрдВ AI рдХреЛ рд╢рдХреНрддрд┐ рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рд╣реИ, рдмрд┐рдирд╛ рдкреИрд╕реЗ рдмрд░реНрдмрд╛рдж рдХрд┐рдП рдпрд╛ 50 ML рд╡рд┐рд╢реЗрд╖рдЬреНрдЮреЛрдВ рдХреЛ рдХрд┐рд░рд╛рдП рдкрд░ рд▓рд┐рдПред"
    },
    "imageAlt": "AI рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдбрд╛рдпрдЧреНрд░рд╛рдо",
    "heading": "ЁЯПЧя╕П рдордзреНрдпрдо рдЖрдХрд╛рд░ рдХреА рдХрдВрдкрдирд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП AI рд╕рдлрд▓рддрд╛ рдХрд╛ рдорд╛рд░реНрдЧрджрд░реНрд╢рдХ",
    "mindsetShift": {
      "title": "1. рдорд╛рдЗрдВрдбрд╕реЗрдЯ рд╢рд┐рдлреНрдЯ: рдХреЗрдВрджреНрд░реАрдХреГрдд рдХрд░рдиреЗ рдХреЗ рдмрдЬрд╛рдп рд▓реЛрдХрддрд╛рдВрддреНрд░рд┐рдХ рдмрдирд╛рдПрдВ",
      "content": "рдпрджрд┐ рдЖрдкрдХреА AI рдЯреАрдо рдПрдХ рдмреЛрддрд▓рди рдЧрд░реНрджрди рдмрди рд░рд╣реА рд╣реИ, рддреЛ рдЖрдк рдкрд╣рд▓реЗ рд╣реА рд╣рд╛рд░ рдЪреБрдХреЗ рд╣реИрдВред рдЗрд╕рдХреЗ рдмрдЬрд╛рдп, рдПрдХ рд╕реЗрд▓реНрдл-рд╕рд░реНрд╡ AI рдЗрдиреНрдлреНрд░рд╛рд╕реНрдЯреНрд░рдХреНрдЪрд░ рдмрдирд╛рдПрдВ рдЬреЛ рдЙрддреНрдкрд╛рдж рдЗрдВрдЬреАрдирд┐рдпрд░реЛрдВ рдХреЛ рд╡рд╣ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рд╢рдХреНрдд рдмрдирд╛рдП рдЬреЛ рдЙрдиреНрд╣реЗрдВ рдЪрд╛рд╣рд┐рдПред",
      "goal": "рд▓рдХреНрд╖реНрдп: рдбреЛрдореЗрди рд╡рд┐рд╢реЗрд╖рдЬреНрдЮреЛрдВ (рд╡рд┐рддреНрдд, рдХрд╛рдиреВрдиреА, рд╕рдкреЛрд░реНрдЯ рдЗрдВрдЬреАрдирд┐рдпрд░реНрд╕) рдХреЛ рдиреНрдпреВрдирддрдо ML рдЬреНрдЮрд╛рди рдХреЗ рд╕рд╛рде AI рд╕рдорд╛рдзрд╛рди рдмрдирд╛рдиреЗ рджреЗрдВред",
      "reality": "рд╡рд╛рд╕реНрддрд╡рд┐рдХрддрд╛: AI рдЯреАрдо рд╣рд╛рдИрд╡реЗ рдмрдирд╛рддреА рд╣реИ; рд╡реНрдпрд╡рд╕рд╛рдп рдЯреАрдореЗрдВ рдХрд╛рд░ рдЪрд▓рд╛рддреА рд╣реИрдВред",
      "supportModel": {
        "title": "рд╕рдорд░реНрдерди рдореЙрдбрд▓:",
        "l1": "L1 - рд╕реЗрд▓реНрдл-рд╕рд░реНрд╡рд┐рд╕: рдбреЗрд╡рд▓рдкрд░реНрд╕ рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рдлреАрдЪрд░реНрд╕ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдЯреВрд▓реНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред",
        "l2": "L2 - рдкрд░рд╛рдорд░реНрд╢ рдФрд░ рд╕рд▓рд╛рд╣: AI рдЯреАрдо рдкреНрд░реЙрдореНрдкреНрдЯ рдбрд┐рдЬрд╝рд╛рдЗрди, рдореВрд▓реНрдпрд╛рдВрдХрди рдФрд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдореЗрдВ рдорджрдж рдХрд░рддреА рд╣реИред",
        "l3": "L3 - рд╕рд╣-рд╡рд┐рдХрд╛рд╕: рд╕рдВрдпреБрдХреНрдд рд░реВрдк рд╕реЗ рдЬрдЯрд┐рд▓, рдЙрдЪреНрдЪ-рдкреНрд░рднрд╛рд╡ рд╡рд╛рд▓реЗ MVPs рдмрдирд╛рдПрдВред"
      },
      "conclusion": "рдпрд╣ AI рдХреЛ рдПрдХ рд╢реЛрдз рдкрд░рд┐рдпреЛрдЬрдирд╛ рд╕реЗ рдПрдХ рд╡реНрдпрд╡рд╕рд╛рдп рдЧреБрдгрдХ рдореЗрдВ рдмрджрд▓ рджреЗрддрд╛ рд╣реИред"
    },
    "stack": {
      "title": "2. рд╕реНрдЯреИрдХ: рдЗрд╕реЗ рдкрддрд▓рд╛ рдФрд░ рдУрдкрди рд░рдЦреЗрдВ",
      "intro": "рдЕрддрд┐-рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ рд╡реЗрдЧ рдХреЛ рдорд╛рд░ рджреЗрддреА рд╣реИред рд╣рдордиреЗ рдПрдХ рддреАрди-рдкрд░рдд рд╡рд╛рд▓рд╛ рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдмрдирд╛рдпрд╛ рд╣реИ рдЬреЛ рдЬрдЯрд┐рд▓рддрд╛ рдХреЛ рд╕рд╛рд░ рдХрд░рддрд╛ рд╣реИ рдмрд┐рдирд╛ рдЖрдкрдХреЛ рд▓реЙрдХ рдХрд┐рдПред",
      "gateway": {
        "title": "рдП. рдпреВрдирд┐рдлрд╛рдЗрдб рдореЙрдбрд▓ рдЧреЗрдЯрд╡реЗ",
        "content": "рдХрд┐рд╕реА рдПрдХ рд╡реЗрдВрдбрд░ рд╕реЗ рдмрдВрдзреЗ рди рд░рд╣реЗрдВред рдЕрдиреБрд░реЛрдзреЛрдВ рдХреЛ рд╕рд╣рдЬрддрд╛ рд╕реЗ рд░реВрдЯ рдХрд░реЗрдВ:",
        "points": [
          "рдХрдорд░реНрд╢рд┐рдпрд▓ LLMs (GPT-4, Claude, рдЖрджрд┐) - рд╢реАрд░реНрд╖-рд╕реНрддрд░реАрдп рддрд░реНрдХ рдХреЗ рд▓рд┐рдПред",
          "рдкреНрд░рд╛рдЗрд╡реЗрдЯ рдореЙрдбрд▓ (Llama, Qwen) - рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбреЗрдЯрд╛ рдФрд░ рд▓рд╛рдЧрдд рдирд┐рдпрдВрддреНрд░рдг рдХреЗ рд▓рд┐рдПред",
          "рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рдореЙрдбрд▓ - рдХреЛрдбрд┐рдВрдЧ, рд╡рд┐рдЬрд╝рди рдпрд╛ рдХрдо-рд╡рд┐рд▓рдВрдмрддрд╛ рд╡рд╛рд▓реЗ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдПред"
        ],
        "conclusion": "рдЧреЗрдЯрд╡реЗ рд░реАрдЯреНрд░рд╛рдЗрдЬрд╝, рдлреЙрд▓рдмреИрдХ, рд▓рд╛рдЧрдд рдЯреНрд░реИрдХрд┐рдВрдЧ рдФрд░ рджрд░ рд╕реАрдорд╛рдУрдВ рдХреЛ рд╕рдВрднрд╛рд▓рддрд╛ рд╣реИ - рддрд╛рдХрд┐ рдбреЗрд╡рд▓рдкрд░реНрд╕ рдХреЛ рдмрд╕ `platform.generate()` рдХреЛ рдХреЙрд▓ рдХрд░рдирд╛ рд╣реЛред"
      },
      "knowledge": {
        "title": "рдмреА. рдиреЙрд▓реЗрдЬ-рдПрдЬрд╝-рдЕ-рд╕рд░реНрд╡рд┐рд╕ (RAG рдХреЛ рд╕рд░рд▓ рдмрдирд╛рдпрд╛ рдЧрдпрд╛)",
        "content": "рд░рд┐рдЯреНрд░реАрд╡рд▓-рдСрдЧрдореЗрдВрдЯреЗрдб рдЬрдирд░реЗрд╢рди рд╡рд╣ рдЬрдЧрд╣ рд╣реИ рдЬрд╣рд╛рдВ рдЕрдзрд┐рдХрд╛рдВрд╢ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдореВрд▓реНрдп рдирд┐рд╣рд┐рдд рд╣реИред рд▓реЗрдХрд┐рди рдЗрдВрдЬреАрдирд┐рдпрд░реЛрдВ рдХреЛ рд╡реЗрдХреНрдЯрд░ рдбреЗрдЯрд╛рдмреЗрд╕ рдкреНрд░рдмрдВрдзрд┐рдд рдирд╣реАрдВ рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдПред",
        "solution": "рдПрдХ 'рдбреНрд░реЙрдк-рдПрдВрдб-рдЪреИрдЯ' рдЗрдВрдЯрд░рдлреЗрд╕ рдмрдирд╛рдПрдВ: рдПрдХ рд╡рд┐рдХреА, PDFs, рдпрд╛ рдбреЗрдЯрд╛рдмреЗрд╕ рдХреА рдУрд░ рдЗрд╢рд╛рд░рд╛ рдХрд░реЗрдВ, рдФрд░ рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдЗрдирдЬреЗрд╕реНрдЯ, рдЪрдВрдХ, рдПрдореНрдмреЗрдб рдФрд░ рдЗрдВрдбреЗрдХреНрд╕ рдХрд░реЗрдЧрд╛ред рдЕрдм рд╣рд░ рдЯреАрдо рдХреЗ рдкрд╛рд╕ рдПрдХ рдирд┐рдЬреА, рдЕрджреНрдпрддрд┐рдд рдЬреНрдЮрд╛рди рдЖрдзрд╛рд░ рд╣реИред"
      },
      "orchestration": {
        "title": "рд╕реА. рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди рд▓реЗрдпрд░",
        "content": "рдХреЛрдб-рдлрд░реНрд╕реНрдЯ AI рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рд╣реИ; рд╡рд░реНрдХрдлреНрд▓реЛ-рдлрд░реНрд╕реНрдЯ AI рддреЗрдЬрд╝ рд╣реИред",
        "example": "рд╣рдо рдЪрд░рдгреЛрдВ рдХреЛ рдЬреЛрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП рд▓реЛ-рдХреЛрдб рдЯреВрд▓реНрд╕ (рдЬреИрд╕реЗ Dify, coze, n8n рдЖрджрд┐) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ:",
        "workflow": [
          "рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреНрд╡реЗрд░реА",
          "рдбреЙрдХреНрдпреБрдореЗрдВрдЯреНрд╕ рд░рд┐рдЯреНрд░реАрд╡ рдХрд░реЗрдВ",
          "рдЯреВрд▓ рдХреЛ рдХреЙрд▓ рдХрд░реЗрдВ (API, SQL)",
          "рддрд░реНрдХ рдХрд░реЗрдВ",
          "рдЖрдЙрдЯрдкреБрдЯ"
        ],
        "conclusion": "рдпрд╣ рдЙрддреНрдкрд╛рдж рдЯреАрдореЛрдВ рдХреЛ рд╣рдлреНрддреЛрдВ рдореЗрдВ рдирд╣реАрдВ, рдмрд▓реНрдХрд┐ рдШрдВрдЯреЛрдВ рдореЗрдВ рдПрдЬреЗрдВрдЯреЛрдВ рдХрд╛ рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдк рдмрдирд╛рдиреЗ рджреЗрддрд╛ рд╣реИред"
      }
    },
    "fineTuning": {
      "title": "3. рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рдХреЛ рдЫреЛрдбрд╝реЗрдВ (рдЕрдзрд┐рдХрд╛рдВрд╢ рд╕рдордп)",
      "content": "рдпрд╣рд╛рдВ рд░рд╣рд╕реНрдп рд╣реИ: **рдЖрдкрдХреЛ рд╢рд╛рдпрдж LLM рдХреЛ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдирд╣реАрдВ рд╣реИред**",
      "strategies": [
        "рдмреЗрд╣рддрд░ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕: рд╡реНрдпрд╡рд╕реНрдерд┐рдд рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рдЯреНрд╡реАрдХрд┐рдВрдЧ рдХреЛ рд╣рд░рд╛ рджреЗрддреА рд╣реИред",
        "рдЙрдЪреНрдЪ-рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓рд╛ RAG: рд╕рд╛рдл, рд╕рдВрд░рдЪрд┐рдд рдЬреНрдЮрд╛рди рдПрдХ рдЪрддреБрд░ рдореЙрдбрд▓ рдХреЛ рд╣рд░рд╛ рджреЗрддрд╛ рд╣реИред",
        "рдорд▓реНрдЯреА-рдореЙрдбрд▓ рдлреНрдпреВрдЬрди: рддрд░реНрдХ рдХреЗ рд▓рд┐рдП GPT-4, рдирд┐рд╖реНрдХрд░реНрд╖рдг рдХреЗ рд▓рд┐рдП рдПрдХ рд╕реНрдерд╛рдиреАрдп рдореЙрдбрд▓, рд░рдЪрдирд╛рддреНрдордХ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП Claude рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред",
        "рдиреНрдпрд╛рдпрд╛рдзреАрд╢ рдХреЗ рд░реВрдк рдореЗрдВ LLM: рд╕рд╕реНрддреЗ рдореЙрдбрд▓ рдХреЗ рдЖрдЙрдЯрдкреБрдЯ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдордЬрдмреВрдд рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред"
      ],
      "conclusion": "рд╣рдо рдХреЗрд╡рд▓ рд╕рдВрдХреАрд░реНрдг, рдЙрдЪреНрдЪ-рдорд╛рддреНрд░рд╛ рд╡рд╛рд▓реЗ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЫреЛрдЯреЗ рдореЙрдбрд▓ рдХреЛ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд░рддреЗ рд╣реИрдВ, рдЙрдЪреНрдЪ-рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓рд╛ рдбреЛрдореЗрди рдбреЗрдЯрд╛ рдХреЛ рдЗрдХрдЯреНрдард╛ рдХрд░рдиреЗ рдФрд░ рд╕рд╛рдл рдХрд░рдиреЗ рдХреА рд▓рдВрдмреА рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреЗ рдмрд╛рджред рдмрд╛рдХреА рд╕рдм рдХреБрдЫ 'рдЯреНрд░реЗрдирд┐рдВрдЧ рдкрд░ рдЗрдВрдЬреАрдирд┐рдпрд░рд┐рдВрдЧ' рд╣реИред"
    },
    "essentialWork": {
      "title": "5. рдЕрдЧреЛрдЪрд░, рд▓реЗрдХрд┐рди рдЖрд╡рд╢реНрдпрдХ рдХрд╛рд░реНрдп",
      "content": "SOTA рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдХреЗрд╡рд▓ рдореЙрдбрд▓реЛрдВ рдкрд░ рдирд╣реАрдВ рдмрдиреЗ рд╣реЛрддреЗ рд╣реИрдВред рд╡реЗ рдЙрдмрд╛рдК, рдХрдард┐рди рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЛ рд╣рд▓ рдХрд░рдиреЗ рдкрд░ рдмрдиреЗ рд╣реЛрддреЗ рд╣реИрдВ:",
      "points": [
        {
          "title": "рдбреЗрдЯрд╛ рдлреНрд▓рд╛рдИрд╡реНрд╣реАрд▓",
          "content": "рдпрджрд┐ рдЖрдк рдЙрддреНрдкрд╛рджрди рдЙрдкрдпреЛрдЧ рд╕реЗ рд▓реЙрдЧ рдФрд░ рд╕реАрдЦ рдирд╣реАрдВ рд╕рдХрддреЗ, рддреЛ рдЖрдкрдХреЗ рдореЙрдбрд▓ рд╕реБрдзрд░реЗрдВрдЧреЗ рдирд╣реАрдВред рд╕реБрд░рдХреНрд╖рд╛ рдХреЗ рд╕рд╛рде рдЬрд▓реНрджреА рдХрд╛рдо рдХрд░реЗрдВ рддрд╛рдХрд┐ рдЕрдиреБрдкрд╛рд▓рди, рдЕрдирд╛рдорд┐рдд рдбреЗрдЯрд╛ рдкрд╛рдЗрдкрд▓рд╛рдЗрдиреНрд╕ рдХреЛ рд╕рдХреНрд╖рдо рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред"
        },
        {
          "title": "рдореВрд▓реНрдпрд╛рдВрдХрди, рднрд╛рд╡рдирд╛рдПрдВ рдирд╣реАрдВ",
          "content": "рд╡реНрдпрд╡рд╕рд╛рдп рдорд╛рд▓рд┐рдХреЛрдВ рд╕реЗ 'рдЧреЛрд▓реНрдбрди рдбреЗрдЯрд╛рд╕реЗрдЯреНрд╕' рдХреА рдорд╛рдВрдЧ рдХрд░реЗрдВ - рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдкреНрд░рд╢реНрди-рдЙрддреНрддрд░ рдЬреЛрдбрд╝реЗ - рддрд╛рдХрд┐ рдЖрдк рд╕рдЯреАрдХрддрд╛/рд░рд┐рдХреЙрд▓ рдХреЛ рдорд╛рдк рд╕рдХреЗрдВ, рди рдХрд┐ рдХреЗрд╡рд▓ 'рдЕрдЪреНрдЫрд╛ рд▓рдЧ рд░рд╣рд╛ рд╣реИ'ред"
        },
        {
          "title": "рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╕рдВрд╕рд╛рдзрди",
          "content": "рдЗрдирдлреЗрд░реЗрдВрд╕ рд╕реАрдкреАрдпреВ рдЪрд▓рд╛рдиреЗ рдЬреИрд╕рд╛ рдирд╣реАрдВ рд╣реИред OOM рдХреНрд░реИрд╢ рдХреЛ рд░реЛрдХрдиреЗ рдФрд░ рдЙрдкрдпреЛрдЧ рдХреЛ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЖрдкрдХреЛ рд╕рдорд░реНрдкрд┐рдд рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИред"
        }
      ]
    },
    "conclusion": {
      "title": "рдирд┐рд╖реНрдХрд░реНрд╖",
      "content": "рдордзреНрдпрдо рдЖрдХрд╛рд░ рдХреА рдЯреЗрдХ рдХрдВрдкрдирд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП, AI рдореЗрдВ рдЬреАрддрдиреЗ рдХрд╛ рдорддрд▓рдм рдмреЗрд╣рддрд░ LLM рдмрдирд╛рдирд╛ рдирд╣реАрдВ рд╣реИред рдЗрд╕рдХрд╛ рдорддрд▓рдм рд╣реИ рдПрдХ рдРрд╕рд╛ рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдмрдирд╛рдирд╛ рдЬреЛ AI рдХреЛ рдПрдХ рджреЛрд╣рд░рд╛рдпрд╛ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛, рд╕реНрдХреЗрд▓реЗрдмрд▓ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдореЗрдВ рдмрджрд▓ рджреЗред",
      "finalThoughts": "рдЗрдиреНрдлреНрд░рд╛рд╕реНрдЯреНрд░рдХреНрдЪрд░ рд╕реЗ рд╢реБрд░реБрдЖрдд рдХрд░реЗрдВ, рдбреЗрдЯрд╛ рдХреЛ рд╕реБрд░рдХреНрд╖рд┐рдд рдХрд░реЗрдВ, рдФрд░ рдЕрдкрдиреА рдЯреАрдореЛрдВ рдХреЛ рдирд┐рд░реНрдорд╛рдг рдХрд░рдиреЗ рджреЗрдВред рднрд╡рд┐рд╖реНрдп рд╕рднреА рдкрд░ рд░рд╛рдЬ рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ рдПрдХ рдореЙрдбрд▓ рдирд╣реАрдВ рд╣реИ - рдпрд╣ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рдПрдЬреЗрдВрдЯреЛрдВ рдХрд╛ рдПрдХ рдмреЗрдбрд╝рд╛ рд╣реИ, рдЬрд┐рдирдореЗрдВ рд╕реЗ рдкреНрд░рддреНрдпреЗрдХ рдПрдХ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рд╕рдорд╕реНрдпрд╛ рдХреЛ рд╣рд▓ рдХрд░ рд░рд╣рд╛ рд╣реИ, рд╕рднреА рдПрдХ рдРрд╕реЗ рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рдд рд╣реИрдВ рдЬреЛ рдЗрд╕реЗ рд╕рд░рд▓ рдмрдирд╛рддрд╛ рд╣реИред",
      "callToAction": "рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рд╣реИрдВ? рдЗрд╕реЗ рд╕рд░рд▓ рд░рдЦреЗрдВ, рдЗрд╕реЗ рдЦреБрд▓рд╛ рд░рдЦреЗрдВ, рдФрд░ рджреВрд╕рд░реЛрдВ рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рдкрд░ рдзреНрдпрд╛рди рджреЗрдВред"
    }
  },
  "home": {
    "metadata": {
      "title": "Curify | AI рдХреЗ рд╕рд╛рде рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдХреЛ рд╕рд╢рдХреНрдд рдмрдирд╛рдПрдВ",
      "description": "Curify рдПрдХ AI-рдореВрд▓ рдордВрдЪ рд╣реИ рдЬреЛ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ, рд╢рд┐рдХреНрд╖рдХреЛрдВ рдФрд░ рдореАрдбрд┐рдпрд╛ рдЯреАрдореЛрдВ рдХреЛ рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рд╡реАрдбрд┐рдпреЛ, рдордВрдЧрд╛ рдФрд░ рдкреНрд░рд╕реНрддреБрддрд┐рдпреЛрдВ рдХрд╛ рдирд┐рд░реНрдорд╛рдг рдФрд░ рд╕реНрдерд╛рдиреАрдпрдХрд░рдг рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реИред"
    },
    "hero": {
      "title": "AI рдХреЗ рд╕рд╛рде рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдХреЛ рд╕рд╢рдХреНрдд рдмрдирд╛рдПрдВ",
      "description": "Curify Studio рдПрдХ AI-рдореВрд▓ рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдордВрдЪ рдмрдирд╛ рд░рд╣рд╛ рд╣реИ рдЬреЛ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдФрд░ рд╕рдВрдЧрдардиреЛрдВ рдХреЛ рднрд╛рд╖рд╛ рдФрд░ рдкреНрд░рд╛рд░реВрдк рдмрд╛рдзрд╛рдУрдВ рдХреЛ рджреВрд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рд╢рдХреНрдд рдмрдирд╛рддрд╛ рд╣реИред рд╣рдо рд╡реИрд╢реНрд╡рд┐рдХ рджрд░реНрд╢рдХреЛрдВ рдХреЗ рд▓рд┐рдП рд╕рд╛рдордЧреНрд░реА рдХреЛ рд╕реНрдХреЗрд▓ рдХрд░рдиреЗ рдХреА рдЪреБрдиреМрддреА рдХреЛ рд╣рд▓ рдХрд░рддреЗ рд╣реИрдВ, рдкреНрд░рд╛рдорд╛рдгрд┐рдХ рдЕрдиреБрд╡рд╛рджреЛрдВ рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдЯреЛрди, рд╢реИрд▓реА рдФрд░ рднрд╛рд╡рдирд╛рддреНрдордХ рдЧрд╣рд░рд╛рдИ рдХреЛ рд╕рдВрд░рдХреНрд╖рд┐рдд рдХрд░рддреЗ рд╣реИрдВред рдореАрдбрд┐рдпрд╛, рд╢рд┐рдХреНрд╖рд╛ рдФрд░ рдордиреЛрд░рдВрдЬрди рдХреЗ рдЪреМрд░рд╛рд╣реЗ рдкрд░ рдХрд╛рдо рдХрд░рддреЗ рд╣реБрдП, рд╣рдо рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреЛ рддреЗрдЬреА рд╕реЗ рд╡реИрд╢реНрд╡реАрдХрд░рдг рд╡рд╛рд▓реЗ рдЙрджреНрдпреЛрдЧ рдореЗрдВ рд╕рд╛рдордЧреНрд░реА рдХреЛ рдореВрд▓ рд░реВрдк рд╕реЗ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдХрд░рдг рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред"
    }
  },
  "coreFeatures": {
    "oneShot": {
      "title": "рд╡рди-рд╢реЙрдЯ рдЕрдиреБрд╡рд╛рдж",
      "desc": "рдПрдХ рд╣реА рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдореЗрдВ рд╡реЙрдпрд╕-рдУрд╡рд░, рдЙрдкрд╢реАрд░реНрд╖рдХ рдФрд░ рд▓рд┐рдк рд╕рд┐рдВрдХ рдХреЗ рд╕рд╛рде рдкреВрд░реНрдг рд╡реАрдбрд┐рдпреЛ рдЕрдиреБрд╡рд╛рджред"
    },
    "toneColor": {
      "title": "рдЯреЛрди рд░рдВрдЧ рд╕рдВрд░рдХреНрд╖рдг",
      "desc": "рдореВрд▓ рд╡рдХреНрддрд╛ рдХреА рдЕрдиреВрдареА рдЖрд╡рд╛рдЬ рд╡рд┐рд╢реЗрд╖рддрд╛рдУрдВ рдФрд░ рддрд╛рдирд╡рд╛рд▓рд╛ рдЧреБрдгреЛрдВ рдХреЛ рдмрдирд╛рдП рд░рдЦрддрд╛ рд╣реИред"
    },
    "emotional": {
      "title": "рднрд╛рд╡рдирд╛рддреНрдордХ рднрд╛рд╖рдг",
      "desc": "AI рднрд╛рд╡рдирд╛рддреНрдордХ рдмрд╛рд░реАрдХрд┐рдпреЛрдВ рдХреЛ рдкреБрди: рдкреЗрд╢ рдХрд░рддрд╛ рд╣реИ, рднрд╛рд╖рд╛рдУрдВ рдореЗрдВ рдкреНрд░рд╛рдорд╛рдгрд┐рдХ рдЕрднрд┐рд╡реНрдпрдХреНрддрд┐ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИред"
    },
    "lipSync": {
      "title": "рд▓рд┐рдк рд╕рд┐рдВрдХ рддрдХрдиреАрдХ",
      "desc": "рдЙрдиреНрдирдд рд▓рд┐рдк рд╕рд┐рдВрдХреНрд░реЛрдирд╛рдЗрдЬрд╝реЗрд╢рди рдЬреЛ рдЕрдиреБрд╡рд╛рджрд┐рдд рдСрдбрд┐рдпреЛ рдХреЗ рд╕рд╛рде рдореБрдВрд╣ рдХреА рдЧрддрд┐рд╡рд┐рдзрд┐рдпреЛрдВ рд╕реЗ рдкреВрд░реА рддрд░рд╣ рдореЗрд▓ рдЦрд╛рддрд╛ рд╣реИред"
    },
    "subtitle": {
      "title": "рдЙрдкрд╢реАрд░реНрд╖рдХ рдХреИрдкреНрд╢рдирд░",
      "desc": "рд╕рдЯреАрдХ рд╕рдордп рдФрд░ рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдкреНрд░рд╡рд╛рд╣ рдХреЗ рд╕рд╛рде рдмреБрджреНрдзрд┐рдорд╛рди рдЙрдкрд╢реАрд░реНрд╖рдХ рдирд┐рд░реНрдорд╛рдгред"
    },
    "languages": {
      "title": "170+ рднрд╛рд╖рд╛рдПрдБ",
      "desc": "рджреЗрд╢реА-рд╕реНрддрд░ рдХреА рд╕рдЯреАрдХрддрд╛ рдХреЗ рд╕рд╛рде 170 рд╕реЗ рдЕрдзрд┐рдХ рднрд╛рд╖рд╛рдУрдВ рдореЗрдВ рдЕрдкрдиреА рд╕рд╛рдордЧреНрд░реА рдХрд╛ рдЕрдиреБрд╡рд╛рдж рдХрд░реЗрдВред"
    }
  },
  "upcoming": {
    "title": "рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ",
    "subtitle": "рдЕрдЧрд▓реА рдкреАрдврд╝реА рдХреА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдВ рд╡рд┐рдХрд╛рд╕ рдореЗрдВ",
    "styleTransfer": {
      "title": "рд╢реИрд▓реА рд╕реНрдерд╛рдирд╛рдВрддрд░рдг",
      "desc": "AI-рд╕рдВрдЪрд╛рд▓рд┐рдд рджреГрд╢реНрдп рдкрд░рд┐рд╡рд░реНрддрди рдХреЗ рд╕рд╛рде рдЕрдкрдиреЗ рд╡реАрдбрд┐рдпреЛ рдкрд░ рд╕рд┐рдиреЗрдорд╛рдИ рдпрд╛ рдмреНрд░рд╛рдВрдб-рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╢реИрд▓рд┐рдпреЛрдВ рдХреЛ рд▓рд╛рдЧреВ рдХрд░реЗрдВред",
      "icon": "ЁЯОи",
      "status": "Q3 2025 рдореЗрдВ рдЖ рд░рд╣рд╛ рд╣реИ",
      "transcript": "рдпрд╣ рдбреЗрдореЛ AI-рд╕рдВрдЪрд╛рд▓рд┐рдд рджреГрд╢реНрдп рд╢реИрд▓реА рд╣рд╕реНрддрд╛рдВрддрд░рдг рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рд▓рд╛рдЗрд╡-рдПрдХреНрд╢рди рдбреНрд░рд╛рдорд╛ рдХреНрд▓рд┐рдк рдХреЛ рдПрдХ рд╕рдирдХреА рдШрд┐рдмрд▓реА-рд╢реИрд▓реА рдХреЗ рдПрдиреАрдореЗрд╢рди рдореЗрдВ рдмрджрд▓ рджреЗрддрд╛ рд╣реИред"
    },
    "mangaTranslation": {
      "title": "рдордВрдЧрд╛ рдЕрдиреБрд╡рд╛рдж",
      "desc": "рдкрд╛рда рдкрд╣рдЪрд╛рди, рдмреБрд▓рдмреБрд▓рд╛ рд╕рдВрдкрд╛рджрди рдФрд░ рд╕рд╛рдВрд╕реНрдХреГрддрд┐рдХ рдЕрдиреБрдХреВрд▓рди рдХреЗ рд╕рд╛рде рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдордВрдЧрд╛ рдФрд░ рд╣рд╛рд╕реНрдп рдЕрдиреБрд╡рд╛рджред",
      "icon": "ЁЯУЪ",
      "status": "Q3 2025 рдореЗрдВ рдЖ рд░рд╣рд╛ рд╣реИ",
      "transcript": "рдпрд╣ рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдк рднрд╛рд╖рдг рдмреБрд▓рдмреБрд▓рд╛ рдкрд╣рдЪрд╛рди рдФрд░ рджреНрд╡рд┐рднрд╛рд╖реА рдЗрди-рдкреНрд▓реЗрд╕ рд╕рдВрдкрд╛рджрди рд╕рд╣рд┐рдд рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдордВрдЧрд╛ рдЕрдиреБрд╡рд╛рдж рдХреЛ рдкреНрд░рджрд░реНрд╢рд┐рдд рдХрд░рддрд╛ рд╣реИред"
    },
    "templatedVideo": {
      "title": "рдЯреЗрдореНрдкреНрд▓реЗрдЯреЗрдб рд╡реАрдбрд┐рдпреЛ рдирд┐рд░реНрдорд╛рдг",
      "desc": "AI-рдЬрдирд┐рдд рд╕рд╛рдордЧреНрд░реА рдФрд░ рдХрд╕реНрдЯрдо рдмреНрд░рд╛рдВрдбрд┐рдВрдЧ рдХреЗ рд╕рд╛рде рдЯреЗрдореНрдкреНрд▓реЗрдЯ рд╕реЗ рдкреЗрд╢реЗрд╡рд░ рд╡реАрдбрд┐рдпреЛ рдмрдирд╛рдПрдВред",
      "icon": "ЁЯОм",
      "status": "Q4 2025 рдореЗрдВ рдЖ рд░рд╣рд╛ рд╣реИ",
      "transcript": "рдпрд╣ рдбреЗрдореЛ рдПрдХ рд╕реНрдХреНрд░рд┐рдкреНрдЯ-рдЯреВ-рд╡реАрдбрд┐рдпреЛ рдкрд╛рдЗрдкрд▓рд╛рдЗрди рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдЬреЛ рд╕реНрдЯреЛрд░реАрдмреЛрд░реНрдб рдХреА рдпреЛрдЬрдирд╛ рдмрдирд╛рдХрд░ рдФрд░ рд╡рд┐рдЬреБрдЕрд▓реНрд╕ рдХреЛ рдЕрд╕реЗрдВрдмрд▓ рдХрд░рдХреЗ рд╢реБрд░реБрдЖрддреА рдЕрдореЗрд░рд┐рдХреА рдЗрддрд┐рд╣рд╛рд╕ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдПрдХ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рджреГрд╢реНрдп рдмрдирд╛рддрд╛ рд╣реИред"
    },
    "statusQ3": "Q3 2025 рдореЗрдВ рдЖ рд░рд╣рд╛ рд╣реИ",
    "statusQ4": "Q4 2025 рдореЗрдВ рдЖ рд░рд╣рд╛ рд╣реИ"
  },
  "export": {
    "title": "рдирд┐рд░реНрдпрд╛рдд",
    "export": "рдирд┐рд░реНрдпрд╛рдд",
    "downloading": "рдбрд╛рдЙрдирд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ..."
  },
  "delete": {
    "title": "рджреЛрд╣рд░реА рдкреБрд╖реНрдЯрд┐",
    "message": "рдХреНрдпрд╛ рдЖрдк рд╡рд╛рдХрдИ рдЗрд╕ рдкрд░рд┐рдпреЛрдЬрдирд╛ рдХреЛ рд╣рдЯрд╛рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ",
    "warning": "рдпрд╣ рдХрд╛рд░реНрд░рд╡рд╛рдИ рдкреВрд░реНрд╡рд╡рдд рдирд╣реАрдВ рдХреА рдЬрд╛ рд╕рдХрддреАред",
    "cancel": "рд░рджреНрдж рдХрд░реЗрдВ",
    "delete": "рд╣рдЯрд╛рдПрдВ",
    "deleting": "рд╣рдЯрд╛рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ..."
  },
  "userMenu": {
    "topUpCredits": "рдХреНрд░реЗрдбрд┐рдЯ рдЯреЙрдк рдЕрдк рдХрд░реЗрдВ",
    "remaining": "рд╢реЗрд╖",
    "planRemaining": "рдпреЛрдЬрдирд╛ рд╢реЗрд╖",
    "validUntil": "рддрдХ рд╡реИрдз",
    "creditsHistory": "рдХреНрд░реЗрдбрд┐рдЯ рдЗрддрд┐рд╣рд╛рд╕",
    "subscribePlan": "рдпреЛрдЬрдирд╛ рдХреА рд╕рджрд╕реНрдпрддрд╛ рд▓реЗрдВ",
    "supportTicket": "рд╕рдорд░реНрдерди рдЯрд┐рдХрдЯ",
    "signOut": "рд╕рд╛рдЗрди рдЖрдЙрдЯ"
  },
  "technology": {
    "multimodal": {
      "title": "рдорд▓реНрдЯреА-рдореЛрдбрд▓ рдорд╛рдиреНрдпрддрд╛",
      "desc": "рд╣рдо рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдФрд░ рдордЬрдмреВрдд рдкреНрд░рддрд┐рд▓реЗрдЦрди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рднрд╛рд╖рдг рдФрд░ рдЙрдкрд╢реАрд░реНрд╖рдХ рд╕рдВрдХреЗрддреЛрдВ рдХреЛ рдЬреЛрдбрд╝рддреЗ рд╣реИрдВред рдпрд╣ рджреЛрд╣рд░реЗ рдЪреИрдирд▓ рдХреА рдорд╛рдиреНрдпрддрд╛ рддреНрд░реБрдЯрд┐рдпреЛрдВ рдХреЛ рдХрдо рдХрд░рддреА рд╣реИ рдФрд░ рдореВрд▓ рд╕рд╛рдордЧреНрд░реА рдХреЗ рд╕рд╛рде рдмреЗрд╣рддрд░ рд╕рдВрд░реЗрдЦрдг рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддреА рд╣реИ, рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рд╢реЛрд░ рдпрд╛ рдЬрдЯрд┐рд▓ рдСрдбрд┐рдпреЛ рджреГрд╢реНрдпреЛрдВ рдореЗрдВред"
    },
    "emotional": {
      "title": "рднрд╛рд╡рдирд╛рддреНрдордХ рднрд╛рд╖рдг",
      "desc": "рд╣рдорд╛рд░реЗ рд╡реЙрдпрд╕ рд╕рд┐рдВрдереЗрд╕рд┐рд╕ рдореЙрдбрд▓ рдЕрднрд┐рд╡реНрдпрдВрдЬрдХ, рднрд╛рд╡рдирд╛рддреНрдордХ рд░реВрдк рд╕реЗ рд╕рдореГрджреНрдз рднрд╛рд╖рдг рдЙрддреНрдкрдиреНрди рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдХрд╣рд╛рдиреА рдХрд╣рдиреЗ рдФрд░ рджрд░реНрд╢рдХ рдЬреБрдбрд╝рд╛рд╡ рдХреЛ рдмрдврд╝рд╛рддреЗ рд╣реИрдВред рдЯреЛрди, рд▓рдп рдФрд░ рдмрд╛рд░реАрдХрд┐рдпреЛрдВ рдХреЛ рдкрдХрдбрд╝рдХрд░, рд╣рдо AI рдЖрд╡рд╛рдЬреЛрдВ рдХреЛ рдЕрдзрд┐рдХ рдорд╛рдирд╡реАрдп рдФрд░ рднрд░реЛрд╕реЗрдордВрдж рдмрдирд╛рддреЗ рд╣реИрдВред"
    },
    "lengthaware": {
      "title": "рд▓рдВрдмрд╛рдИ-рдЬрд╛рдЧрд░реВрдХ рдЕрдиреБрд╡рд╛рдж рдФрд░ рдЕрдиреБрдХреВрд▓рди",
      "desc": "рд╣рдо рдЕрдиреБрд╡рд╛рджреЛрдВ рдХреЛ рди рдХреЗрд╡рд▓ рд╕рдЯреАрдХрддрд╛ рдХреЗ рд▓рд┐рдП, рдмрд▓реНрдХрд┐ рд╕рдордп рдФрд░ рдкреЗрд╕рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рднреА рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░рддреЗ рд╣реИрдВ - рдЬреЛ рд╡реАрдбрд┐рдпреЛ рдФрд░ рд╡реЙрдпрд╕ рд╕рдВрд░реЗрдЦрдг рдХреЗ рд▓рд┐рдП рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рд╡рд┐рднрд┐рдиреНрди рд╕рд╛рдордЧреНрд░реА рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдпрд╛ рджрд░реНрд╢рдХреЛрдВ рдХреА рдкреНрд░рд╛рдердорд┐рдХрддрд╛рдУрдВ рдХреЗ рдЕрдиреБрд░реВрдк рдЯреЛрди, рд▓рдВрдмрд╛рдИ рдФрд░ рд╡рд╛рдХреНрдпрд╛рдВрд╢ рдХреЛ рдФрд░ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
    },
    "controlled": {
      "title": "рдирд┐рдпрдВрддреНрд░рд┐рдд рд╡реАрдбрд┐рдпреЛ рдирд┐рд░реНрдорд╛рдг",
      "desc": "рд╣рдо рдирд┐рдпрдВрддреНрд░рдгреАрдп рджреГрд╢реНрдп рддрддреНрд╡реЛрдВ рдФрд░ рд╕рдВрдХреНрд░рдордгреЛрдВ рдХреЗ рд╕рд╛рде рд╕рдВрд░рдЪрд┐рдд, рдЯреЗрдореНрдкрд▓реЗрдЯ-рд╕рдВрдЪрд╛рд▓рд┐рдд рд╡реАрдбрд┐рдпреЛ рдирд┐рд░реНрдорд╛рдг рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВред рдпрд╣ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреЛ рд░рдЪрдирд╛рддреНрдордХ рд╕реНрд╡рддрдВрддреНрд░рддрд╛ рдФрд░ рдЙрддреНрдкрд╛рджрди рд╕реНрдерд┐рд░рддрд╛ рджреЛрдиреЛрдВ рджреЗрддрд╛ рд╣реИ, рдореИрдиреНрдпреБрдЕрд▓ рдкреНрд░рдпрд╛рд╕ рдХреЛ рдХрдо рдХрд░рддрд╛ рд╣реИ рдЬрдмрдХрд┐ рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓рд╛ рдЖрдЙрдЯрдкреБрдЯ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИред"
    }
  },
  "tools": {
    "video_dubbing": {
      "title": "рд╡реАрдбрд┐рдпреЛ рдбрдмрд┐рдВрдЧ",
      "desc": "рд╕рдЯреАрдХ рд╕реНрдерд╛рдиреАрдпрдХрд░рдг рдФрд░ рд╡реЙрдпрд╕ рд╕рд┐рдВрдХ рдХреЗ рд╕рд╛рде рдЕрдкрдиреЗ рд╡реАрдбрд┐рдпреЛ рдХрд╛ рдХрд┐рд╕реА рднреА рднрд╛рд╖рд╛ рдореЗрдВ рдЕрдиреБрд╡рд╛рдж рдХрд░реЗрдВ"
    },
    "subtitle_captioner": {
      "title": "рдЙрдкрд╢реАрд░реНрд╖рдХ рдХреИрдкреНрд╢рдирд░",
      "desc": "рд╕реНрдкрд╖реНрдЯрддрд╛ рдФрд░ рдкрд╣реБрдВрдЪ рдмрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдмрд╣реБрднрд╛рд╖реА рдЙрдкрд╢реАрд░реНрд╖рдХ рдСрдЯреЛ-рдЬреЗрдирд░реЗрдЯ рдХрд░реЗрдВ"
    },
    "lip_syncing": {
      "title": "рд▓рд┐рдк рд╕рд┐рдВрдХрд┐рдВрдЧ",
      "desc": "AI-рд╕рдВрдЪрд╛рд▓рд┐рдд рд▓рд┐рдк рд╕рд┐рдВрдХ рдХреЗ рд╕рд╛рде рднрд╛рд╖рдг рд╕реЗ рд╣реЛрдВрдареЛрдВ рдХрд╛ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рдорд┐рд▓рд╛рди рдХрд░реЗрдВ"
    },
    "style_transfer": {
      "title": "рд╢реИрд▓реА рд╕реНрдерд╛рдирд╛рдВрддрд░рдг",
      "desc": "рдЕрдкрдиреЗ рд╡реАрдбрд┐рдпреЛ рдХреЛ рдкрд┐рдХреНрд╕рд░, рдШрд┐рдмрд▓реА, рдпрд╛ рдЕрдиреНрдп рдХрд▓рд╛рддреНрдордХ рд╢реИрд▓рд┐рдпреЛрдВ рдореЗрдВ рдмрджрд▓реЗрдВ тАФ рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ"
    },
    "coming_soon": "рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ",
    "create": "рдмрдирд╛рдПрдВ"
  },
  "bilingual": {
    "metadata": {
      "title": "рдирд┐рдГрд╢реБрд▓реНрдХ рджреНрд╡рд┐рднрд╛рд╖реА рдЙрдкрд╢реАрд░реНрд╖рдХ рдЬреЗрдирд░реЗрдЯрд░ | Curify AI",
      "description": "Curify рдХреЗ рдирд┐рдГрд╢реБрд▓реНрдХ AI-рд╕рдВрдЪрд╛рд▓рд┐рдд рдЯреВрд▓ рдХреЗ рд╕рд╛рде рдЕрдкрдиреЗ рд╡реАрдбрд┐рдпреЛ рдХреЗ рд▓рд┐рдП рджреНрд╡рд┐рднрд╛рд╖реА рдЙрдкрд╢реАрд░реНрд╖рдХ рдмрдирд╛рдПрдВред YouTube, TikTok, рд╢рд┐рдХреНрд╖рд╛ рдФрд░ рд╡реИрд╢реНрд╡рд┐рдХ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреЗ рд▓рд┐рдП рдмрд┐рд▓реНрдХреБрд▓ рд╕рд╣реАред"
    },
    "title": "рджреНрд╡рд┐рднрд╛рд╖реА рдЙрдкрд╢реАрд░реНрд╖рдХ рдЖрд╕рд╛рди рдмрдирд╛рдП рдЧрдП",
    "intro": "Curify рдХреЗ AI рдЙрдкрд╢реАрд░реНрд╖рдХ рдЗрдВрдЬрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рджреЛ рднрд╛рд╖рд╛рдУрдВ рдореЗрдВ рдЙрдкрд╢реАрд░реНрд╖рдХ рдЙрддреНрдкрдиреНрди рдХрд░реЗрдВред рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ, рд╢рд┐рдХреНрд╖рдХреЛрдВ рдФрд░ рд╡реИрд╢реНрд╡рд┐рдХ рд╡реНрдпрд╡рд╕рд╛рдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢ред",
    "example": "рдЙрджрд╛рд╣рд░рдг: рдЬреЗрдирд╕реЗрди рд╣реБрдЖрдВрдЧ AI рд░рдгрдиреАрддрд┐ рдХреА рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХрд░рддреЗ рд╣реБрдП тАФ рдЕрдВрдЧреНрд░реЗрдЬреА + рдЪреАрдиреА рдЙрдкрд╢реАрд░реНрд╖рдХ рдСрдЯреЛ-рдЬреЗрдирд░реЗрдЯ рдХрд┐рдП рдЧрдПред",
    "cta": "рдЗрд╕реЗ рдореБрдлреНрдд рдореЗрдВ рдЖрдЬрд╝рдорд╛рдПрдВ",
    "why": {
      "title": "рджреНрд╡рд┐рднрд╛рд╖реА рдЙрдкрд╢реАрд░реНрд╖рдХ рдХреЗ рд▓рд┐рдП Curify рдХреНрдпреЛрдВ рдЪреБрдиреЗрдВ?",
      "point1": "рд╕рдЯреАрдХ рдЕрдиреБрд╡рд╛рдж рдХреЗ рд╕рд╛рде 170 рд╕реЗ рдЕрдзрд┐рдХ рднрд╛рд╖рд╛рдУрдВ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИред",
      "point2": "рднрд╛рд╡рдирд╛рддреНрдордХ рдЯреЛрди рдФрд░ рд╕рдордп рдХреЛ рд╕рдВрд░рдХреНрд╖рд┐рдд рдХрд░рддрд╛ рд╣реИред",
      "point3": "YouTube, TikTok рдФрд░ рд╢реИрдХреНрд╖рд┐рдХ рд╡реАрдбрд┐рдпреЛ рдХреЗ рд▓рд┐рдП рдмрд┐рд▓реНрдХреБрд▓ рд╕рд╣реАред",
      "point4": "рдкреНрд░рдХрд╛рд╢рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдЙрдкрд╢реАрд░реНрд╖рдХ рдлрд╝рд╛рдЗрд▓реЗрдВ рдпрд╛ рдПрдореНрдмреЗрдбреЗрдб рд╡реАрдбрд┐рдпреЛ рдирд┐рд░реНрдпрд╛рдд рдХрд░реЗрдВред"
    },
    "faq": {
      "title": "рдЕрдХреНрд╕рд░ рдкреВрдЫреЗ рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдкреНрд░рд╢реНрди",
      "q1": "рдХреНрдпрд╛ рдпрд╣ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдореБрдлрд╝реНрдд рд╣реИ?",
      "a1": "рд╣рд╛рдВ, Curify рдкреНрд░рддрд┐ рдорд╛рд╣ рд╕реАрдорд┐рдд рдЙрдкрд╢реАрд░реНрд╖рдХ рдорд┐рдирдЯреЛрдВ рдХреЗ рд╕рд╛рде рдПрдХ рдирд┐рдГрд╢реБрд▓реНрдХ рдпреЛрдЬрдирд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред",
      "q2": "рдХреНрдпрд╛ рдореИрдВ рдирд┐рд░реНрдорд╛рдг рдХреЗ рдмрд╛рдж рдЙрдкрд╢реАрд░реНрд╖рдХ рд╕рдВрдкрд╛рджрд┐рдд рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ?",
      "a2": "рдмрд┐рд▓реНрдХреБрд▓ред рдЖрдк рдирд┐рд░реНрдпрд╛рдд рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╕рдордп, рдЕрдиреБрд╡рд╛рдж рдФрд░ рд╢реИрд▓реА рдХреЛ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
    }
  },
  "videoDubbing": {
    "metadata": {
      "title": "AI рд╡реАрдбрд┐рдпреЛ рдбрдмрд┐рдВрдЧ рдЯреВрд▓ | Curify AI",
      "description": "AI рд╡реЙрдпрд╕ рдХреНрд▓реЛрдирд┐рдВрдЧ, рднрд╛рд╡рдирд╛ рд╕рдВрд░рдХреНрд╖рдг рдФрд░ рд▓рд┐рдк рд╕рд┐рдВрдХ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдкрдиреЗ рд╡реАрдбрд┐рдпреЛ рдХреЛ 170+ рднрд╛рд╖рд╛рдУрдВ рдореЗрдВ рдбрдм рдХрд░реЗрдВред Curify рдХреА AI рдбрдмрд┐рдВрдЧ рдХреЛ рдореБрдлреНрдд рдореЗрдВ рдЖрдЬрд╝рдорд╛рдПрдВред"
    },
    "title": "рдкреНрд░рд╛рдХреГрддрд┐рдХ рдЖрд╡рд╛рдЬ рдХреЗ рд╕рд╛рде AI рд╡реАрдбрд┐рдпреЛ рдбрдмрд┐рдВрдЧ",
    "description": "рдпрдерд╛рд░реНрдерд╡рд╛рджреА AI рдЖрд╡рд╛рдЬ рдФрд░ рд▓рд┐рдк рд╕рд┐рдВрдХ рдХреЗ рд╕рд╛рде рдЕрдкрдиреА рд╡реАрдбрд┐рдпреЛ рд╕рд╛рдордЧреНрд░реА рдХрд╛ 170 рд╕реЗ рдЕрдзрд┐рдХ рднрд╛рд╖рд╛рдУрдВ рдореЗрдВ рдЕрдиреБрд╡рд╛рдж рдФрд░ рдбрдм рдХрд░реЗрдВред рдЕрдВрддрд░рд░рд╛рд╖реНрдЯреНрд░реАрдп рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдФрд░ рдмреНрд░рд╛рдВрдбреЛрдВ рдХреЗ рд▓рд┐рдП рдмрд┐рд▓реНрдХреБрд▓ рд╕рд╣реАред"
  },
  "about": {
    "metadata": {
      "title": "Curify рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ | рд╡рд┐рдЬрди, рдкреНрд░реМрджреНрдпреЛрдЧрд┐рдХреА рдФрд░ рдЯреАрдо",
      "description": "AI рдХреЗ рд╕рд╛рде рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдХреЛ рд▓реЛрдХрддрд╛рдВрддреНрд░рд┐рдХ рдмрдирд╛рдиреЗ рдХреЗ Curify рдХреЗ рджреГрд╖реНрдЯрд┐рдХреЛрдг рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЬрд╛рдиреЗрдВред рд╣рдо рдЗрдВрдЬреАрдирд┐рдпрд░реЛрдВ рдФрд░ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреА рдПрдХ рдЯреАрдо рд╣реИрдВ рдЬреЛ рдореАрдбрд┐рдпрд╛ рд╕реНрдерд╛рдиреАрдпрдХрд░рдг рдХреЗ рднрд╡рд┐рд╖реНрдп рдХрд╛ рдирд┐рд░реНрдорд╛рдг рдХрд░ рд░рд╣реЗ рд╣реИрдВред"
    }
  },
  "contact": {
    "metadata": {
      "title": "рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВ | Curify Studio",
      "description": "рд╕рдорд░реНрдерди, рдмрд┐рдХреНрд░реА рдпрд╛ рд╕рд╛рдЭреЗрджрд╛рд░реА рдХреЗ рд▓рд┐рдП Curify рдЯреАрдо рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред рд╣рдо рдЖрдкрдХреА рд╕рд╛рдордЧреНрд░реА рдХреЛ рд╡рд┐рд╢реНрд╡ рд╕реНрддрд░ рдкрд░ рд╕реНрдХреЗрд▓ рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдпрд╣рд╛рдВ рд╣реИрдВред"
    }
  },
  "blog": {
    "metadata": {
      "title": "Curify рдмреНрд▓реЙрдЧ | AI рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐",
      "description": "AI рд╡реАрдбрд┐рдпреЛ рдирд┐рд░реНрдорд╛рдг, рдбрдмрд┐рдВрдЧ, рд╢реИрд▓реА рд╣рд╕реНрддрд╛рдВрддрд░рдг рдФрд░ рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдХреЗ рднрд╡рд┐рд╖реНрдп рдкрд░ рдирд╡реАрдирддрдо рд▓реЗрдЦ рдкрдврд╝реЗрдВред"
    }
  },
  "pricing": {
    "metadata": {
      "title": "рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг рдпреЛрдЬрдирд╛рдПрдВ | Curify Studio",
      "description": "рдЕрдкрдиреА рд╕рд╛рдордЧреНрд░реА рдирд┐рд░реНрдорд╛рдг рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рд╕рд╣реА рдпреЛрдЬрдирд╛ рдЪреБрдиреЗрдВред рдореБрдлреНрдд рдЯреВрд▓ рд╕реЗ рд▓реЗрдХрд░ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб AI рдбрдмрд┐рдВрдЧ рдФрд░ рд╕реНрдерд╛рдиреАрдпрдХрд░рдг рддрдХред"
    },
    "header": {
      "title": "рдПрдХ рдпреЛрдЬрдирд╛ рдХреЗ рд╕рд╛рде рд╢реБрд░реБрдЖрдд рдХрд░рдирд╛",
      "subtitle": "рдПрдХ рдпреЛрдЬрдирд╛ рдЪреБрдиреЗрдВ рдЬреЛ рдЖрдкрдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдЕрдиреБрд░реВрдк рд╣реЛред"
    },
    "common": {
      "month": "рдорд╣реАрдирд╛",
      "pricing": "рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг",
      "receive": "рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ"
    },
    "buttons": {
      "signUp": "рд╕рд╛рдЗрди рдЕрдк рдХрд░реЗрдВ",
      "subscribePlan": "рдпреЛрдЬрдирд╛ рдХреА рд╕рджрд╕реНрдпрддрд╛ рд▓реЗрдВ",
      "currentPlan": "рд╡рд░реНрддрдорд╛рди рдпреЛрдЬрдирд╛",
      "comingSoon": "рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ",
      "downgradeToFree": "рдирд┐рдГрд╢реБрд▓реНрдХ рдореЗрдВ рдбрд╛рдЙрдирдЧреНрд░реЗрдб рдХрд░реЗрдВ",
      "downgradeToCreator": "рдХреНрд░рд┐рдПрдЯрд░ рдореЗрдВ рдбрд╛рдЙрдирдЧреНрд░реЗрдб рдХрд░реЗрдВ",
      "contactSales": "рдмрд┐рдХреНрд░реА рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВ"
    },
    "plans": {
      "free": {
        "name": "рдирд┐рдГрд╢реБрд▓реНрдХ",
        "description": "рдЯреВрд▓ рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдФрд░ рд╣рд▓реНрдХреЗ рдХрд╛рдо рдХреЗ рд▓рд┐рдП рдмрдврд╝рд┐рдпрд╛",
        "features": [
          "рд╡реЙрдЯрд░рдорд╛рд░реНрдХ рдХреЗ рдмрд┐рдирд╛ рд╡реАрдбрд┐рдпреЛ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
          "1 рдШрдВрдЯреЗ рдХреА рдореБрдлреНрдд рдЙрдкрд╢реАрд░реНрд╖рдХ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг",
          "SRT рдлрд╝рд╛рдЗрд▓реЗрдВ рдирд┐рд░реНрдпрд╛рдд рдХрд░реЗрдВ"
        ]
      },
      "creator": {
        "name": "рдХреНрд░рд┐рдПрдЯрд░",
        "description": "рдирд┐рдпрдорд┐рдд рдЙрдкрд╢реАрд░реНрд╖рдХ рдФрд░ рд╣рд▓реНрдХреА рдбрдмрд┐рдВрдЧ рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдЫреЛрдЯреЗ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢",
        "plusTitle": "рдирд┐рдГрд╢реБрд▓реНрдХ рдореЗрдВ рд╕рдм рдХреБрдЫ, рдкреНрд▓рд╕:",
        "features": [
          "рд▓рд┐рдк рд╕рд┐рдВрдХрд┐рдВрдЧ",
          "рдмреИрдЪ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг",
          "5 рдШрдВрдЯреЗ рдХреА рдореБрдлреНрдд рдЙрдкрд╢реАрд░реНрд╖рдХ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг",
          "рдкреНрд░рддрд┐ рдХрд╛рд░реНрдп 30 рдорд┐рдирдЯ рддрдХ"
        ]
      },
      "pro": {
        "name": "рдкреНрд░реЛ",
        "description": "рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ тАФ рдЙрдЪреНрдЪ рдорд╛рддреНрд░рд╛ рд╡рд╛рд▓реЗ рд░рдЪрдирд╛рдХрд╛рд░реЛрдВ рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛",
        "plusTitle": "рдХреНрд░рд┐рдПрдЯрд░ рдореЗрдВ рд╕рдм рдХреБрдЫ, рдкреНрд▓рд╕:",
        "features": [
          "рд╡реЙрдпрд╕ рдмреНрдпреВрдЯрд┐рдлрд┐рдХреЗрд╢рди рдФрд░ рд╢реЛрд░ рд╣рдЯрд╛рдирд╛",
          "рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рдХрддрд╛рд░",
          "рдкреНрд░рддрд┐ рдХрд╛рд░реНрдп 60 рдорд┐рдирдЯ рддрдХ",
          "рдЕрд╕реАрдорд┐рдд рдЙрдкрд╢реАрд░реНрд╖рдХ рдорд┐рдирдЯ"
        ]
      },
      "enterprise": {
        "name": "рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝",
        "description": "рдЯреАрдореЛрдВ, рд╕реНрдЯреВрдбрд┐рдпреЛ рдФрд░ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдХреЗ рд▓рд┐рдП",
        "customPricing": "рдХрд╕реНрдЯрдо",
        "unlimited": "рдЕрд╕реАрдорд┐рдд ЁЯРЪ",
        "tailoredSupport": "рдФрд░ рдЕрдиреБрд░реВрдк рд╕рдорд░реНрдерди",
        "plusTitle": "рдкреНрд░реЛ рдореЗрдВ рд╕рдм рдХреБрдЫ, рдкреНрд▓рд╕:",
        "features": [
          "рд╕рдорд░реНрдкрд┐рдд рдЦрд╛рддрд╛ рдкреНрд░рдмрдВрдзрдХ",
          "рдСрди-рдкреНрд░реЗрдорд┐рд╕ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╡рд┐рдХрд▓реНрдк",
          "API рдкрд╣реБрдВрдЪ рдФрд░ рдЙрдкрдпреЛрдЧ рд╡рд┐рд╢реНрд▓реЗрд╖рдг",
          "рдХрд╕реНрдЯрдо рдПрдХреАрдХрд░рдг рдФрд░ SLA",
          "рдЕрд╕реАрдорд┐рдд рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдШрдВрдЯреЗ"
        ]
      }
    },
    "table": {
      "header": {
        "feature": "рд╕реБрд╡рд┐рдзрд╛ / рд╕реАрдорд╛"
      },
      "rows": {
        "videoDownloadWithWatermark": "рд╡реЙрдЯрд░рдорд╛рд░реНрдХ рдХреЗ рд╕рд╛рде рд╡реАрдбрд┐рдпреЛ рдбрд╛рдЙрдирд▓реЛрдб",
        "videoDownloadWithoutWatermark": "рд╡реЙрдЯрд░рдорд╛рд░реНрдХ рдХреЗ рдмрд┐рдирд╛ рд╡реАрдбрд┐рдпреЛ рдбрд╛рдЙрдирд▓реЛрдб",
        "downloadSrt": "SRT рдлрд╝рд╛рдЗрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
        "voiceBeautification": "рд╡реЙрдпрд╕ рдмреНрдпреВрдЯрд┐рдлрд┐рдХреЗрд╢рди рдФрд░ рд╢реЛрд░ рд╣рдЯрд╛рдирд╛",
        "lipSync": "рд▓рд┐рдк рд╕рд┐рдВрдХ",
        "subtitleTools": "рдЙрдкрд╢реАрд░реНрд╖рдХ рдЙрдкрдХрд░рдг (рдЬреЛрдбрд╝реЗрдВ/рд╣рдЯрд╛рдПрдВ, рдХреЛрдИ рдЕрдиреБрд╡рд╛рдж рдирд╣реАрдВ)",
        "batchProcessing": "рдмреИрдЪ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг",
        "maxVideoLength": "рдкреНрд░рддрд┐ рдХрд╛рд░реНрдп рдЕрдзрд┐рдХрддрдо рд╡реАрдбрд┐рдпреЛ рд▓рдВрдмрд╛рдИ",
        "monthlyCredits": "рдорд╛рд╕рд┐рдХ рдореБрдлреНрдд рдХреНрд░реЗрдбрд┐рдЯ",
        "priorityQueue": "рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рдХрддрд╛рд░ / рддреЗрдЬ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг",
        "creditTopUp": "рдХреНрд░реЗрдбрд┐рдЯ рдЯреЙрдк-рдЕрдк"
      },
      "values": {
        "free": "рдирд┐рдГрд╢реБрд▓реНрдХ",
        "unlimited": "рдЕрд╕реАрдорд┐рдд",
        "oneHourPerMonth": "1 рдШрдВрдЯреЗ/рдорд╛рд╣",
        "fiveHoursPerMonth": "5 рдШрдВрдЯреЗ/рдорд╛рд╣",
        "fiveMinutes": "5 рдорд┐рдирдЯ",
        "thirtyMinutes": "30 рдорд┐рдирдЯ",
        "sixtyMinutes": "60 рдорд┐рдирдЯ"
      }
    }
  },
  "aeVsComfyUi": {
    "title": "AE vs ComfyUI тАУ Redefining Animation (Part 3)",
    "heading": "ЁЯОи AE vs ComfyUI",
    "intro1": "We often get asked: why not just use After Effects (AE)? Or why bother with ComfyUI? Both are essential тАФ one provides fine control, the other generative creativity.",
    "intro2": "AE offers timeline precision and control over transitions, lighting, and effects. ComfyUI brings AI-native workflows, combining diffusion, text, and multimodal orchestration.",
    "table": {
      "colAE": "AE",
      "colComfy": "ComfyUI",
      "row1a": "Precise VFX and motion control",
      "row1b": "AI-native generation of videos",
      "row2a": "Timeline-based editing",
      "row2b": "Workflow/node-based rendering",
      "row3a": "Manual / plugin-driven workflow",
      "row3b": "Diffusion + LLM + multimodal orchestration"
    },
    "outro": "In our workflow, ComfyUI handles the AI generation and iteration, while AE refines the final look тАФ transitions, overlays, and compositing."
  },
  "video_translation_eval": {
    "title": "Evaluating AI Video Translation Quality",
    "subtitle": "Metrics that Matter",
    "intro": "Translating videos across languages is no small feat тАФ it involves transcription, translation, voice synthesis, timing, and more. At Curify, weтАЩve built a robust evaluation pipeline to ensure each piece meets industry standards.",
    "section1_title": "1. Transcription Quality",
    "section1_engine": "Engine: WhisperX",
    "section1_metrics": [
      "WER (Word Error Rate)",
      "Punctuation F1 (for expressiveness and readability)"
    ],
    "section2_title": "2. Translation Quality",
    "section2_engine": "Engines: Helsinki, MarianMT",
    "section2_metrics": [
      "BLEU (standard metric)",
      "COMET / chrF++ (semantic similarity)",
      "Human review: fluency + adequacy"
    ],
    "section3_title": "3. Voice Synthesis Quality",
    "section3_engine": "Engines: XTTS / YourTTS",
    "section3_metrics": [
      "MOS (Naturalness, similarity, expressiveness)",
      "Speaker verification accuracy"
    ],
    "section4_title": "4. Alignment & Lip Sync",
    "section4_metrics": [
      "Segment duration mismatch",
      "Wav2Lip sync confidence",
      "Temporal drift analysis"
    ],
    "section5_title": "5. Semantic Preservation",
    "section5_method": "We use LLMs (like GPT-4) to judge whether the translated speech preserves the original meaning, tone, and emotion. Example prompt:",
    "section5_prompt": "Compare this Mandarin transcript to the English voiceover. Does the tone, intent, and content match? Rate 1тАУ5 and explain.",
    "section6_title": "6. User Feedback & GTM Validation",
    "section6_metrics": [
      "Voice quality fit for product category",
      "Viewer retention improvement",
      "Adoption willingness from early users (e.g., 1688 sellers)"
    ],
    "closing": "At Curify, we donтАЩt just translate тАФ we preserve storytelling, emotion, and clarity across languages. If youтАЩre ready to scale your voice globally, get in touch.",
    "available_locales": "Post available in: [EN] [ZH] [ES] [DE]"
  },
  "storyboardToPipeline": {
    "title": "From Storyboards to AI Pipelines тАУ Redefining Animation",
    "intro": {
      "p1": "Most people think AI video means \"text in, clip out.\" But if you're aiming for <strong>cinematic, director-level control</strong>, it's an entirely different game.",
      "p2": "In traditional animation, every detail matters тАФ character design, motion continuity, timing, and scene transitions. Our goal is to make AI match that level of precision.",
      "p3": "Animation today is both an art and a structured orchestration challenge. We think like directors, but build like engineers.",
      "p4": "That's why we build <strong>Controlled Generation Pipelines</strong> instead of one-shot generation. These pipelines combine structure and creativity:",
      "pipelineItems": [
        "Storyboard-to-Video: JSON-based scene specs with IDs, timing, and camera metadata",
        "ComfyUI-based workflows: node-graph DAGs with versioned checkpoints, LoRA stacks, and seeds",
        "Temporal & multimodal control: shared scene IDs across image, motion, audio, and subtitles"
      ],
      "p5": "Now, let's walk through a simple example to show how AI pipelines work in practice.",
      "technicalNotes": [
        "All stages read/write typed artifacts (JSON/CSV, PNG sequences, WAV/MP3, MP4, .aep)",
        "Pipelines are orchestrated via Python/CLI (e.g., ComfyUI API, ffmpeg, TTS APIs)",
        "Every run is reproducible through stored config (model, sampler, seed, prompts, duration)"
      ]
    },
    "pipeline": {
      "title": "AI Video Generation Pipeline",
      "description": "The AI video generation pipeline transforms text prompts into polished videos through structured stages with explicit inputs, outputs, and configs.",
      "prompt": "1. Prompt (raw idea тЖТ structured JSON spec)",
      "storyboard": "2. Storyboard (scene/shot table with timing, camera, and description)",
      "images": "3. Images (per-shot keyframes generated via Stable Diffusion / ComfyUI)",
      "animation": "4. Animation (image sequences тЖТ motion, parallax, and effects)",
      "voiceOver": "5. Voice Over (TTS + alignment data)",
      "finalVideo": "6. Final Video (ffmpeg composition: video + audio + subtitles)",
      "features": [
        "JSON-first design: every scene is addressable and scriptable (scene_id, shot_id)",
        "ComfyUI-based workflows: modular, reproducible, composable DAGs for image/video generation",
        "Temporal & multimodal control: consistent seeds, character embeddings, and timing across modalities"
      ],
      "exampleIntro": "Now, let's walk through a simple example to show how AI pipelines work in practice.",
      "artifacts": {
        "promptSpec": "prompt_run_001.json",
        "storyboardTable": "storyboard_v1.csv",
        "imageOutputDir": "renders/scene_{scene_id}/shot_{shot_id}/frame_####.png",
        "audioOutput": "audio/voiceover_final.wav",
        "subtitleFile": "subtitles/storyboard_v1.srt",
        "finalVideoFile": "exports/storyboard_v1_final.mp4"
      }
    },
    "steps": {
      "step1": {
        "title": "Step 1: Start with a Basic Prompt",
        "example": "A girl stands at a midnight train station, wind blowing her hair.",
        "expandedPrompt": "With the help of GPT or a local LLM, we expand this into a structured JSON object with global style, character definitions, and per-scene breakdown.",
        "technicalDetails": {
          "llmFields": [
            "global_style: art style, camera language, color palette",
            "characters: name, age, look, outfit, emotional state",
            "scenes: [{ scene_id, shot_id, description, camera_type, duration_seconds }]"
          ],
          "outputFile": "prompt_run_001.json",
          "exampleStack": "Python script calling OpenAI/LLM API and writing JSON to disk"
        }
      },
      "step2": {
        "title": "Step 2: Convert Prompt to a Storyboard Table",
        "description": "The JSON spec is flattened into a storyboard table (CSV or Notion) that both humans and the pipeline can read.",
        "technicalDetails": {
          "columns": [
            "scene_id",
            "shot_id",
            "start_time",
            "end_time",
            "duration_seconds",
            "camera_type",
            "visual_description",
            "character_state",
            "motion_notes"
          ],
          "storage": "storyboard_v1.csv (used as the single source of truth for downstream steps)",
          "automation": "Python / Node.js script transforms prompt_run_001.json тЖТ storyboard_v1.csv"
        }
      },
      "step3": {
        "title": "ЁЯЫая╕П Step 3: Generate Visuals",
        "description": "Generate high-quality keyframe images for each shot using Stable Diffusion through a ComfyUI workflow.",
        "points": [
          "ЁЯОи Use <strong>Stable Diffusion</strong> or <strong>ComfyUI</strong> to turn each row in `storyboard_v1.csv` into a high-res keyframe.",
          "Keep the style consistent by using the same base checkpoint, LoRA stack, sampler, and seed policy across all shots.",
          "Refine images with inpainting (for faces/hands) and outpainting (for extended compositions and camera motion)."
        ],
        "technicalDetails": {
          "modelConfig": {
            "checkpoint": "sd_xl_base_1.0.safetensors",
            "vae": "sdxl_vae.safetensors",
            "sampler": "euler_a",
            "steps": 25,
            "cfgScale": 6.5,
            "resolution": "1024x576",
            "loraStack": [
              "character_girl_v2.safetensors",
              "style_cinematic_blue_hour.safetensors"
            ]
          },
          "consistency": {
            "seedStrategy": "fixed_per_scene",
            "seedExample": "seed = hash(scene_id + character_name)",
            "namingConvention": "renders/scene_{scene_id}/shot_{shot_id}/kf_0001.png"
          },
          "comfyui": {
            "workflowFile": "workflows/storyboard_to_frame.json",
            "inputMethod": "custom node / HTTP API reading storyboard_v1.csv and modelConfig",
            "batching": "GPU batches keyed by scene_id to reuse loaded weights"
          }
        }
      },
      "step4": {
        "title": "ЁЯОм Step 4: Add Motion and Atmosphere in After Effects",
        "description": "Enhance static keyframes with motion, parallax, and atmosphere using Adobe After Effects (or an equivalent compositor).",
        "points": [
          "Import image sequences or keyframes into <strong>Adobe After Effects</strong> as layered compositions.",
          "Apply keyframe animations: pan, zoom, parallax layers, fog overlays, glow and light flicker.",
          "Add ambient sound cues and cinematic transitions between scenes."
        ],
        "technicalDetails": {
          "input": "renders/scene_{scene_id}/shot_{shot_id}/kf_0001.png (plus optional depth/alpha maps)",
          "projectFile": "ae/storyboard_v1.aep",
          "automation": [
            "Use AE scripts/ExtendScript or JSX to auto-create comps per scene_id.",
            "Map `duration_seconds` from storyboard_v1.csv тЖТ comp duration.",
            "Generate intermediate frames via AE plugins or video-aware diffusion tools if needed."
          ],
          "output": "ae_renders/scene_{scene_id}_shot_{shot_id}_anim.mp4"
        }
      },
      "step5": {
        "title": "ЁЯОз Step 5: Add Voice and Subtitles",
        "description": "Generate voiceover aligned to the storyboard and attach subtitles for accessibility and clarity.",
        "points": [
          "Use <strong>XTTS</strong> or <strong>ElevenLabs</strong> to generate natural voiceovers from the script, using a consistent speaker profile.",
          "For acronyms (like API, NBA), generate English snippets separately and merge in post to keep pronunciation clean.",
          "Add subtitles using `.srt` or `.json` timeline files synced to the voiceover track."
        ],
        "technicalDetails": {
          "scriptSource": "dialogue and narration pulled from prompt_run_001.json + storyboard_v1.csv",
          "ttsConfig": {
            "engine": "XTTS or ElevenLabs",
            "voiceId": "cinematic_female_en",
            "sampleRate": 44100,
            "format": "wav"
          },
          "outputs": {
            "voiceFile": "audio/storyboard_v1_voiceover.wav",
            "subtitleFile": "subtitles/storyboard_v1.srt"
          },
          "syncStrategy": "align `start_time` / `end_time` from storyboard_v1.csv with subtitle cues; ensure total audio length тЙИ final timeline duration"
        }
      },
      "step6": {
        "title": "Step 6: Final Composition with FFMPEG",
        "description": "Use FFMPEG to combine all pieces into one final video file with audio and subtitles.",
        "technicalDetails": {
          "inputs": {
            "video": "ae_renders/storyboard_v1_timeline.mp4",
            "audio": "audio/storyboard_v1_voiceover.wav",
            "subtitles": "subtitles/storyboard_v1.srt"
          },
          "ffmpegExample": "ffmpeg -i storyboard_v1_timeline.mp4 -i storyboard_v1_voiceover.wav -c:v libx264 -c:a aac -shortest -vf subtitles=subtitles/storyboard_v1.srt exports/storyboard_v1_final.mp4",
          "output": "exports/storyboard_v1_final.mp4 (H.264, 24 fps, AAC audio)"
        }
      }
    },
    "whatYouNeed": "ЁЯУБ What You'll Need",
    "whatYouNeedTechnical": [
      "GPU with at least 12GB VRAM for Stable Diffusion / ComfyUI",
      "Python environment for JSON/CSV transforms and automation scripts",
      "ComfyUI installed with required custom nodes and workflows",
      "Adobe After Effects or similar compositor for motion and FX",
      "XTTS / ElevenLabs API access for TTS",
      "ffmpeg installed and available on the command line"
    ],
    "cta": "ЁЯЪА Ready to bring your storyboard to life with AI? <strong>We can provide a full starter kit</strong> with example JSONs, ComfyUI workflows, and ffmpeg/AE templates to help you get started."
  },
  "SceneDetection": {
    "tags": {
      "computerVision": "Computer Vision",
      "deepLearning": "Deep Learning",
      "realTimeAnalysis": "Real-time Analysis"
    },
    "hero": {
      "title": "Transform Video into Storyboards with AI",
      "subtitle": "How we built an advanced pipeline that turns hours of footage into structured, searchable storyboards in minutes."
    },
    "introduction": {
      "paragraph1": "Imagine being able to upload hours of raw footage and within minutes get a <strong>detailed, scene-by-scene breakdown</strong> of your entire video. That's exactly what our AI-powered scene detection system delivers.",
      "paragraph2": "Built with cutting-edge Python libraries and deep learning models, this pipeline doesn't just detect scene changesтАФit understands the content, identifies key elements, and structures everything into a comprehensive storyboard."
    },
    "imageAlt": "The scene detection pipeline in action, identifying key moments and generating structured storyboards",
    "protip": "For optimal results, ensure your video has clear visual separation between scenes. The system works best with well-lit footage and minimal motion blur. Consider adding chapter markers or scene breaks in your video editor to improve detection accuracy.",
    "humanEvaluation": {
      "title": "Human Evaluation of AI Output",
      "introduction": "While our AI pipeline is highly accurate, human evaluation remains a critical component of our quality assurance process. Here's how we ensure the highest quality output:",
      "evaluationAreas": [
        "<strong>Scene Boundary Accuracy</strong> - Reviewing and adjusting scene transition points",
        "<strong>Metadata Validation</strong> - Verifying AI-generated descriptions, tags, and labels",
        "<strong>Consistency Check</strong> - Ensuring uniform style and formatting across all scenes",
        "<strong>Content Accuracy</strong> - Validating that the AI correctly identified key elements in each scene"
      ],
      "workflow": {
        "title": "Human-in-the-Loop Workflow",
        "steps": [
          "AI processes the video and generates initial storyboard",
          "Human reviewers evaluate the AI output using our specialized tools",
          "Reviewers provide feedback and make necessary adjustments",
          "System learns from human corrections to improve future outputs",
          "Final quality check before delivery"
        ]
      },
      "benefits": {
        "title": "Benefits of Human Evaluation",
        "items": [
          "<strong>Higher Accuracy</strong> - Human reviewers catch subtle nuances that AI might miss",
          "<strong>Contextual Understanding</strong> - Better interpretation of cultural and situational context",
          "<strong>Quality Assurance</strong> - Additional layer of validation for professional use cases",
          "<strong>Continuous Improvement</strong> - Human feedback helps train and refine the AI models"
        ]
      },
      "tools": {
        "title": "Evaluation Tools",
        "description": "Our platform includes specialized tools to assist human reviewers:",
        "features": [
          "Side-by-side video and storyboard comparison",
          "Easy-to-use interface for adjusting scene boundaries",
          "Bulk editing of metadata and tags",
          "Collaboration features for team review",
          "Version history and change tracking"
        ]
      }
    },
    "header": {
      "title": "From Raw Footage to Storyboards",
      "author": "Curify AI Team",
      "role": "AI Research Team",
      "imageAlt": "AI analyzing video scenes and generating storyboards",
      "imageCaption": "AI-powered scene detection in action, identifying key moments in video content",
      "subtitle": "AI-Powered Video Analysis",
      "date": "December 11, 2025",
      "readingTime": "8 min read"
    },
    "Technical": {
      "title": "TECHNICAL DEEP DIVE",
      "steps": {
        "step1": "How It Works: Under the Hood",
        "videoProcessingPipeline": "Our system processes videos through a sophisticated multi-stage pipeline that ensures accurate scene detection and analysis:",
        "step2": "Video Processing Pipeline",
        "step2Text": "Our system processes videos through a sophisticated multi-stage pipeline that ensures accurate scene detection and analysis:",
        "step3": "Scene Detection and Metadata Extraction",
        "step3Text": "OpenCV-powered frame sampling at optimal intervals",
        "step4": "Shot Analysis and Metadata Enhancement",
        "step4Text": "Adaptive thresholding for precise scene boundary detection",
        "step5": "Scene Labeling and Metadata Organization",
        "step5Text": "Deep learning models for comprehensive scene understanding",
        "step6": "Metadata Export and Integration",
        "step6Text": "Export metadata to JSON format for integration with other tools"
      }
    },
    "featuresTitle": "Powerful Features at Your Fingertips",
    "features1": "Seamless Video Integration",
    "features1Text": "Process local files, YouTube links, or cloud storage with our unified interface.",
    "features": {
      "modularArchitecture": {
        "title": "Modular Architecture",
        "description": "The system is built with separate components for video analysis, AI processing, and output generation, making it easy to extend and maintain."
      },
      "performance": {
        "title": "Performance Optimized",
        "description": "Efficient frame processing and parallelization ensure fast analysis even for long videos."
      },
      "aiEnhanced": {
        "title": "AI-Enhanced Analysis",
        "description": "Optional AI components provide deeper scene understanding and more accurate labeling."
      }
    },
    "features2": "Seamless Video Integration",
    "features2Text": "Process local files, YouTube links, or cloud storage with our unified interface.",
    "features3": "AI-Powered Analysis",
    "features3Text": "Enhance scene understanding with our optional AI analysis module.",
    "features4": "Camera Motion Detection",
    "features4Text": "Automatically identify pans, zooms, and other camera movements.",
    "features5": "Customizable Output",
    "features5Text": "Export metadata to JSON format for integration with other tools.",
    "intro": {
      "p1": "In today's fast-paced content creation landscape, <strong>efficient video analysis</strong> is no longer a luxuryтАФit's a necessity. Our AI-powered scene detection technology transforms hours of raw footage into structured, searchable content in minutes, not days.",
      "p2": "Whether you're a filmmaker, content creator, or media professional, understanding the power of automated scene detection can revolutionize your workflow and unlock new creative possibilities."
    },
    "proTip": "For best results, ensure your source video has clear audio and visual separation between scenes. Well-lit environments and minimal background noise significantly improve detection accuracy.",
    "titanicExample": {
      "title": "Real-World Example: Titanic Scene Analysis",
      "description": "Watch how our system analyzes a scene from Titanic, detecting shot changes and generating detailed scene metadata:",
      "analysis": "Analysis:",
      "analysisText": "Scene detection and metadata extraction in real-time"
    },
    "inceptionExample": {
      "title": "Dream Level Analysis: Inception Scene Breakdown",
      "description": "Explore how our AI analyzes the complex dream layers and visual effects in Inception:",
      "analysis": "Analysis",
      "analysisText": "Dream layer detection and visual effect breakdown",
      "breakdownTitle": "Scene Analysis Breakdown",
      "showFullAnalysis": "Show Full Scene Analysis",
      "hideFullAnalysis": "Hide Full Scene Analysis",
      "fullSceneAnalysis": "Full Scene Analysis",
      "sceneCard": {
        "mood": "Mood",
        "environment": "Environment",
        "shotNotes": "Shot Notes"
      }
    },
    "Scene": "Scene",
    "process": {
      "title": "How Our Scene Detection Works",
      "steps": {
        "step1": {
          "title": "1. Video Analysis",
          "description": "Our AI scans your video frame by frame, analyzing visual and audio cues to identify potential scene boundaries.",
          "details": [
            "Analyzes color histograms and motion vectors",
            "Detects audio level changes and silences",
            "Identifies shot boundaries and transitions"
          ]
        },
        "step2": {
          "title": "2. Scene Segmentation",
          "description": "The system groups related shots into coherent scenes based on visual and temporal relationships.",
          "details": [
            "Uses machine learning to understand scene context",
            "Considers shot duration and transition types",
            "Merges related shots into logical scenes"
          ]
        },
        "step3": {
          "title": "3. Content Classification",
          "description": "Each detected scene is analyzed and categorized based on its visual and audio content.",
          "details": [
            "Identifies key visual elements and objects",
            "Classifies scene type (e.g., interview, action, landscape)",
            "Analyzes audio for speech, music, and effects"
          ]
        },
        "step4": {
          "title": "4. Metadata Generation",
          "description": "Comprehensive metadata is generated for each scene, enabling powerful search and organization.",
          "details": [
            "Creates timestamps and duration information",
            "Generates representative thumbnails",
            "Extracts key dialogue and audio cues"
          ]
        }
      }
    },
    "whyItWorks": {
      "title": "Why Our Scene Detection Works So Well",
      "points": "<li>Our AI analyzes both <strong>visual and audio cues</strong> to identify scene boundaries with over 95% accuracy.</li><li>Advanced <strong>machine learning models</strong> understand context, not just visual changes, for more natural scene detection.</li><li>Real-time processing allows for <strong>immediate feedback</strong> and adjustments during filming or editing.</li>"
    },
    "recommendedStyle": {
      "title": "Recommended Style for Best Results",
      "description": "To get the most accurate scene detection, we recommend the following style guidelines:",
      "points": [
        "Maintain consistent lighting within each scene",
        "Use clear audio markers or clapperboards between takes",
        "Keep camera movements smooth and intentional",
        "Maintain consistent audio levels within scenes"
      ]
    },
    "title": "From Raw Footage to Storyboards: AI-Powered Video Analysis",
    "description": "Discover how AI transforms raw video into structured storyboards with automated scene detection and analysis.",
    "timeline": {
      "title": "Scene Timeline",
      "viewScene": "View Scene {1}"
    },
    "cta": "ЁЯЪА Ready to bring your storyboard to life with AI? <strong>We can provide a full starter kit</strong> with example JSONs, ComfyUI workflows, and ffmpeg/AE templates to help you get started.",
    "sceneBreakdown": {
      "title": "Understanding Scene Detection Output",
      "introduction": "Let's break down a typical scene detection output to understand how our AI analyzes and structures video content. Below each explanation, you'll find the corresponding JSON structure that powers these insights.",
      "scenes": [
        {
          "title": "1. Scene Identification",
          "content": "Each scene is assigned a unique identifier and timestamp range, allowing for precise navigation through the video content. This forms the foundation of our analysis.",
          "example": "Scene 1 (00:00:02.50 - 00:00:05.20)",
          "jsonExample": {
            "scene_id": "scene_001",
            "start_time": 2.5,
            "end_time": 5.2,
            "duration": 2.7,
            "keyframe_index": 5,
            "keyframe_time": 3.8
          },
          "jsonDescription": "This JSON structure shows the basic identification data for a scene, including its unique ID, timing information, and the index/time of its representative keyframe."
        },
        {
          "title": "2. Visual Analysis",
          "content": "Our AI examines keyframes to understand the visual composition of each scene, including dominant colors, lighting conditions, and visual elements.",
          "example": "Keyframe analysis: Outdoor, daylight, multiple subjects",
          "jsonExample": {
            "visual_analysis": {
              "brightness": 0.78,
              "contrast": 0.65,
              "color_palette": [
                "#3A5FCD",
                "#87CEEB",
                "#F5F5DC"
              ],
              "dominant_colors": [
                {
                  "color": "#3A5FCD",
                  "percentage": 0.45
                },
                {
                  "color": "#87CEEB",
                  "percentage": 0.35
                },
                {
                  "color": "#F5F5DC",
                  "percentage": 0.2
                }
              ],
              "lighting_condition": "daylight",
              "environment": "outdoor",
              "detected_objects": [
                {
                  "label": "person",
                  "confidence": 0.97,
                  "count": 2
                },
                {
                  "label": "sky",
                  "confidence": 0.99,
                  "count": 1
                }
              ]
            }
          },
          "jsonDescription": "This JSON shows the visual analysis data, including color information, lighting conditions, and detected objects with confidence scores."
        },
        {
          "title": "3. Shot Composition",
          "content": "Within each scene, we identify individual shots and their transitions, helping understand the visual flow and pacing of the content.",
          "example": "3 shots detected with smooth cuts and one cross-fade",
          "jsonExample": {
            "shots": [
              {
                "shot_id": "shot_001",
                "start_time": 2.5,
                "end_time": 3.1,
                "transition": {
                  "type": "cut",
                  "confidence": 0.98
                },
                "camera_motion": {
                  "type": "static",
                  "confidence": 0.92
                }
              },
              {
                "shot_id": "shot_002",
                "start_time": 3.1,
                "end_time": 4.3,
                "transition": {
                  "type": "fade",
                  "duration": 0.3,
                  "confidence": 0.95
                },
                "camera_motion": {
                  "type": "pan_left",
                  "confidence": 0.88
                }
              }
            ]
          },
          "jsonDescription": "This JSON structure details the shot composition within a scene, including timing, transition types, and camera motion analysis."
        },
        {
          "title": "4. Content Classification",
          "content": "Scenes are automatically categorized based on their content, making it easy to find specific types of footage later.",
          "example": "Category: Drama, Setting: Ship Deck, Subjects: Main Characters",
          "jsonExample": {
            "content_analysis": {
              "primary_category": "drama",
              "secondary_categories": [
                "romance",
                "disaster"
              ],
              "setting": {
                "type": "ship_deck",
                "time_of_day": "night",
                "confidence": 0.92
              },
              "subjects": [
                {
                  "type": "main_character",
                  "name": "Jack",
                  "position": "center_frame",
                  "emotion": "determined",
                  "confidence": 0.89
                },
                {
                  "type": "main_character",
                  "name": "Rose",
                  "position": "center_frame",
                  "emotion": "fearful",
                  "confidence": 0.91
                }
              ],
              "sentiment": {
                "overall": "intense_dramatic",
                "confidence": 0.88,
                "emotions": [
                  "fear",
                  "determination",
                  "urgency"
                ]
              },
              "key_elements": [
                "lifeboat",
                "ocean",
                "moonlight"
              ],
              "narrative_importance": 0.95,
              "action_required": true
            }
          },
          "jsonDescription": "This JSON shows how the AI analyzes and classifies movie scenes, including character emotions, setting details, and narrative importance, with Titanic's dramatic lifeboat scene as an example."
        }
      ],
      "analysisTitle": "Putting It All Together",
      "analysisContent": "By combining these elements, our system creates a comprehensive map of your video content. This structured data powers features like intelligent search, automated editing, and content analysis.",
      "fullExampleTitle": "Complete Scene Data Example",
      "fullExampleDescription": "Here's how all the pieces come together in a complete scene analysis:",
      "fullExample": {
        "scene_id": "scene_001",
        "start_time": 2.5,
        "end_time": 5.2,
        "duration": 2.7,
        "metadata": {
          "created_at": "2025-12-11T14:25:30Z",
          "video_source": "interview_001.mp4",
          "resolution": "1920x1080",
          "fps": 30
        },
        "visual_analysis": {
          "brightness": 0.78,
          "contrast": 0.65,
          "color_palette": [
            "#3A5FCD",
            "#87CEEB",
            "#F5F5DC"
          ],
          "lighting_condition": "daylight",
          "environment": "studio"
        },
        "audio_analysis": {
          "has_speech": true,
          "speech_confidence": 0.92,
          "background_noise_level": 0.15,
          "speaker_gender": [
            "male",
            "female"
          ],
          "speech_text": "Let's discuss how AI is transforming video production..."
        },
        "content_analysis": {
          "primary_category": "interview",
          "setting": "studio",
          "subjects": [
            "host",
            "guest"
          ],
          "sentiment": "neutral_positive"
        },
        "shots": [
          {
            "shot_id": "shot_001",
            "start_time": 2.5,
            "end_time": 3.1,
            "keyframe": "https://example.com/keyframes/scene_001_shot_001.jpg",
            "transition": {
              "type": "cut",
              "confidence": 0.98
            }
          },
          {
            "shot_id": "shot_002",
            "start_time": 3.1,
            "end_time": 5.2,
            "keyframe": "https://example.com/keyframes/scene_001_shot_002.jpg",
            "transition": {
              "type": "fade",
              "confidence": 0.95
            }
          }
        ]
      },
      "benefitsTitle": "Key Benefits",
      "benefits": [
        "<strong>Efficient Editing:</strong> Jump directly to any scene or shot without scrubbing through hours of footage",
        "<strong>Smart Search:</strong> Find content based on visual elements, not just metadata",
        "<strong>Consistent Quality:</strong> Identify and maintain visual consistency across your project",
        "<strong>Data-Driven Decisions:</strong> Get insights into your content structure and pacing"
      ]
    },
    "conclusion": {
      "title": "Transforming Video Production with AI",
      "p1": "AI-powered scene detection is revolutionizing how we approach video production. By automating the tedious process of scene identification and organization, creators can focus on what truly matters тАУ telling compelling stories. Our technology bridges the gap between raw footage and polished content, making professional-grade video analysis accessible to everyone.",
      "p2": "As we continue to refine our algorithms and expand our capabilities, we're excited to see how filmmakers, educators, and content creators will leverage these tools to push the boundaries of visual storytelling. The future of video production is here, and it's more efficient and creative than ever before."
    },
    "richStructuredOutput": "Rich, Structured Output",
    "richStructuredOutputText": "Our system generates comprehensive storyboard data with detailed metadata for each scene, giving you complete control over your video content.",
    "advancedUsage": {
      "title": "Advanced Usage & Customization",
      "description": "The scene detection system is highly customizable to fit different use cases. Here are some advanced features and customization options:",
      "features": {
        "thresholds": {
          "title": "Custom Scene Detection Thresholds",
          "description": "Adjust the sensitivity of scene detection by modifying the threshold parameter. Lower values make the detection more sensitive to changes."
        },
        "aiAnalysis": {
          "title": "AI-Enhanced Analysis",
          "description": "Enable AI analysis for more detailed scene understanding and labeling. This requires additional setup with the Ollama server."
        },
        "outputCustomization": {
          "title": "Output Customization",
          "description": "Customize the output format and include additional metadata in the generated storyboard."
        }
      },
      "integration": {
        "title": "Integration with Other Tools",
        "description": "The storyboard output can be easily integrated with other tools and workflows. Here are some examples:",
        "tools": {
          "editingSoftware": {
            "title": "Video Editing Software",
            "description": "Import the JSON output into video editors that support script-based editing"
          },
          "cms": {
            "title": "Content Management Systems",
            "description": "Automatically generate metadata for video assets"
          },
          "aiTraining": {
            "title": "AI Training Data",
            "description": "Use the structured output as training data for machine learning models"
          }
        }
      }
    },
    "Benefitss": {
      "title": "Benefits",
      "description": "The benefits of using our AI-powered scene detection system include:",
      "tags": {
        "computerVision": "Computer Vision",
        "deepLearning": "Deep Learning",
        "realTimeAnalysis": "Real-time Analysis"
      },
      "features": {
        "modularArchitecture": {
          "title": "Modular Architecture",
          "description": "The system is built with separate components for video analysis, AI processing, and output generation, making it easy to extend and maintain."
        },
        "performance": {
          "title": "Performance Optimized",
          "description": "Efficient frame processing and parallelization ensure fast analysis even for long videos."
        },
        "aiEnhanced": {
          "title": "AI-Enhanced Analysis",
          "description": "Optional AI components provide deeper scene understanding and more accurate labeling."
        }
      }
    },
    "benefits": {
      "subtitle": "WHY CHOOSE OUR SOLUTION",
      "title": "The Power of AI-Powered Scene Analysis"
    },
    "integration": {
      "title": "Easy Integration",
      "description": "The structured JSON output makes it easy to integrate with other tools and workflows:",
      "technologies": [
        "Python",
        "JavaScript",
        "Node.js",
        "React",
        "Vue"
      ]
    },
    "features10": {
      "comprehensiveData": {
        "title": "Comprehensive Scene Data",
        "items": [
          "Precise timing information for each scene",
          "Key frames for visual reference",
          "Object detection results",
          "Camera movement analysis"
        ]
      },
      "export": {
        "title": "Export Option",
        "formats": {
          "json": "JSON"
        }
      }
    },
    "performance": {
      "title": "Performance Optimized",
      "features": {
        "speed": "5-10x faster than real-time",
        "memory": "Low memory footprint",
        "parallel": "Parallel processing"
      }
    }
  },
  "nanoBananaProPrompts": {
    "title": "Nano Banana Pro Prompts",
    "description": "Discover a collection of creative and effective prompts for your AI content generation needs. These prompts are designed to help you get the most out of your AI tools.",
    "prompts": {
      "title": "Popular Nano Banana Pro Prompts",
      "prompt1": "Create a short story about a futuristic city where emotions are currency",
      "prompt2": "Generate a dialogue between two characters meeting for the first time in a coffee shop",
      "prompt3": "Write a product description for an innovative AI-powered kitchen gadget"
    }
  },
  "qaBotToTaskAgent": {
    "heading": "ЁЯПЧя╕П From QA Bot to Task Agent: An Architecture Guide",
    "description": "Learn how to build reliable task agents that go beyond simple question answering",
    "tldr": "TL;DR: Stop building chatbots that just answer questions. Start building Task Agents that actually do work.",
    "intro": "This guide explains the architectural shift from monolithic QA bots to Task Agents using Static Rules, Dynamic Skills, and Deterministic HooksтАФwith concrete code examples and open-source references.",
    "coreShift": {
      "title": "1. The Core Shift: QA Bot тЖТ Task Agent",
      "content": [
        "Most AI systems today are still context-stuffed QA bots:",
        "тАв They answer questions well",
        "тАв They hallucinate under pressure",
        "тАв They lack guarantees around execution, safety, and consistency"
      ],
      "keyInsight": "The key insight: Don't scale context. Structure it."
    },
    "threeLayerArch": {
      "title": "2. The Three-Layer Architecture",
      "layers": [
        {
          "title": "ЁЯз▒ 1. Static Context тАФ Rules (Always On)",
          "points": [
            "Mental model: Employee handbook",
            "Always loaded",
            "Defines identity, coding standards, behavioral constraints",
            "Prevents hallucinations and style drift",
            "Small, stable, human-editable"
          ]
        },
        {
          "title": "ЁЯЫая╕П 2. Dynamic Context тАФ Skills (On Demand)",
          "points": [
            "Mental model: Toolbox",
            "Loaded only when needed",
            "Each skill is a self-contained capability",
            "Keeps the context window clean"
          ]
        },
        {
          "title": "тЪУ 3. Deterministic Hooks тАФ Guardrails",
          "points": [
            "Mental model: Security + Compliance layer",
            "Not probabilistic",
            "Runs before / after LLM reasoning",
            "Enforces rules that must never fail"
          ]
        }
      ]
    },
    "projectStructure": {
      "title": "3. Recommended Project Structure",
      "structure": "my-task-agent/\nтФЬтФАтФА .cursorrules\nтФЬтФАтФА main.py\nтФЬтФАтФА tools/\nтФВ   тФФтФАтФА linear_mcp.py\nтФФтФАтФА README.md"
    },
    "staticContextExample": {
      "title": "4. Static Context Example: .cursorrules",
      "content": "# ROLE\nYou are a Senior Python Engineer focused on production-grade systems.\n\n# RULES\n- NEVER use print() for debugging\n- ALWAYS type-hint functions\n- Propose a plan if touching >3 files\n\n# BEHAVIOR\n- Be concise\n- Ask clarifying questions if needed\n\nReference: https://github.com/PatrickJS/awesome-cursorrules"
    },
    "dynamicSkillExample": {
      "title": "5. Dynamic Skill Example (MCP)",
      "content": "from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"DevTools\")\n\n@mcp.tool()\ndef create_linear_ticket(title: str, priority: str = \"low\") -> str:\n    ticket_id = f\"LIN-{hash(title) % 10000}\"\n    return f\"Created ticket {ticket_id} with priority={priority}\"\n\nif __name__ == \"__main__\":\n    mcp.run()\n\nReference: https://github.com/modelcontextprotocol/python-sdk"
    },
    "deterministicHookExample": {
      "title": "6. Deterministic Hook Example",
      "content": "def compliance_check_hook(state):\n    user_input = state[\"messages\"][-1].content.lower()\n    if \"password\" in user_input or \"api_key\" in user_input:\n        return {\"error\": \"Security violation detected\"}\n    return agent_node(state)\n\nReference: https://langchain-ai.github.io/langgraph/"
    },
    "finalThought": "рдпрджрд┐ рдЖрдкрдХрд╛ рдПрдЬреЗрдВрдЯ рдХреЗрд╡рд▓ рд╕рд╡рд╛рд▓реЛрдВ рдХреЗ рдЬрд╡рд╛рдм рджреЗрддрд╛ рд╣реИ, рддреЛ рдпрд╣ рдПрдХ рдЪреИрдЯрдмреЙрдЯ рд╣реИред рдпрджрд┐ рдпрд╣ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рд░реВрдк рд╕реЗ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ, рддреЛ рдпрд╣ рдПрдХ рдЯрд╛рд╕реНрдХ рдПрдЬреЗрдВрдЯ рд╣реИред",
    "taskAgentImageAlt": "Illustration of a task agent system architecture showing the interaction between different components"
  },
  "ageAi": {
    "heading": "Data Science in the Age of AI: Is the \"Sexiest Job\" Still Sexy?",
    "intro1": "\"It was the best of times, it was the worst of times.\"",
    "intro2": "A decade ago, Harvard Business Review called Data Scientist the \"sexiest job of the 21st century.\" Today, the landscape is shifting beneath our feet. While the demand for data talent remains high, the rise of Generative AI is fundamentally changing what it means to be a 'Data Scientist.'",
    "realityCheck": {
      "title": "The Reality Check",
      "content": "Traditional domains like Search, Ads, and Recommendation (SAR) are maturing, and the industry is shifting its focus toward heavy-duty engineering and AI architecture. We are seeing a strange paradox.",
      "lowBarTrap": {
        "title": "The \"Low-Bar\" Trap",
        "content": "Master's students can now use GPT-4 to handle data cleaning, EDA, and visualization in seconds. However, without a solid foundation, they often lack the judgment to know when the AI is \"hallucinating\" or providing statistically flawed results."
      },
      "stakeholderShift": {
        "title": "Stakeholder Shift",
        "content": "When business partners can write their own prompts to get basic insights, many DS professionals feel \"under-stimulated,\" trapped in endless meetings and repetitive prompt engineering."
      }
    },
    "strategicPillars": {
      "title": "How to Stay Indispensable: Two Strategic Pillars",
      "intro": "To thrive in this era, we need to evolve from 'builders of models' to 'architects of value.' I see this happening in two dimensions:",
      "buildingTools": {
        "title": "Building the Tools (The Engineer/Architect Mindset)",
        "subtitle": "Don't just use the AI; improve it.",
        "points": [
          {
            "title": "Model Evaluation & Governance",
            "content": "As AI output becomes a commodity, the person who can define what a 'good' result looks like is the most valuable person in the room. Focus on specialized evaluation frameworks (like risk-weighting in Finance)."
          },
          {
            "title": "Domain Fine-Tuning",
            "content": "Mastering techniques like LoRA or RAG to inject specific business knowledge into LLMs."
          },
          {
            "title": "Automation",
            "content": "Lead internal initiatives like 'Virtual Analysts' or automated experimentation pipelines."
          }
        ]
      },
      "leveragingTools": {
        "title": "Leveraging the Tools (The Strategist Mindset)",
        "subtitle": "Use AI to 10x your output so you can focus on what humans do best.",
        "points": [
          {
            "title": "Domain Expertise",
            "content": "AI knows the 'how,' but you know the 'why.' Deep business understanding allows you to provide the right context that AI lacks."
          },
          {
            "title": "Critical Thinking & Experimentation",
            "content": "While AI can generate code, human DS skills are still core for hypothesis testing, causal inference, and interpreting 'messy' real-world data."
          },
          {
            "title": "Communication & Influence",
            "content": "The ability to translate complex data into a business story and build stakeholder trust is a 'soft' skill that has become a 'hard' requirement."
          }
        ]
      }
    },
    "bottomLine": {
      "title": "The Bottom Line",
      "content1": "AI hasn't killed Data Science; it has raised the floor. If your value was purely in writing SQL or tuning hyperparameters, the 'sexiness' is fading. But if you can bridge the gap between business problems and AI solutions, your value has never been higher.",
      "content2": "Personal experience is your edge. A LLM can mimic logic, but it doesn't have the years of 'battle scars' from failed deployments or the intuition built from navigating complex organizations."
    },
    "discussion": {
      "title": "Let's discuss:",
      "prompt": "Are you feeling more 'efficient' or 'replaced' in your current role? How are you evolving your toolkit this year?"
    },
    "hashtags": [
      "#DataScience",
      "#AI",
      "#MachineLearning",
      "#GenerativeAI",
      "#CareerDevelopment",
      "#TechTrends"
    ]
  }
}
