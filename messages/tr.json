{
  "home": {
    "metadata": {
      "title": "Curify | Yapay Zeka ile Ä°Ã§erik OluÅŸturmayÄ± GÃ¼Ã§lendirin",
      "description": "Curify, iÃ§erik oluÅŸturucularÄ±n, eÄŸitimcilerin ve medya ekiplerinin videolarÄ±, mangalarÄ± ve sunumlarÄ± Ã¶lÃ§ekli bir ÅŸekilde Ã¼retmesine ve yerelleÅŸtirmesine yardÄ±mcÄ± olan yapay zeka tabanlÄ± bir platformdur."
    },
    "hero": {
      "title": "Yapay Zeka ile Ä°Ã§erik OluÅŸturmayÄ± GÃ¼Ã§lendirin",
      "description": "Curify Studio, iÃ§erik oluÅŸturucularÄ±n ve kuruluÅŸlarÄ±n dil ve format engellerini aÅŸmasÄ±nÄ± saÄŸlayan yapay zeka tabanlÄ± bir iÃ§erik oluÅŸturma platformu inÅŸa ediyor. Ä°Ã§eriÄŸi kÃ¼resel kitlelere Ã¶lÃ§eklendirme zorluÄŸunu Ã§Ã¶zÃ¼yor, tonu, stili ve duygusal derinliÄŸi koruyan otantik Ã§eviriler saÄŸlÄ±yoruz. Medya, eÄŸitim ve eÄŸlencenin kesiÅŸim noktasÄ±nda faaliyet gÃ¶stererek, hÄ±zla kÃ¼reselleÅŸen bir endÃ¼stride iÃ§erik oluÅŸturucularÄ±n iÃ§eriÄŸi sorunsuz bir ÅŸekilde uyarlamalarÄ± iÃ§in araÃ§lar sunuyoruz."
    }
  },
  "coreFeatures": {
    "oneShot": {
      "title": "Tek AdÄ±mda Ã‡eviri",
      "desc": "Tek bir iÅŸlemde seslendirme, altyazÄ± ve dudak senkronizasyonu ile tam video Ã§evirisi."
    },
    "toneColor": {
      "title": "Ses Rengi Koruma",
      "desc": "Orijinal konuÅŸmacÄ±nÄ±n benzersiz ses Ã¶zelliklerini ve ton kalitesini korur."
    },
    "emotional": {
      "title": "Duygusal KonuÅŸma",
      "desc": "Yapay zeka, duygusal nÃ¼anslarÄ± yeniden Ã¼reterek diller arasÄ±nda otantik ifade saÄŸlar."
    },
    "lipSync": {
      "title": "Dudak Senkronizasyon Teknolojisi",
      "desc": "AÄŸÄ±z hareketlerini Ã§evrilmiÅŸ sesle mÃ¼kemmel bir ÅŸekilde eÅŸleÅŸtiren geliÅŸmiÅŸ dudak senkronizasyonu."
    },
    "subtitle": {
      "title": "AltyazÄ± OluÅŸturucu",
      "desc": "Hassas zamanlama ve doÄŸal dil akÄ±ÅŸÄ± ile akÄ±llÄ± altyazÄ± oluÅŸturma."
    },
    "languages": {
      "title": "170+ Dil",
      "desc": "Ä°Ã§eriÄŸinizi 170'ten fazla dile yerel dÃ¼zeyde doÄŸrulukla Ã§evirin."
    }
  },
  "upcoming": {
    "title": "YakÄ±nda",
    "subtitle": "GeliÅŸtirilmekte olan yeni nesil Ã¶zellikler",
    "styleTransfer": {
      "title": "Stil Transferi",
      "desc": "Yapay zeka destekli gÃ¶rsel dÃ¶nÃ¼ÅŸÃ¼m ile videolarÄ±nÄ±za sinematik veya markaya Ã¶zgÃ¼ stiller uygulayÄ±n.",
      "icon": "ğŸ¨",
      "status": "2025 3. Ã‡eyrekte Geliyor",
      "transcript": "Bu demo, yapay zeka destekli gÃ¶rsel stil transferi kullanarak canlÄ± aksiyon drama klibini tuhaf bir Ghibli tarzÄ± animasyona dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor."
    },
    "mangaTranslation": {
      "title": "Manga Ã‡evirisi",
      "desc": "Metin algÄ±lama, balon dÃ¼zenleme ve kÃ¼ltÃ¼rel uyarlama ile otomatik manga ve Ã§izgi roman Ã§evirisi.",
      "icon": "ğŸ“š",
      "status": "2025 3. Ã‡eyrekte Geliyor",
      "transcript": "Bu prototip, konuÅŸma balonu algÄ±lama ve iki dilli yerinde dÃ¼zenleme dahil olmak Ã¼zere otomatik manga Ã§evirisini gÃ¶stermektedir."
    },
    "templatedVideo": {
      "title": "Åablonlu Video OluÅŸturma",
      "desc": "Yapay zeka tarafÄ±ndan oluÅŸturulan iÃ§erik ve Ã¶zel marka ile ÅŸablonlardan profesyonel videolar oluÅŸturun.",
      "icon": "ğŸ¬",
      "status": "2025 4. Ã‡eyrekte Geliyor",
      "transcript": "Bu demo, hikaye panosunu planlayarak ve gÃ¶rselleri birleÅŸtirerek erken ABD tarihi hakkÄ±nda tarihi bir sahne oluÅŸturan senaryodan videoya bir boru hattÄ±nÄ± gÃ¶stermektedir."
    },
    "statusQ3": "2025 3. Ã‡eyrekte Geliyor",
    "statusQ4": "2025 4. Ã‡eyrekte Geliyor"
  },
  "export": {
    "title": "DÄ±ÅŸa Aktar",
    "export": "DÄ±ÅŸa Aktar",
    "downloading": "Ä°ndiriliyor..."
  },
  "delete": {
    "title": "Ã‡ifte Onay",
    "message": "Bu projeyi silmek istediÄŸinizden emin misiniz?",
    "warning": "Bu iÅŸlem geri alÄ±namaz.",
    "cancel": "Ä°ptal",
    "delete": "Sil",
    "deleting": "Siliniyor..."
  },
  "userMenu": {
    "topUpCredits": "Kredi YÃ¼kle",
    "remaining": "Kalan",
    "planRemaining": "Plan KalanÄ±",
    "validUntil": "GeÃ§erlilik Tarihi",
    "creditsHistory": "Kredi GeÃ§miÅŸi",
    "subscribePlan": "Plana Abone Ol",
    "supportTicket": "Destek Bileti",
    "signOut": "Ã‡Ä±kÄ±ÅŸ Yap"
  },
  "technology": {
    "multimodal": {
      "title": "Ã‡ok Modlu TanÄ±ma",
      "desc": "Daha doÄŸru ve saÄŸlam transkripsiyon elde etmek iÃ§in konuÅŸma ve altyazÄ± sinyallerini birleÅŸtiriyoruz. Bu Ã§ift kanallÄ± tanÄ±ma, hatalarÄ± azaltÄ±r ve Ã¶zellikle gÃ¼rÃ¼ltÃ¼lÃ¼ veya karmaÅŸÄ±k ses sahnelerinde orijinal iÃ§erikle daha iyi hizalanmayÄ± saÄŸlar."
    },
    "emotional": {
      "title": "Duygusal KonuÅŸma",
      "desc": "Ses sentezi modellerimiz, hikaye anlatÄ±mÄ±nÄ± ve izleyici etkileÅŸimini geliÅŸtiren etkileyici, duygusal aÃ§Ä±dan zengin konuÅŸmalar Ã¼retir. Tonu, ritmi ve nÃ¼ansÄ± yakalayarak yapay zeka seslerinin daha insan ve iliÅŸkilendirilebilir hissettirmesini saÄŸlÄ±yoruz."
    },
    "lengthaware": {
      "title": "Uzunluk DuyarlÄ± Ã‡eviri ve Ã–zelleÅŸtirme",
      "desc": "Ã‡evirileri yalnÄ±zca doÄŸruluk iÃ§in deÄŸil, aynÄ± zamanda video ve ses hizalamasÄ± iÃ§in Ã§ok Ã¶nemli olan zamanlama ve hÄ±z iÃ§in de optimize ediyoruz. KullanÄ±cÄ±lar, farklÄ± iÃ§erik ihtiyaÃ§larÄ±na veya izleyici tercihlerine uyacak ÅŸekilde tonu, uzunluÄŸu ve ifadeyi daha da Ã¶zelleÅŸtirebilir."
    },
    "controlled": {
      "title": "KontrollÃ¼ Video OluÅŸturma",
      "desc": "Kontrol edilebilir gÃ¶rsel Ã¶ÄŸeler ve geÃ§iÅŸlerle yapÄ±landÄ±rÄ±lmÄ±ÅŸ, ÅŸablon odaklÄ± video oluÅŸturmayÄ± mÃ¼mkÃ¼n kÄ±lÄ±yoruz. Bu, yaratÄ±cÄ±lara hem yaratÄ±cÄ± Ã¶zgÃ¼rlÃ¼k hem de Ã¼retim tutarlÄ±lÄ±ÄŸÄ± saÄŸlayarak manuel Ã§abayÄ± azaltÄ±rken yÃ¼ksek kaliteli Ã§Ä±ktÄ± saÄŸlar."
    }
  },
  "tools": {
    "video_dubbing": {
      "title": "Video DublajÄ±",
      "desc": "Videonuzu hassas yerelleÅŸtirme ve ses senkronizasyonu ile herhangi bir dile Ã§evirin"
    },
    "subtitle_captioner": {
      "title": "AltyazÄ± OluÅŸturucu",
      "desc": "NetliÄŸi ve eriÅŸilebilirliÄŸi artÄ±rmak iÃ§in Ã§ok dilli altyazÄ±larÄ± otomatik olarak oluÅŸturun"
    },
    "lip_syncing": {
      "title": "Dudak Senkronizasyonu",
      "desc": "Yapay zeka destekli dudak senkronizasyonu ile dudaklarÄ± konuÅŸmayla mÃ¼kemmel bir ÅŸekilde eÅŸleÅŸtirin"
    },
    "style_transfer": {
      "title": "Stil Transferi",
      "desc": "Videonuzu Pixar, Ghibli veya diÄŸer sanatsal stillere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n â€” yakÄ±nda"
    },
    "coming_soon": "YakÄ±nda",
    "create": "OluÅŸtur"
  },
  "bilingual": {
    "metadata": {
      "title": "Ãœcretsiz Ä°ki Dilli AltyazÄ± OluÅŸturucu | Curify AI",
      "description": "Curify'Ä±n Ã¼cretsiz yapay zeka destekli aracÄ±yla videolarÄ±nÄ±z iÃ§in iki dilli altyazÄ±lar oluÅŸturun. YouTube, TikTok, eÄŸitim ve kÃ¼resel iÃ§erik oluÅŸturucular iÃ§in mÃ¼kemmel."
    },
    "title": "Ä°ki Dilli AltyazÄ±lar ArtÄ±k Ã‡ok Kolay",
    "intro": "Curify'Ä±n yapay zeka altyazÄ± motorunu kullanarak iki dilde otomatik olarak altyazÄ± oluÅŸturun. Ä°Ã§erik oluÅŸturucular, eÄŸitimciler ve kÃ¼resel iÅŸletmeler iÃ§in ideal.",
    "example": "Ã–rnek: Jensen Huang yapay zeka stratejisini aÃ§Ä±klÄ±yor â€” Ä°ngilizce + Ã‡ince altyazÄ±lar otomatik olarak oluÅŸturuldu.",
    "cta": "Ãœcretsiz Deneyin",
    "why": {
      "title": "Ä°ki Dilli AltyazÄ±lar Ä°Ã§in Neden Curify'Ä± SeÃ§melisiniz?",
      "point1": "DoÄŸru Ã§eviri ile 170'ten fazla dili destekler.",
      "point2": "Duygusal tonu ve zamanlamayÄ± korur.",
      "point3": "YouTube, TikTok ve eÄŸitim videolarÄ± iÃ§in mÃ¼kemmeldir.",
      "point4": "YayÄ±nlanmaya hazÄ±r altyazÄ± dosyalarÄ±nÄ± veya gÃ¶mÃ¼lÃ¼ videolarÄ± dÄ±ÅŸa aktarÄ±n."
    },
    "faq": {
      "title": "SÄ±kÃ§a Sorulan Sorular",
      "q1": "GerÃ§ekten Ã¼cretsiz mi?",
      "a1": "Evet, Curify ayda sÄ±nÄ±rlÄ± altyazÄ± dakikasÄ± iÃ§eren Ã¼cretsiz bir plan sunar.",
      "q2": "OluÅŸturduktan sonra altyazÄ±larÄ± dÃ¼zenleyebilir miyim?",
      "a2": "Kesinlikle. DÄ±ÅŸa aktarmadan Ã¶nce zamanlamayÄ±, Ã§eviriyi ve stili ayarlayabilirsiniz."
    }
  },
  "videoDubbing": {
    "metadata": {
      "title": "Yapay Zeka Video Dublaj AracÄ± | Curify AI",
      "description": "Yapay zeka ses klonlama, duygu koruma ve dudak senkronizasyonu kullanarak videolarÄ±nÄ±zÄ± 170'ten fazla dile dublaj yapÄ±n. Curify'Ä±n yapay zeka dublajÄ±nÄ± Ã¼cretsiz deneyin."
    },
    "title": "DoÄŸal Ses ile Yapay Zeka Video DublajÄ±",
    "description": "Video iÃ§eriÄŸinizi gerÃ§ekÃ§i yapay zeka sesi ve dudak senkronizasyonu ile 170'ten fazla dile Ã§evirin ve dublaj yapÄ±n. UluslararasÄ± iÃ§erik oluÅŸturucular ve markalar iÃ§in mÃ¼kemmel."
  },
  "about": {
    "metadata": {
      "title": "Curify HakkÄ±nda | Vizyon, Teknoloji ve Ekip",
      "description": "Curify'Ä±n yapay zeka ile iÃ§erik oluÅŸturmayÄ± demokratikleÅŸtirme vizyonunu Ã¶ÄŸrenin. Biz, medya yerelleÅŸtirmesinin geleceÄŸini inÅŸa eden bir mÃ¼hendis ve yaratÄ±cÄ± ekibiyiz."
    }
  },
  "contact": {
    "metadata": {
      "title": "Bize UlaÅŸÄ±n | Curify Studio",
      "description": "Destek, satÄ±ÅŸ veya ortaklÄ±klar iÃ§in Curify ekibiyle iletiÅŸime geÃ§in. Ä°Ã§eriÄŸinizi kÃ¼resel olarak Ã¶lÃ§eklendirmenize yardÄ±mcÄ± olmak iÃ§in buradayÄ±z."
    }
  },
  "blog": {
    "metadata": {
      "title": "Curify Blog | Yapay Zeka Ä°Ã§erik OluÅŸturma Analizleri",
      "description": "Yapay zeka video oluÅŸturma, dublaj, stil transferi ve iÃ§erik oluÅŸturmanÄ±n geleceÄŸi hakkÄ±ndaki en son makaleleri okuyun."
    }
  },
  "pricing": {
    "metadata": {
      "title": "FiyatlandÄ±rma PlanlarÄ± | Curify Studio",
      "description": "Ä°Ã§erik oluÅŸturma ihtiyaÃ§larÄ±nÄ±z iÃ§in doÄŸru planÄ± seÃ§in. Ãœcretsiz araÃ§lardan kurumsal dÃ¼zeyde yapay zeka dublajÄ±na ve yerelleÅŸtirmeye kadar."
    },
    "header": {
      "title": "Bir planla baÅŸlarken",
      "subtitle": "Ä°htiyaÃ§larÄ±nÄ±za uygun bir plan seÃ§in."
    },
    "common": {
      "month": "Ay",
      "pricing": "FiyatlandÄ±rma",
      "receive": "Al"
    },
    "buttons": {
      "signUp": "Kaydol",
      "subscribePlan": "Plana Abone Ol",
      "currentPlan": "Mevcut Plan",
      "comingSoon": "YakÄ±nda",
      "downgradeToFree": "Ãœcretsiz Plana GeÃ§",
      "downgradeToCreator": "Creator PlanÄ±na GeÃ§",
      "contactSales": "SatÄ±ÅŸ Ekibiyle Ä°letiÅŸime GeÃ§"
    },
    "plans": {
      "free": {
        "name": "Ãœcretsiz",
        "description": "AraÃ§larÄ± test etmek ve hafif iÅŸler iÃ§in harika",
        "features": [
          "Filigran olmadan video indirme",
          "1 saat Ã¼cretsiz altyazÄ± iÅŸleme",
          "SRT dosyalarÄ±nÄ± dÄ±ÅŸa aktarma"
        ]
      },
      "creator": {
        "name": "Creator",
        "description": "DÃ¼zenli altyazÄ± ve hafif dublaj yapan kÃ¼Ã§Ã¼k iÃ§erik oluÅŸturucular iÃ§in ideal",
        "plusTitle": "Ãœcretsiz plandaki her ÅŸey, artÄ±:",
        "features": [
          "Dudak Senkronizasyonu",
          "Toplu iÅŸleme",
          "5 saat Ã¼cretsiz altyazÄ± iÅŸleme",
          "GÃ¶rev baÅŸÄ±na 30 dakikaya kadar"
        ]
      },
      "pro": {
        "name": "Pro",
        "description": "YakÄ±nda â€” YÃ¼ksek hacimli iÃ§erik oluÅŸturucular iÃ§in tasarlandÄ±",
        "plusTitle": "Creator planÄ±ndaki her ÅŸey, artÄ±:",
        "features": [
          "Ses gÃ¼zelleÅŸtirme ve gÃ¼rÃ¼ltÃ¼ giderme",
          "Ã–ncelik sÄ±rasÄ±",
          "GÃ¶rev baÅŸÄ±na 60 dakikaya kadar",
          "SÄ±nÄ±rsÄ±z altyazÄ± dakikasÄ±"
        ]
      },
      "enterprise": {
        "name": "Kurumsal",
        "description": "Ekipler, stÃ¼dyolar ve kurumsal iÅŸ akÄ±ÅŸlarÄ± iÃ§in",
        "customPricing": "Ã–zel",
        "unlimited": "SÄ±nÄ±rsÄ±z ğŸš",
        "tailoredSupport": "ve Ã¶zel destek",
        "plusTitle": "Pro planÄ±ndaki her ÅŸey, artÄ±:",
        "features": [
          "Ã–zel hesap yÃ¶neticisi",
          "Åirket iÃ§i kurulum seÃ§enekleri",
          "API eriÅŸimi ve kullanÄ±m analizleri",
          "Ã–zel entegrasyonlar ve SLA",
          "SÄ±nÄ±rsÄ±z iÅŸleme saatleri"
        ]
      }
    },
    "table": {
      "header": {
        "feature": "Ã–zellik / SÄ±nÄ±r"
      },
      "rows": {
        "videoDownloadWithWatermark": "FiligranlÄ± Video Ä°ndirme",
        "videoDownloadWithoutWatermark": "FiligransÄ±z Video Ä°ndirme",
        "downloadSrt": "SRT DosyasÄ±nÄ± Ä°ndir",
        "voiceBeautification": "Ses GÃ¼zelleÅŸtirme ve GÃ¼rÃ¼ltÃ¼ Giderme",
        "lipSync": "Dudak Senkronizasyonu",
        "subtitleTools": "AltyazÄ± AraÃ§larÄ± (ekle/kaldÄ±r, Ã§eviri yok)",
        "batchProcessing": "Toplu Ä°ÅŸleme",
        "maxVideoLength": "GÃ¶rev BaÅŸÄ±na Maksimum Video UzunluÄŸu",
        "monthlyCredits": "AylÄ±k Ãœcretsiz Krediler",
        "priorityQueue": "Ã–ncelik SÄ±rasÄ± / Daha HÄ±zlÄ± Ä°ÅŸleme",
        "creditTopUp": "Kredi YÃ¼kleme"
      },
      "values": {
        "free": "Ãœcretsiz",
        "unlimited": "SÄ±nÄ±rsÄ±z",
        "oneHourPerMonth": "1 saat/ay",
        "fiveHoursPerMonth": "5 saat/ay",
        "fiveMinutes": "5 dk",
        "thirtyMinutes": "30 dk",
        "sixtyMinutes": "60 dk"
      }
    }
  },
  "aeVsComfyUi": {
    "title": "AE vs ComfyUI â€“ Redefining Animation (Part 3)",
    "heading": "ğŸ¨ AE vs ComfyUI",
    "intro1": "We often get asked: why not just use After Effects (AE)? Or why bother with ComfyUI? Both are essential â€” one provides fine control, the other generative creativity.",
    "intro2": "AE offers timeline precision and control over transitions, lighting, and effects. ComfyUI brings AI-native workflows, combining diffusion, text, and multimodal orchestration.",
    "table": {
      "colAE": "AE",
      "colComfy": "ComfyUI",
      "row1a": "Precise VFX and motion control",
      "row1b": "AI-native generation of videos",
      "row2a": "Timeline-based editing",
      "row2b": "Workflow/node-based rendering",
      "row3a": "Manual / plugin-driven workflow",
      "row3b": "Diffusion + LLM + multimodal orchestration"
    },
    "outro": "In our workflow, ComfyUI handles the AI generation and iteration, while AE refines the final look â€” transitions, overlays, and compositing."
  },
  "video_translation_eval": {
    "title": "Evaluating AI Video Translation Quality",
    "subtitle": "Metrics that Matter",
    "intro": "Translating videos across languages is no small feat â€” it involves transcription, translation, voice synthesis, timing, and more. At Curify, weâ€™ve built a robust evaluation pipeline to ensure each piece meets industry standards.",
    "section1_title": "1. Transcription Quality",
    "section1_engine": "Engine: WhisperX",
    "section1_metrics": [
      "WER (Word Error Rate)",
      "Punctuation F1 (for expressiveness and readability)"
    ],
    "section2_title": "2. Translation Quality",
    "section2_engine": "Engines: Helsinki, MarianMT",
    "section2_metrics": [
      "BLEU (standard metric)",
      "COMET / chrF++ (semantic similarity)",
      "Human review: fluency + adequacy"
    ],
    "section3_title": "3. Voice Synthesis Quality",
    "section3_engine": "Engines: XTTS / YourTTS",
    "section3_metrics": [
      "MOS (Naturalness, similarity, expressiveness)",
      "Speaker verification accuracy"
    ],
    "section4_title": "4. Alignment & Lip Sync",
    "section4_metrics": [
      "Segment duration mismatch",
      "Wav2Lip sync confidence",
      "Temporal drift analysis"
    ],
    "section5_title": "5. Semantic Preservation",
    "section5_method": "We use LLMs (like GPT-4) to judge whether the translated speech preserves the original meaning, tone, and emotion. Example prompt:",
    "section5_prompt": "Compare this Mandarin transcript to the English voiceover. Does the tone, intent, and content match? Rate 1â€“5 and explain.",
    "section6_title": "6. User Feedback & GTM Validation",
    "section6_metrics": [
      "Voice quality fit for product category",
      "Viewer retention improvement",
      "Adoption willingness from early users (e.g., 1688 sellers)"
    ],
    "closing": "At Curify, we donâ€™t just translate â€” we preserve storytelling, emotion, and clarity across languages. If youâ€™re ready to scale your voice globally, get in touch.",
    "available_locales": "Post available in: [EN] [ZH] [ES] [DE]"
  },
  "storyboardToPipeline": {
    "title": "From Storyboards to AI Pipelines â€“ Redefining Animation",
    "intro": {
      "p1": "Most people think AI video means \"text in, clip out.\" But if you're aiming for <strong>cinematic, director-level control</strong>, it's an entirely different game.",
      "p2": "In traditional animation, every detail matters â€” character design, motion continuity, timing, and scene transitions. Our goal is to make AI match that level of precision.",
      "p3": "Animation today is both an art and a structured orchestration challenge. We think like directors, but build like engineers.",
      "p4": "That's why we build <strong>Controlled Generation Pipelines</strong> instead of one-shot generation. These pipelines combine structure and creativity:",
      "pipelineItems": [
        "Storyboard-to-Video: JSON-based scene specs with IDs, timing, and camera metadata",
        "ComfyUI-based workflows: node-graph DAGs with versioned checkpoints, LoRA stacks, and seeds",
        "Temporal & multimodal control: shared scene IDs across image, motion, audio, and subtitles"
      ],
      "p5": "Now, let's walk through a simple example to show how AI pipelines work in practice.",
      "technicalNotes": [
        "All stages read/write typed artifacts (JSON/CSV, PNG sequences, WAV/MP3, MP4, .aep)",
        "Pipelines are orchestrated via Python/CLI (e.g., ComfyUI API, ffmpeg, TTS APIs)",
        "Every run is reproducible through stored config (model, sampler, seed, prompts, duration)"
      ]
    },
    "pipeline": {
      "title": "AI Video Generation Pipeline",
      "description": "The AI video generation pipeline transforms text prompts into polished videos through structured stages with explicit inputs, outputs, and configs.",
      "prompt": "1. Prompt (raw idea â†’ structured JSON spec)",
      "storyboard": "2. Storyboard (scene/shot table with timing, camera, and description)",
      "images": "3. Images (per-shot keyframes generated via Stable Diffusion / ComfyUI)",
      "animation": "4. Animation (image sequences â†’ motion, parallax, and effects)",
      "voiceOver": "5. Voice Over (TTS + alignment data)",
      "finalVideo": "6. Final Video (ffmpeg composition: video + audio + subtitles)",
      "features": [
        "JSON-first design: every scene is addressable and scriptable (scene_id, shot_id)",
        "ComfyUI-based workflows: modular, reproducible, composable DAGs for image/video generation",
        "Temporal & multimodal control: consistent seeds, character embeddings, and timing across modalities"
      ],
      "exampleIntro": "Now, let's walk through a simple example to show how AI pipelines work in practice.",
      "artifacts": {
        "promptSpec": "prompt_run_001.json",
        "storyboardTable": "storyboard_v1.csv",
        "imageOutputDir": "renders/scene_{scene_id}/shot_{shot_id}/frame_####.png",
        "audioOutput": "audio/voiceover_final.wav",
        "subtitleFile": "subtitles/storyboard_v1.srt",
        "finalVideoFile": "exports/storyboard_v1_final.mp4"
      }
    },
    "steps": {
      "step1": {
        "title": "Step 1: Start with a Basic Prompt",
        "example": "A girl stands at a midnight train station, wind blowing her hair.",
        "expandedPrompt": "With the help of GPT or a local LLM, we expand this into a structured JSON object with global style, character definitions, and per-scene breakdown.",
        "technicalDetails": {
          "llmFields": [
            "global_style: art style, camera language, color palette",
            "characters: name, age, look, outfit, emotional state",
            "scenes: [{ scene_id, shot_id, description, camera_type, duration_seconds }]"
          ],
          "outputFile": "prompt_run_001.json",
          "exampleStack": "Python script calling OpenAI/LLM API and writing JSON to disk"
        }
      },
      "step2": {
        "title": "Step 2: Convert Prompt to a Storyboard Table",
        "description": "The JSON spec is flattened into a storyboard table (CSV or Notion) that both humans and the pipeline can read.",
        "technicalDetails": {
          "columns": [
            "scene_id",
            "shot_id",
            "start_time",
            "end_time",
            "duration_seconds",
            "camera_type",
            "visual_description",
            "character_state",
            "motion_notes"
          ],
          "storage": "storyboard_v1.csv (used as the single source of truth for downstream steps)",
          "automation": "Python / Node.js script transforms prompt_run_001.json â†’ storyboard_v1.csv"
        }
      },
      "step3": {
        "title": "ğŸ› ï¸ Step 3: Generate Visuals",
        "description": "Generate high-quality keyframe images for each shot using Stable Diffusion through a ComfyUI workflow.",
        "points": [
          "ğŸ¨ Use <strong>Stable Diffusion</strong> or <strong>ComfyUI</strong> to turn each row in `storyboard_v1.csv` into a high-res keyframe.",
          "Keep the style consistent by using the same base checkpoint, LoRA stack, sampler, and seed policy across all shots.",
          "Refine images with inpainting (for faces/hands) and outpainting (for extended compositions and camera motion)."
        ],
        "technicalDetails": {
          "modelConfig": {
            "checkpoint": "sd_xl_base_1.0.safetensors",
            "vae": "sdxl_vae.safetensors",
            "sampler": "euler_a",
            "steps": 25,
            "cfgScale": 6.5,
            "resolution": "1024x576",
            "loraStack": [
              "character_girl_v2.safetensors",
              "style_cinematic_blue_hour.safetensors"
            ]
          },
          "consistency": {
            "seedStrategy": "fixed_per_scene",
            "seedExample": "seed = hash(scene_id + character_name)",
            "namingConvention": "renders/scene_{scene_id}/shot_{shot_id}/kf_0001.png"
          },
          "comfyui": {
            "workflowFile": "workflows/storyboard_to_frame.json",
            "inputMethod": "custom node / HTTP API reading storyboard_v1.csv and modelConfig",
            "batching": "GPU batches keyed by scene_id to reuse loaded weights"
          }
        }
      },
      "step4": {
        "title": "ğŸ¬ Step 4: Add Motion and Atmosphere in After Effects",
        "description": "Enhance static keyframes with motion, parallax, and atmosphere using Adobe After Effects (or an equivalent compositor).",
        "points": [
          "Import image sequences or keyframes into <strong>Adobe After Effects</strong> as layered compositions.",
          "Apply keyframe animations: pan, zoom, parallax layers, fog overlays, glow and light flicker.",
          "Add ambient sound cues and cinematic transitions between scenes."
        ],
        "technicalDetails": {
          "input": "renders/scene_{scene_id}/shot_{shot_id}/kf_0001.png (plus optional depth/alpha maps)",
          "projectFile": "ae/storyboard_v1.aep",
          "automation": [
            "Use AE scripts/ExtendScript or JSX to auto-create comps per scene_id.",
            "Map `duration_seconds` from storyboard_v1.csv â†’ comp duration.",
            "Generate intermediate frames via AE plugins or video-aware diffusion tools if needed."
          ],
          "output": "ae_renders/scene_{scene_id}_shot_{shot_id}_anim.mp4"
        }
      },
      "step5": {
        "title": "ğŸ§ Step 5: Add Voice and Subtitles",
        "description": "Generate voiceover aligned to the storyboard and attach subtitles for accessibility and clarity.",
        "points": [
          "Use <strong>XTTS</strong> or <strong>ElevenLabs</strong> to generate natural voiceovers from the script, using a consistent speaker profile.",
          "For acronyms (like API, NBA), generate English snippets separately and merge in post to keep pronunciation clean.",
          "Add subtitles using `.srt` or `.json` timeline files synced to the voiceover track."
        ],
        "technicalDetails": {
          "scriptSource": "dialogue and narration pulled from prompt_run_001.json + storyboard_v1.csv",
          "ttsConfig": {
            "engine": "XTTS or ElevenLabs",
            "voiceId": "cinematic_female_en",
            "sampleRate": 44100,
            "format": "wav"
          },
          "outputs": {
            "voiceFile": "audio/storyboard_v1_voiceover.wav",
            "subtitleFile": "subtitles/storyboard_v1.srt"
          },
          "syncStrategy": "align `start_time` / `end_time` from storyboard_v1.csv with subtitle cues; ensure total audio length â‰ˆ final timeline duration"
        }
      },
      "step6": {
        "title": "Step 6: Final Composition with FFMPEG",
        "description": "Use FFMPEG to combine all pieces into one final video file with audio and subtitles.",
        "technicalDetails": {
          "inputs": {
            "video": "ae_renders/storyboard_v1_timeline.mp4",
            "audio": "audio/storyboard_v1_voiceover.wav",
            "subtitles": "subtitles/storyboard_v1.srt"
          },
          "ffmpegExample": "ffmpeg -i storyboard_v1_timeline.mp4 -i storyboard_v1_voiceover.wav -c:v libx264 -c:a aac -shortest -vf subtitles=subtitles/storyboard_v1.srt exports/storyboard_v1_final.mp4",
          "output": "exports/storyboard_v1_final.mp4 (H.264, 24 fps, AAC audio)"
        }
      }
    },
    "whatYouNeed": "ğŸ“ What You'll Need",
    "whatYouNeedTechnical": [
      "GPU with at least 12GB VRAM for Stable Diffusion / ComfyUI",
      "Python environment for JSON/CSV transforms and automation scripts",
      "ComfyUI installed with required custom nodes and workflows",
      "Adobe After Effects or similar compositor for motion and FX",
      "XTTS / ElevenLabs API access for TTS",
      "ffmpeg installed and available on the command line"
    ],
    "cta": "ğŸš€ Ready to bring your storyboard to life with AI? <strong>We can provide a full starter kit</strong> with example JSONs, ComfyUI workflows, and ffmpeg/AE templates to help you get started."
  },
  "SceneDetection": {
    "tags": {
      "computerVision": "Computer Vision",
      "deepLearning": "Deep Learning",
      "realTimeAnalysis": "Real-time Analysis"
    },
    "hero": {
      "title": "Transform Video into Storyboards with AI",
      "subtitle": "How we built an advanced pipeline that turns hours of footage into structured, searchable storyboards in minutes."
    },
    "introduction": {
      "paragraph1": "Imagine being able to upload hours of raw footage and within minutes get a <strong>detailed, scene-by-scene breakdown</strong> of your entire video. That's exactly what our AI-powered scene detection system delivers.",
      "paragraph2": "Built with cutting-edge Python libraries and deep learning models, this pipeline doesn't just detect scene changesâ€”it understands the content, identifies key elements, and structures everything into a comprehensive storyboard."
    },
    "imageAlt": "The scene detection pipeline in action, identifying key moments and generating structured storyboards",
    "protip": "For optimal results, ensure your video has clear visual separation between scenes. The system works best with well-lit footage and minimal motion blur. Consider adding chapter markers or scene breaks in your video editor to improve detection accuracy.",
    "humanEvaluation": {
      "title": "Human Evaluation of AI Output",
      "introduction": "While our AI pipeline is highly accurate, human evaluation remains a critical component of our quality assurance process. Here's how we ensure the highest quality output:",
      "evaluationAreas": [
        "<strong>Scene Boundary Accuracy</strong> - Reviewing and adjusting scene transition points",
        "<strong>Metadata Validation</strong> - Verifying AI-generated descriptions, tags, and labels",
        "<strong>Consistency Check</strong> - Ensuring uniform style and formatting across all scenes",
        "<strong>Content Accuracy</strong> - Validating that the AI correctly identified key elements in each scene"
      ],
      "workflow": {
        "title": "Human-in-the-Loop Workflow",
        "steps": [
          "AI processes the video and generates initial storyboard",
          "Human reviewers evaluate the AI output using our specialized tools",
          "Reviewers provide feedback and make necessary adjustments",
          "System learns from human corrections to improve future outputs",
          "Final quality check before delivery"
        ]
      },
      "benefits": {
        "title": "Benefits of Human Evaluation",
        "items": [
          "<strong>Higher Accuracy</strong> - Human reviewers catch subtle nuances that AI might miss",
          "<strong>Contextual Understanding</strong> - Better interpretation of cultural and situational context",
          "<strong>Quality Assurance</strong> - Additional layer of validation for professional use cases",
          "<strong>Continuous Improvement</strong> - Human feedback helps train and refine the AI models"
        ]
      },
      "tools": {
        "title": "Evaluation Tools",
        "description": "Our platform includes specialized tools to assist human reviewers:",
        "features": [
          "Side-by-side video and storyboard comparison",
          "Easy-to-use interface for adjusting scene boundaries",
          "Bulk editing of metadata and tags",
          "Collaboration features for team review",
          "Version history and change tracking"
        ]
      }
    },
    "header": {
      "title": "From Raw Footage to Storyboards",
      "author": "Curify AI Team",
      "role": "AI Research Team",
      "imageAlt": "AI analyzing video scenes and generating storyboards",
      "imageCaption": "AI-powered scene detection in action, identifying key moments in video content",
      "subtitle": "AI-Powered Video Analysis",
      "date": "December 11, 2025",
      "readingTime": "8 min read"
    },
    "Technical": {
      "title": "TECHNICAL DEEP DIVE",
      "steps": {
        "step1": "How It Works: Under the Hood",
        "videoProcessingPipeline": "Our system processes videos through a sophisticated multi-stage pipeline that ensures accurate scene detection and analysis:",
        "step2": "Video Processing Pipeline",
        "step2Text": "Our system processes videos through a sophisticated multi-stage pipeline that ensures accurate scene detection and analysis:",
        "step3": "Scene Detection and Metadata Extraction",
        "step3Text": "OpenCV-powered frame sampling at optimal intervals",
        "step4": "Shot Analysis and Metadata Enhancement",
        "step4Text": "Adaptive thresholding for precise scene boundary detection",
        "step5": "Scene Labeling and Metadata Organization",
        "step5Text": "Deep learning models for comprehensive scene understanding",
        "step6": "Metadata Export and Integration",
        "step6Text": "Export metadata to JSON format for integration with other tools"
      }
    },
    "featuresTitle": "Powerful Features at Your Fingertips",
    "features1": "Seamless Video Integration",
    "features1Text": "Process local files, YouTube links, or cloud storage with our unified interface.",
    "features": {
      "modularArchitecture": {
        "title": "Modular Architecture",
        "description": "The system is built with separate components for video analysis, AI processing, and output generation, making it easy to extend and maintain."
      },
      "performance": {
        "title": "Performance Optimized",
        "description": "Efficient frame processing and parallelization ensure fast analysis even for long videos."
      },
      "aiEnhanced": {
        "title": "AI-Enhanced Analysis",
        "description": "Optional AI components provide deeper scene understanding and more accurate labeling."
      }
    },
    "features2": "Seamless Video Integration",
    "features2Text": "Process local files, YouTube links, or cloud storage with our unified interface.",
    "features3": "AI-Powered Analysis",
    "features3Text": "Enhance scene understanding with our optional AI analysis module.",
    "features4": "Camera Motion Detection",
    "features4Text": "Automatically identify pans, zooms, and other camera movements.",
    "features5": "Customizable Output",
    "features5Text": "Export metadata to JSON format for integration with other tools.",
    "intro": {
      "p1": "In today's fast-paced content creation landscape, <strong>efficient video analysis</strong> is no longer a luxuryâ€”it's a necessity. Our AI-powered scene detection technology transforms hours of raw footage into structured, searchable content in minutes, not days.",
      "p2": "Whether you're a filmmaker, content creator, or media professional, understanding the power of automated scene detection can revolutionize your workflow and unlock new creative possibilities."
    },
    "proTip": "For best results, ensure your source video has clear audio and visual separation between scenes. Well-lit environments and minimal background noise significantly improve detection accuracy.",
    "titanicExample": {
      "title": "Real-World Example: Titanic Scene Analysis",
      "description": "Watch how our system analyzes a scene from Titanic, detecting shot changes and generating detailed scene metadata:",
      "analysis": "Analysis:",
      "analysisText": "Scene detection and metadata extraction in real-time"
    },
    "inceptionExample": {
      "title": "Dream Level Analysis: Inception Scene Breakdown",
      "description": "Explore how our AI analyzes the complex dream layers and visual effects in Inception:",
      "analysis": "Analysis",
      "analysisText": "Dream layer detection and visual effect breakdown",
      "breakdownTitle": "Scene Analysis Breakdown",
      "showFullAnalysis": "Show Full Scene Analysis",
      "hideFullAnalysis": "Hide Full Scene Analysis",
      "fullSceneAnalysis": "Full Scene Analysis",
      "sceneCard": {
        "mood": "Mood",
        "environment": "Environment",
        "shotNotes": "Shot Notes"
      }
    },
    "Scene": "Scene",
    "process": {
      "title": "How Our Scene Detection Works",
      "steps": {
        "step1": {
          "title": "1. Video Analysis",
          "description": "Our AI scans your video frame by frame, analyzing visual and audio cues to identify potential scene boundaries.",
          "details": [
            "Analyzes color histograms and motion vectors",
            "Detects audio level changes and silences",
            "Identifies shot boundaries and transitions"
          ]
        },
        "step2": {
          "title": "2. Scene Segmentation",
          "description": "The system groups related shots into coherent scenes based on visual and temporal relationships.",
          "details": [
            "Uses machine learning to understand scene context",
            "Considers shot duration and transition types",
            "Merges related shots into logical scenes"
          ]
        },
        "step3": {
          "title": "3. Content Classification",
          "description": "Each detected scene is analyzed and categorized based on its visual and audio content.",
          "details": [
            "Identifies key visual elements and objects",
            "Classifies scene type (e.g., interview, action, landscape)",
            "Analyzes audio for speech, music, and effects"
          ]
        },
        "step4": {
          "title": "4. Metadata Generation",
          "description": "Comprehensive metadata is generated for each scene, enabling powerful search and organization.",
          "details": [
            "Creates timestamps and duration information",
            "Generates representative thumbnails",
            "Extracts key dialogue and audio cues"
          ]
        }
      }
    },
    "whyItWorks": {
      "title": "Why Our Scene Detection Works So Well",
      "points": "<li>Our AI analyzes both <strong>visual and audio cues</strong> to identify scene boundaries with over 95% accuracy.</li><li>Advanced <strong>machine learning models</strong> understand context, not just visual changes, for more natural scene detection.</li><li>Real-time processing allows for <strong>immediate feedback</strong> and adjustments during filming or editing.</li>"
    },
    "recommendedStyle": {
      "title": "Recommended Style for Best Results",
      "description": "To get the most accurate scene detection, we recommend the following style guidelines:",
      "points": [
        "Maintain consistent lighting within each scene",
        "Use clear audio markers or clapperboards between takes",
        "Keep camera movements smooth and intentional",
        "Maintain consistent audio levels within scenes"
      ]
    },
    "title": "From Raw Footage to Storyboards: AI-Powered Video Analysis",
    "description": "Discover how AI transforms raw video into structured storyboards with automated scene detection and analysis.",
    "timeline": {
      "title": "Scene Timeline",
      "viewScene": "View Scene {1}"
    },
    "cta": "ğŸš€ Ready to bring your storyboard to life with AI? <strong>We can provide a full starter kit</strong> with example JSONs, ComfyUI workflows, and ffmpeg/AE templates to help you get started.",
    "sceneBreakdown": {
      "title": "Understanding Scene Detection Output",
      "introduction": "Let's break down a typical scene detection output to understand how our AI analyzes and structures video content. Below each explanation, you'll find the corresponding JSON structure that powers these insights.",
      "scenes": [
        {
          "title": "1. Scene Identification",
          "content": "Each scene is assigned a unique identifier and timestamp range, allowing for precise navigation through the video content. This forms the foundation of our analysis.",
          "example": "Scene 1 (00:00:02.50 - 00:00:05.20)",
          "jsonExample": {
            "scene_id": "scene_001",
            "start_time": 2.5,
            "end_time": 5.2,
            "duration": 2.7,
            "keyframe_index": 5,
            "keyframe_time": 3.8
          },
          "jsonDescription": "This JSON structure shows the basic identification data for a scene, including its unique ID, timing information, and the index/time of its representative keyframe."
        },
        {
          "title": "2. Visual Analysis",
          "content": "Our AI examines keyframes to understand the visual composition of each scene, including dominant colors, lighting conditions, and visual elements.",
          "example": "Keyframe analysis: Outdoor, daylight, multiple subjects",
          "jsonExample": {
            "visual_analysis": {
              "brightness": 0.78,
              "contrast": 0.65,
              "color_palette": [
                "#3A5FCD",
                "#87CEEB",
                "#F5F5DC"
              ],
              "dominant_colors": [
                {
                  "color": "#3A5FCD",
                  "percentage": 0.45
                },
                {
                  "color": "#87CEEB",
                  "percentage": 0.35
                },
                {
                  "color": "#F5F5DC",
                  "percentage": 0.2
                }
              ],
              "lighting_condition": "daylight",
              "environment": "outdoor",
              "detected_objects": [
                {
                  "label": "person",
                  "confidence": 0.97,
                  "count": 2
                },
                {
                  "label": "sky",
                  "confidence": 0.99,
                  "count": 1
                }
              ]
            }
          },
          "jsonDescription": "This JSON shows the visual analysis data, including color information, lighting conditions, and detected objects with confidence scores."
        },
        {
          "title": "3. Shot Composition",
          "content": "Within each scene, we identify individual shots and their transitions, helping understand the visual flow and pacing of the content.",
          "example": "3 shots detected with smooth cuts and one cross-fade",
          "jsonExample": {
            "shots": [
              {
                "shot_id": "shot_001",
                "start_time": 2.5,
                "end_time": 3.1,
                "transition": {
                  "type": "cut",
                  "confidence": 0.98
                },
                "camera_motion": {
                  "type": "static",
                  "confidence": 0.92
                }
              },
              {
                "shot_id": "shot_002",
                "start_time": 3.1,
                "end_time": 4.3,
                "transition": {
                  "type": "fade",
                  "duration": 0.3,
                  "confidence": 0.95
                },
                "camera_motion": {
                  "type": "pan_left",
                  "confidence": 0.88
                }
              }
            ]
          },
          "jsonDescription": "This JSON structure details the shot composition within a scene, including timing, transition types, and camera motion analysis."
        },
        {
          "title": "4. Content Classification",
          "content": "Scenes are automatically categorized based on their content, making it easy to find specific types of footage later.",
          "example": "Category: Drama, Setting: Ship Deck, Subjects: Main Characters",
          "jsonExample": {
            "content_analysis": {
              "primary_category": "drama",
              "secondary_categories": [
                "romance",
                "disaster"
              ],
              "setting": {
                "type": "ship_deck",
                "time_of_day": "night",
                "confidence": 0.92
              },
              "subjects": [
                {
                  "type": "main_character",
                  "name": "Jack",
                  "position": "center_frame",
                  "emotion": "determined",
                  "confidence": 0.89
                },
                {
                  "type": "main_character",
                  "name": "Rose",
                  "position": "center_frame",
                  "emotion": "fearful",
                  "confidence": 0.91
                }
              ],
              "sentiment": {
                "overall": "intense_dramatic",
                "confidence": 0.88,
                "emotions": [
                  "fear",
                  "determination",
                  "urgency"
                ]
              },
              "key_elements": [
                "lifeboat",
                "ocean",
                "moonlight"
              ],
              "narrative_importance": 0.95,
              "action_required": true
            }
          },
          "jsonDescription": "This JSON shows how the AI analyzes and classifies movie scenes, including character emotions, setting details, and narrative importance, with Titanic's dramatic lifeboat scene as an example."
        }
      ],
      "analysisTitle": "Putting It All Together",
      "analysisContent": "By combining these elements, our system creates a comprehensive map of your video content. This structured data powers features like intelligent search, automated editing, and content analysis.",
      "fullExampleTitle": "Complete Scene Data Example",
      "fullExampleDescription": "Here's how all the pieces come together in a complete scene analysis:",
      "fullExample": {
        "scene_id": "scene_001",
        "start_time": 2.5,
        "end_time": 5.2,
        "duration": 2.7,
        "metadata": {
          "created_at": "2025-12-11T14:25:30Z",
          "video_source": "interview_001.mp4",
          "resolution": "1920x1080",
          "fps": 30
        },
        "visual_analysis": {
          "brightness": 0.78,
          "contrast": 0.65,
          "color_palette": [
            "#3A5FCD",
            "#87CEEB",
            "#F5F5DC"
          ],
          "lighting_condition": "daylight",
          "environment": "studio"
        },
        "audio_analysis": {
          "has_speech": true,
          "speech_confidence": 0.92,
          "background_noise_level": 0.15,
          "speaker_gender": [
            "male",
            "female"
          ],
          "speech_text": "Let's discuss how AI is transforming video production..."
        },
        "content_analysis": {
          "primary_category": "interview",
          "setting": "studio",
          "subjects": [
            "host",
            "guest"
          ],
          "sentiment": "neutral_positive"
        },
        "shots": [
          {
            "shot_id": "shot_001",
            "start_time": 2.5,
            "end_time": 3.1,
            "keyframe": "https://example.com/keyframes/scene_001_shot_001.jpg",
            "transition": {
              "type": "cut",
              "confidence": 0.98
            }
          },
          {
            "shot_id": "shot_002",
            "start_time": 3.1,
            "end_time": 5.2,
            "keyframe": "https://example.com/keyframes/scene_001_shot_002.jpg",
            "transition": {
              "type": "fade",
              "confidence": 0.95
            }
          }
        ]
      },
      "benefitsTitle": "Key Benefits",
      "benefits": [
        "<strong>Efficient Editing:</strong> Jump directly to any scene or shot without scrubbing through hours of footage",
        "<strong>Smart Search:</strong> Find content based on visual elements, not just metadata",
        "<strong>Consistent Quality:</strong> Identify and maintain visual consistency across your project",
        "<strong>Data-Driven Decisions:</strong> Get insights into your content structure and pacing"
      ]
    },
    "conclusion": {
      "title": "Transforming Video Production with AI",
      "p1": "AI-powered scene detection is revolutionizing how we approach video production. By automating the tedious process of scene identification and organization, creators can focus on what truly matters â€“ telling compelling stories. Our technology bridges the gap between raw footage and polished content, making professional-grade video analysis accessible to everyone.",
      "p2": "As we continue to refine our algorithms and expand our capabilities, we're excited to see how filmmakers, educators, and content creators will leverage these tools to push the boundaries of visual storytelling. The future of video production is here, and it's more efficient and creative than ever before."
    },
    "richStructuredOutput": "Rich, Structured Output",
    "richStructuredOutputText": "Our system generates comprehensive storyboard data with detailed metadata for each scene, giving you complete control over your video content.",
    "advancedUsage": {
      "title": "Advanced Usage & Customization",
      "description": "The scene detection system is highly customizable to fit different use cases. Here are some advanced features and customization options:",
      "features": {
        "thresholds": {
          "title": "Custom Scene Detection Thresholds",
          "description": "Adjust the sensitivity of scene detection by modifying the threshold parameter. Lower values make the detection more sensitive to changes."
        },
        "aiAnalysis": {
          "title": "AI-Enhanced Analysis",
          "description": "Enable AI analysis for more detailed scene understanding and labeling. This requires additional setup with the Ollama server."
        },
        "outputCustomization": {
          "title": "Output Customization",
          "description": "Customize the output format and include additional metadata in the generated storyboard."
        }
      },
      "integration": {
        "title": "Integration with Other Tools",
        "description": "The storyboard output can be easily integrated with other tools and workflows. Here are some examples:",
        "tools": {
          "editingSoftware": {
            "title": "Video Editing Software",
            "description": "Import the JSON output into video editors that support script-based editing"
          },
          "cms": {
            "title": "Content Management Systems",
            "description": "Automatically generate metadata for video assets"
          },
          "aiTraining": {
            "title": "AI Training Data",
            "description": "Use the structured output as training data for machine learning models"
          }
        }
      }
    },
    "Benefitss": {
      "title": "Benefits",
      "description": "The benefits of using our AI-powered scene detection system include:",
      "tags": {
        "computerVision": "Computer Vision",
        "deepLearning": "Deep Learning",
        "realTimeAnalysis": "Real-time Analysis"
      },
      "features": {
        "modularArchitecture": {
          "title": "Modular Architecture",
          "description": "The system is built with separate components for video analysis, AI processing, and output generation, making it easy to extend and maintain."
        },
        "performance": {
          "title": "Performance Optimized",
          "description": "Efficient frame processing and parallelization ensure fast analysis even for long videos."
        },
        "aiEnhanced": {
          "title": "AI-Enhanced Analysis",
          "description": "Optional AI components provide deeper scene understanding and more accurate labeling."
        }
      }
    },
    "benefits": {
      "subtitle": "WHY CHOOSE OUR SOLUTION",
      "title": "The Power of AI-Powered Scene Analysis"
    },
    "integration": {
      "title": "Easy Integration",
      "description": "The structured JSON output makes it easy to integrate with other tools and workflows:",
      "technologies": [
        "Python",
        "JavaScript",
        "Node.js",
        "React",
        "Vue"
      ]
    },
    "features10": {
      "comprehensiveData": {
        "title": "Comprehensive Scene Data",
        "items": [
          "Precise timing information for each scene",
          "Key frames for visual reference",
          "Object detection results",
          "Camera movement analysis"
        ]
      },
      "export": {
        "title": "Export Option",
        "formats": {
          "json": "JSON"
        }
      }
    },
    "performance": {
      "title": "Performance Optimized",
      "features": {
        "speed": "5-10x faster than real-time",
        "memory": "Low memory footprint",
        "parallel": "Parallel processing"
      }
    }
  },
  "aiPlatform": {
    "title": "Orta Ã–lÃ§ekli Åirketler iÃ§in Yapay Zeka BaÅŸarÄ± Rehberi",
    "subtitle": "BÃ¼tÃ§eyi Zorlamadan Ã–lÃ§eklenebilir Bir Yapay Zeka Platformu NasÄ±l Kurulur?",
    "intro": {
      "p1": "KÃ¼Ã§Ã¼k ve orta Ã¶lÃ§ekli teknoloji ÅŸirketlerinde asÄ±l avantaj, bÃ¼yÃ¼k modeller eÄŸitmek deÄŸil, herkesin akÄ±llÄ± Ã¶zellikler geliÅŸtirebildiÄŸi bir yapay zeka platformu inÅŸa etmektir. Ä°ÅŸte Ã§evikliÄŸi etkiye dÃ¶nÃ¼ÅŸtÃ¼rme yÃ¶nteminiz.",
      "p2": "Ä°ÅŸte finans, hukuk, mÃ¼ÅŸteri hizmetleri ve mÃ¼hendislik alanlarÄ±nda yapay zekayÄ± gÃ¼Ã§lendirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z, bÃ¼tÃ§eyi zorlamadan veya 50 ML uzmanÄ± iÅŸe almadan uygulanabilir, Ã¼retim hazÄ±rÄ± bir plan."
    },
    "imageAlt": "Yapay Zeka Platformu Mimarisi ÅemasÄ±",
    "heading": "ğŸ—ï¸ Orta Ã–lÃ§ekli Åirketler iÃ§in Yapay Zeka BaÅŸarÄ± Rehberi",
    "mindsetShift": {
      "title": "1. Zihniyet DeÄŸiÅŸimi: MerkezileÅŸtirmeyin, DemokratikleÅŸtirin",
      "content": "EÄŸer yapay zeka ekibiniz bir darboÄŸam haline geldiyse, zaten kaybettiniz demektir. Bunun yerine, Ã¼rÃ¼n mÃ¼hendislerinin ihtiyaÃ§ duyduklarÄ±nÄ± inÅŸa edebilecekleri kendi kendine yeten bir yapay zeka altyapÄ±sÄ± oluÅŸturun.",
      "goal": "AmaÃ§: Alan uzmanlarÄ±nÄ±n (finans, hukuk, destek mÃ¼hendisleri) minimum ML bilgisiyle yapay zeka Ã§Ã¶zÃ¼mleri oluÅŸturabilmesini saÄŸlayÄ±n.",
      "reality": "GerÃ§ek: Yapay zeka ekibi otoyolu inÅŸa eder; iÅŸ ekipleri arabalarÄ± kullanÄ±r.",
      "supportModel": {
        "title": "Destek modeli:",
        "l1": "Seviye 1 â€” Self Servis: GeliÅŸtiriciler kendi Ã¶zelliklerini oluÅŸturmak iÃ§in platform araÃ§larÄ±nÄ± kullanÄ±r.",
        "l2": "Seviye 2 â€” DanÄ±ÅŸmanlÄ±k & DanÄ±ÅŸmanlÄ±k: Yapay zeka ekibi, istem tasarÄ±mÄ±, deÄŸerlendirme ve mimari konularÄ±nda yardÄ±mcÄ± olur.",
        "l3": "Seviye 3 â€” Birlikte GeliÅŸtirme: KarmaÅŸÄ±k, yÃ¼ksek etkili MVP'leri birlikte oluÅŸturun."
      },
      "conclusion": "Bu, yapay zekayÄ± bir araÅŸtÄ±rma projesinden iÅŸ Ã§arpanÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."
    },
    "stack": {
      "title": "2. Teknoloji YÄ±ÄŸÄ±nÄ±: Basit ve AÃ§Ä±k KayÄ±rlÄ± Tutun",
      "intro": "AÅŸÄ±rÄ± mÃ¼hendislik hÄ±zÄ±nÄ±zÄ± keser. Sizi kilitlemeden karmaÅŸÄ±klÄ±ÄŸÄ± soyutlayan Ã¼Ã§ katmanlÄ± bir platform oluÅŸturduk.",
      "gateway": {
        "title": "A. BirleÅŸik Model AÄŸ GeÃ§idi",
        "content": "Tek bir satÄ±cÄ±ya baÄŸlÄ± kalmayÄ±n. Ä°stekleri sorunsuz bir ÅŸekilde yÃ¶nlendirin:",
        "points": [
          "Ticari BÃ¼yÃ¼k Dil Modelleri (GPT-4, Claude vb.) â€” Ã¼st dÃ¼zey akÄ±l yÃ¼rÃ¼tme iÃ§in.",
          "Ã–zel Modeller (Llama, Qwen) â€” hassas veriler ve maliyet kontrolÃ¼ iÃ§in.",
          "Uzman Modeller â€” kodlama, gÃ¶rÃ¼ntÃ¼ iÅŸleme veya dÃ¼ÅŸÃ¼k gecikme sÃ¼reli gÃ¶revler iÃ§in."
        ],
        "conclusion": "AÄŸ geÃ§idi, yeniden denemeleri, yedeklemeleri, maliyet takibini ve hÄ±z sÄ±nÄ±rlarÄ±nÄ± yÃ¶netir â€” bÃ¶ylece geliÅŸtiriciler sadece `platform.generate()` Ã§aÄŸrÄ±sÄ± yapar."
      },
      "knowledge": {
        "title": "B. Hizmet Olarak Bilgi (RAG BasitleÅŸtirildi)",
        "content": "Bilgiyle GÃ¼Ã§lendirilmiÅŸ Ãœretim, iÅŸ deÄŸerinin bÃ¼yÃ¼k kÄ±smÄ±nÄ± oluÅŸturur. Ancak mÃ¼hendisler vektÃ¶r veritabanlarÄ±nÄ± yÃ¶netmemelidir.",
        "solution": "'BÄ±rak ve sohbet et' arayÃ¼zÃ¼ oluÅŸturun: bir wiki'yi, PDF'leri veya veritabanÄ±nÄ± iÅŸaretleyin ve platform otomatik olarak iÃ§e aktarÄ±r, bÃ¶ler, gÃ¶mÃ¼ler ve indeksler. ArtÄ±k her ekibin gÃ¼ncel, Ã¶zel bir bilgi tabanÄ± var."
      },
      "orchestration": {
        "title": "C. Orkestrasyon KatmanÄ±",
        "content": "Kod-Ã¶ncelikli yapay zeka gÃ¼Ã§lÃ¼dÃ¼r; ancak iÅŸ akÄ±ÅŸÄ±-Ã¶ncelikli yapay zeka daha hÄ±zlÄ±dÄ±r.",
        "example": "AdÄ±mlarÄ± zincirlemek iÃ§in dÃ¼ÅŸÃ¼k kodlu araÃ§lar (Dify, coze, n8n gibi) kullanÄ±yoruz:",
        "workflow": [
          "KullanÄ±cÄ± sorusu",
          "Belgeleri getir",
          "AraÃ§ Ã§aÄŸÄ±r (API, SQL)",
          "AkÄ±l yÃ¼rÃ¼t",
          "Ã‡Ä±ktÄ±"
        ],
        "conclusion": "Bu, Ã¼rÃ¼n ekiplerinin haftalar deÄŸil, saatler iÃ§inde ajan prototipleri oluÅŸturmasÄ±nÄ± saÄŸlar."
      }
    },
    "fineTuning": {
      "title": "3. Ä°nce Ayardan KaÃ§Ä±nÄ±n (Ã‡oÄŸu Zaman)",
      "content": "Ä°ÅŸte sÄ±r: **bÃ¼yÃ¼k olasÄ±lÄ±kla bir bÃ¼yÃ¼k dil modelini ince ayarlamanÄ±za gerek yok.**",
      "strategies": [
        "Daha iyi istemler: sistematik mÃ¼hendislik rastgele ayarlamalarÄ± yener.",
        "YÃ¼ksek kaliteli RAG: temiz, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi, daha akÄ±llÄ± bir modelden daha iyidir.",
        "Ã‡oklu model fÃ¼zyonu: akÄ±l yÃ¼rÃ¼tme iÃ§in GPT-4, Ã§Ä±karma iÃ§in yerel bir model, yaratÄ±cÄ± gÃ¶revler iÃ§in Claude kullanÄ±n.",
        "Hakem olarak LLM: daha gÃ¼Ã§lÃ¼ bir modeli, daha ucuz modellerin Ã§Ä±ktÄ±larÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±n."
      ],
      "conclusion": "YalnÄ±zca dar, yÃ¼ksek hacimli gÃ¶revler iÃ§in kÃ¼Ã§Ã¼k modelleri ince ayarlÄ±yoruz ve bu da yÃ¼ksek kaliteli, alana Ã¶zgÃ¼ veri toplama ve temizleme sÃ¼recinden sonra geliyor. Geri kalan her ÅŸey 'eÄŸitim yerine mÃ¼hendislik' ile Ã§Ã¶zÃ¼lÃ¼yor."
    },
    "essentialWork": {
      "title": "5. Az Ä°lgi Ã‡eken, Ancak Temel Ä°ÅŸler",
      "content": "En iyi platformlar sadece modellere dayanmaz. SÄ±kÄ±cÄ±, zor problemleri Ã§Ã¶zmeye dayanÄ±r:",
      "points": [
        {
          "title": "Veri Ã‡arkÄ±",
          "content": "Ãœretim kullanÄ±mÄ±ndan Ã¶ÄŸrenip kaydedemezseniz, modelleriniz geliÅŸmez. Uyumlu, anonimleÅŸtirilmiÅŸ veri boru hatlarÄ±nÄ± etkinleÅŸtirmek iÃ§in gÃ¼venlik ekibiyle erken Ã§alÄ±ÅŸÄ±n."
        },
        {
          "title": "Hissiyat DeÄŸil, DeÄŸerlendirme",
          "content": "Ä°ÅŸ sahiplerinden 'altÄ±n veri setleri' talep edin â€” gerÃ§ek soru-cevap Ã§iftleri â€” bÃ¶ylece sadece 'iyi gÃ¶rÃ¼nÃ¼yor' demek yerine hassasiyet/duyarlÄ±lÄ±k Ã¶lÃ§ebilirsiniz."
        },
        {
          "title": "Hesaplama KaynaklarÄ±",
          "content": "Ã‡Ä±karÄ±m, CPU Ã§alÄ±ÅŸtÄ±rmak gibi deÄŸildir. Bellek taÅŸmasÄ± hatalarÄ±nÄ± Ã¶nlemek ve kullanÄ±mÄ± optimize etmek iÃ§in Ã¶zel izleme gerekir."
        }
      ]
    },
    "conclusion": {
      "title": "SonuÃ§",
      "content": "Orta Ã¶lÃ§ekli teknoloji ÅŸirketleri iÃ§in yapay zekada kazanmak, daha iyi bir bÃ¼yÃ¼k dil modeli oluÅŸturmak anlamÄ±na gelmez. Yapay zekayÄ± tekrarlanabilir, Ã¶lÃ§eklenebilir bir iÅŸ sÃ¼recine dÃ¶nÃ¼ÅŸtÃ¼ren bir platform inÅŸa etmek anlamÄ±na gelir.",
      "finalThoughts": "AltyapÄ±yla baÅŸlayÄ±n, veriyi gÃ¼venceye alÄ±n ve ekiplerinizin inÅŸa etmesine izin verin. Gelecek, hepsine hÃ¼kmeden tek bir model deÄŸil, her biri gerÃ§ek bir iÅŸ problemini Ã§Ã¶zen, hepsi de bunu basitleÅŸtiren bir platform tarafÄ±ndan desteklenen uzmanlaÅŸmÄ±ÅŸ ajanlar filosudur.",
      "callToAction": "Ä°nÅŸa etmeye hazÄ±r mÄ±sÄ±nÄ±z? Basit ve aÃ§Ä±k kaynaklÄ± tutun ve baÅŸkalarÄ±nÄ± gÃ¼Ã§lendirmeye odaklanÄ±n."
    }
  },
  "nanoBananaProPrompts": {
    "title": "Nano Banana Pro Prompts",
    "description": "Discover a collection of creative and effective prompts for your AI content generation needs. These prompts are designed to help you get the most out of your AI tools.",
    "prompts": {
      "title": "Popular Nano Banana Pro Prompts",
      "prompt1": "Create a short story about a futuristic city where emotions are currency",
      "prompt2": "Generate a dialogue between two characters meeting for the first time in a coffee shop",
      "prompt3": "Write a product description for an innovative AI-powered kitchen gadget"
    }
  },
  "qaBotToTaskAgent": {
    "heading": "ğŸ—ï¸ From QA Bot to Task Agent: An Architecture Guide",
    "description": "Learn how to build reliable task agents that go beyond simple question answering",
    "tldr": "TL;DR: Stop building chatbots that just answer questions. Start building Task Agents that actually do work.",
    "intro": "This guide explains the architectural shift from monolithic QA bots to Task Agents using Static Rules, Dynamic Skills, and Deterministic Hooksâ€”with concrete code examples and open-source references.",
    "coreShift": {
      "title": "1. The Core Shift: QA Bot â†’ Task Agent",
      "content": [
        "Most AI systems today are still context-stuffed QA bots:",
        "â€¢ They answer questions well",
        "â€¢ They hallucinate under pressure",
        "â€¢ They lack guarantees around execution, safety, and consistency"
      ],
      "keyInsight": "The key insight: Don't scale context. Structure it."
    },
    "threeLayerArch": {
      "title": "2. The Three-Layer Architecture",
      "layers": [
        {
          "title": "ğŸ§± 1. Static Context â€” Rules (Always On)",
          "points": [
            "Mental model: Employee handbook",
            "Always loaded",
            "Defines identity, coding standards, behavioral constraints",
            "Prevents hallucinations and style drift",
            "Small, stable, human-editable"
          ]
        },
        {
          "title": "ğŸ› ï¸ 2. Dynamic Context â€” Skills (On Demand)",
          "points": [
            "Mental model: Toolbox",
            "Loaded only when needed",
            "Each skill is a self-contained capability",
            "Keeps the context window clean"
          ]
        },
        {
          "title": "âš“ 3. Deterministic Hooks â€” Guardrails",
          "points": [
            "Mental model: Security + Compliance layer",
            "Not probabilistic",
            "Runs before / after LLM reasoning",
            "Enforces rules that must never fail"
          ]
        }
      ]
    },
    "projectStructure": {
      "title": "3. Recommended Project Structure",
      "structure": "my-task-agent/\nâ”œâ”€â”€ .cursorrules\nâ”œâ”€â”€ main.py\nâ”œâ”€â”€ tools/\nâ”‚   â””â”€â”€ linear_mcp.py\nâ””â”€â”€ README.md"
    },
    "staticContextExample": {
      "title": "4. Static Context Example: .cursorrules",
      "content": "# ROLE\nYou are a Senior Python Engineer focused on production-grade systems.\n\n# RULES\n- NEVER use print() for debugging\n- ALWAYS type-hint functions\n- Propose a plan if touching >3 files\n\n# BEHAVIOR\n- Be concise\n- Ask clarifying questions if needed\n\nReference: https://github.com/PatrickJS/awesome-cursorrules"
    },
    "dynamicSkillExample": {
      "title": "5. Dynamic Skill Example (MCP)",
      "content": "from mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"DevTools\")\n\n@mcp.tool()\ndef create_linear_ticket(title: str, priority: str = \"low\") -> str:\n    ticket_id = f\"LIN-{hash(title) % 10000}\"\n    return f\"Created ticket {ticket_id} with priority={priority}\"\n\nif __name__ == \"__main__\":\n    mcp.run()\n\nReference: https://github.com/modelcontextprotocol/python-sdk"
    },
    "deterministicHookExample": {
      "title": "6. Deterministic Hook Example",
      "content": "def compliance_check_hook(state):\n    user_input = state[\"messages\"][-1].content.lower()\n    if \"password\" in user_input or \"api_key\" in user_input:\n        return {\"error\": \"Security violation detected\"}\n    return agent_node(state)\n\nReference: https://langchain-ai.github.io/langgraph/"
    },
    "finalThought": "If your agent only answers questions, it's a chatbot. If it reliably executes work, it's a Task Agent.",
    "taskAgentImageAlt": "Illustration of a task agent system architecture showing the interaction between different components"
  },
  "ageAi": {
    "heading": "Data Science in the Age of AI: Is the \"Sexiest Job\" Still Sexy?",
    "intro1": "\"It was the best of times, it was the worst of times.\"",
    "intro2": "A decade ago, Harvard Business Review called Data Scientist the \"sexiest job of the 21st century.\" Today, the landscape is shifting beneath our feet. While the demand for data talent remains high, the rise of Generative AI is fundamentally changing what it means to be a 'Data Scientist.'",
    "realityCheck": {
      "title": "The Reality Check",
      "content": "Traditional domains like Search, Ads, and Recommendation (SAR) are maturing, and the industry is shifting its focus toward heavy-duty engineering and AI architecture. We are seeing a strange paradox.",
      "lowBarTrap": {
        "title": "The \"Low-Bar\" Trap",
        "content": "Master's students can now use GPT-4 to handle data cleaning, EDA, and visualization in seconds. However, without a solid foundation, they often lack the judgment to know when the AI is \"hallucinating\" or providing statistically flawed results."
      },
      "stakeholderShift": {
        "title": "Stakeholder Shift",
        "content": "When business partners can write their own prompts to get basic insights, many DS professionals feel \"under-stimulated,\" trapped in endless meetings and repetitive prompt engineering."
      }
    },
    "strategicPillars": {
      "title": "How to Stay Indispensable: Two Strategic Pillars",
      "intro": "To thrive in this era, we need to evolve from 'builders of models' to 'architects of value.' I see this happening in two dimensions:",
      "buildingTools": {
        "title": "Building the Tools (The Engineer/Architect Mindset)",
        "subtitle": "Don't just use the AI; improve it.",
        "points": [
          {
            "title": "Model Evaluation & Governance",
            "content": "As AI output becomes a commodity, the person who can define what a 'good' result looks like is the most valuable person in the room. Focus on specialized evaluation frameworks (like risk-weighting in Finance)."
          },
          {
            "title": "Domain Fine-Tuning",
            "content": "Mastering techniques like LoRA or RAG to inject specific business knowledge into LLMs."
          },
          {
            "title": "Automation",
            "content": "Lead internal initiatives like 'Virtual Analysts' or automated experimentation pipelines."
          }
        ]
      },
      "leveragingTools": {
        "title": "Leveraging the Tools (The Strategist Mindset)",
        "subtitle": "Use AI to 10x your output so you can focus on what humans do best.",
        "points": [
          {
            "title": "Domain Expertise",
            "content": "AI knows the 'how,' but you know the 'why.' Deep business understanding allows you to provide the right context that AI lacks."
          },
          {
            "title": "Critical Thinking & Experimentation",
            "content": "While AI can generate code, human DS skills are still core for hypothesis testing, causal inference, and interpreting 'messy' real-world data."
          },
          {
            "title": "Communication & Influence",
            "content": "The ability to translate complex data into a business story and build stakeholder trust is a 'soft' skill that has become a 'hard' requirement."
          }
        ]
      }
    },
    "bottomLine": {
      "title": "The Bottom Line",
      "content1": "AI hasn't killed Data Science; it has raised the floor. If your value was purely in writing SQL or tuning hyperparameters, the 'sexiness' is fading. But if you can bridge the gap between business problems and AI solutions, your value has never been higher.",
      "content2": "Personal experience is your edge. A LLM can mimic logic, but it doesn't have the years of 'battle scars' from failed deployments or the intuition built from navigating complex organizations."
    },
    "discussion": {
      "title": "Let's discuss:",
      "prompt": "Are you feeling more 'efficient' or 'replaced' in your current role? How are you evolving your toolkit this year?"
    },
    "hashtags": [
      "#DataScience",
      "#AI",
      "#MachineLearning",
      "#GenerativeAI",
      "#CareerDevelopment",
      "#TechTrends"
    ]
  }
}
