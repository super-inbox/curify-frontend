{
    "home": {
    "hero": {
      "title": "KI-gest√ºtzte Content-Erstellung der n√§chsten Stufe",
      "description": "Curify Studio entwickelt eine KI-native Plattform f√ºr Content-Erstellung, die Kreative und Organisationen dabei unterst√ºtzt, Sprach- und Formatbarrieren zu √ºberwinden. Wir erm√∂glichen authentische √úbersetzungen, die Ton, Stil und emotionale Tiefe bewahren ‚Äì und helfen so, Inhalte effektiv f√ºr ein globales Publikum zu skalieren. An der Schnittstelle von Medien, Bildung und Unterhaltung bieten wir Werkzeuge, um Inhalte nahtlos an internationale M√§rkte anzupassen."
    }
  },
  "coreFeatures": {
  "oneShot": {
    "title": "Ein-Klick-√úbersetzung",
    "desc": "Komplette Video√ºbersetzung mit Voice-over, Untertiteln und Lippen-Synchronisation in einem Schritt."
  },
  "toneColor": {
    "title": "Stimmfarbenerhaltung",
    "desc": "Erh√§lt die einzigartigen Stimmmerkmale und Tonqualit√§ten des urspr√ºnglichen Sprechers."
  },
  "emotional": {
    "title": "Emotionale Sprache",
    "desc": "KI reproduziert emotionale Nuancen und sorgt f√ºr authentischen Ausdruck √ºber Sprachgrenzen hinweg."
  },
  "lipSync": {
    "title": "Lippen-Synchronisation",
    "desc": "Fortschrittliche Lippen-Synchronisierung, die Mundbewegungen perfekt mit der √ºbersetzten Tonspur abgleicht."
  },
  "subtitle": {
    "title": "Untertitelgenerator",
    "desc": "Intelligente Untertitelerstellung mit pr√§zisem Timing und nat√ºrlichem Sprachfluss."
  },
  "languages": {
    "title": "170+ Sprachen",
    "desc": "√úbersetzen Sie Ihre Inhalte in √ºber 170 Sprachen mit nahezu muttersprachlicher Genauigkeit."
  }
},
 "upcoming": {
    "title": "Demn√§chst verf√ºgbar",
    "subtitle": "N√§chste Generation von Funktionen in Entwicklung",
    "styleTransfer": {
      "title": "Stil√ºbertragung",
      "desc": "Wende filmische oder markenspezifische Stile auf deine Videos an ‚Äì mit KI-gest√ºtzter visueller Transformation."
    },
    "mangaTranslation": {
      "title": "Manga-√úbersetzung",
      "desc": "Automatische √úbersetzung von Manga und Comics mit Texterkennung, Blasenbearbeitung und kultureller Anpassung."
    },
    "templatedVideo": {
      "title": "Vorlagenbasierte Videogenerierung",
      "desc": "Erstelle professionelle Videos aus Vorlagen mit KI-generierten Inhalten und Markenanpassung."
    },
    "statusQ3": "Kommt im Q3 2025",
    "statusQ4": "Kommt im Q4 2025"
  },
  "export": {
    "title": "Export",
    "export": "Export",
    "downloading": "Downloading..."
  },
  "delete": {
    "title": "Double Confirm",
    "message": "Are you sure you want to delete this project",
    "warning": "This action cannot be undone.",
    "cancel": "Cancel",
    "delete": "Delete",
    "deleting": "Deleting..."
  },
  "userMenu": {
    "topUpCredits": "Top Up Credits",
    "remaining": "Remaining",
    "planRemaining": "Plan Remaining", 
    "validUntil": "Valid until",
    "creditsHistory": "Credits History",
    "subscribePlan": "Subscribe Plan",
    "supportTicket": "Support Ticket",
    "signOut": "Sign Out"
  },
  "technology": {
    "multimodal": {
      "title": "Multimodale Erkennung",
      "desc": "Wir kombinieren Sprach- und Untertitelsignale, um genauere und robustere Transkriptionen zu erzielen. Diese Zwei-Kanal-Erkennung reduziert Fehler und sorgt f√ºr bessere √úbereinstimmung mit dem Originalinhalt ‚Äì insbesondere in lauten oder komplexen Audioszenen."
    },
    "emotional": {
      "title": "Emotionale Sprachsynthese",
      "desc": "Unsere Sprachsynthese-Modelle erzeugen ausdrucksstarke, emotional nuancierte Sprache, die das Storytelling verbessert und das Publikum st√§rker einbindet. Durch die Erfassung von Tonfall, Rhythmus und Nuancen wirken AI-Stimmen menschlicher."
    },
    "lengthaware": {
      "title": "L√§ngenbewusste √úbersetzung und Anpassung",
      "desc": "Wir optimieren √úbersetzungen nicht nur auf Genauigkeit, sondern auch auf Timing und Tempo ‚Äì entscheidend f√ºr die Synchronisation von Video und Sprache. Nutzer k√∂nnen Tonfall, L√§nge und Formulierungen an unterschiedliche Inhalte und Zielgruppen anpassen."
    },
    "controlled": {
      "title": "Kontrollierte Videogenerierung",
      "desc": "Wir erm√∂glichen strukturierte, vorlagenbasierte Videogenerierung mit steuerbaren visuellen Elementen und √úberg√§ngen. So erhalten Kreative kreative Freiheit und gleichzeitige Produktionskonsistenz ‚Äì mit weniger manueller Arbeit und hoher Qualit√§t."
    }
  },
  "tools": {
    "video_dubbing": {
      "title": "Video-Synchronisation",
      "desc": "√úbersetze dein Video in jede Sprache mit pr√§ziser Lokalisierung und Sprachsynchronisation"
    },
    "subtitle_captioner": {
      "title": "Untertitel-Generator",
      "desc": "Erstelle automatisch mehrsprachige Untertitel zur Verbesserung von Klarheit und Zug√§nglichkeit"
    },
    "lip_syncing": {
      "title": "Lippensynchronisation",
      "desc": "Perfekte Lippensynchronit√§t dank KI-gest√ºtzter Technik"
    },
    "style_transfer": {
      "title": "Stil√ºbertragung",
      "desc": "Verwandle dein Video in Pixar-, Ghibli- oder andere k√ºnstlerische Stile ‚Äì bald verf√ºgbar"
    },
    "coming_soon": "Bald verf√ºgbar",
    "create": "Erstellen"
  },
  "bilingual": {
  "title": "Zweisprachige Untertitel leicht gemacht",
  "intro": "Erstelle automatisch Untertitel in zwei Sprachen mit Curifys KI‚ÄëUntertitel‚ÄëEngine. Ideal f√ºr Creator, Lehrkr√§fte und internationale Unternehmen.",
  "example": "Beispiel: Jensen Huang erkl√§rt die KI‚ÄëStrategie ‚Äî automatisch erstellte englische und chinesische Untertitel.",
  "cta": "Jetzt kostenlos ausprobieren",
  "why": {
    "title": "Warum Curify f√ºr zweisprachige Untertitel?",
    "point1": "Unterst√ºtzt √ºber 170 Sprachen mit pr√§ziser √úbersetzung.",
    "point2": "Bewahrt Emotion, Ton und Timing.",
    "point3": "Perfekt f√ºr YouTube, TikTok und Lehrvideos.",
    "point4": "Exportiere fertige Untertiteldateien oder eingebettete Videos."
  },
  "faq": {
    "title": "H√§ufige Fragen",
    "q1": "Ist es wirklich kostenlos?",
    "a1": "Ja, Curify bietet einen kostenlosen Plan mit monatlich begrenzten Untertitelminuten.",
    "q2": "Kann ich die Untertitel nachtr√§glich bearbeiten?",
    "a2": "Nat√ºrlich. Du kannst Timing, √úbersetzung und Stil anpassen, bevor du exportierst."
  }
},
"videoDubbing": {
  "title": "KI-Video-Synchronisation mit nat√ºrlicher Stimme",
  "description": "√úbersetzen und synchronisieren Sie Ihre Videoinhalte in √ºber 170 Sprachen mit realistischer KI-Stimme und Lippensynchronisation. Perfekt f√ºr internationale Ersteller und Marken."
},
"pricing": {
  "header": {
    "title": "Erste Schritte mit einem Plan",
    "subtitle": "W√§hlen Sie einen Plan, der Ihren Bed√ºrfnissen entspricht."
  },
  "common": {
    "month": "Monat",
    "pricing": "Preisgestaltung",
    "receive": "Erhalten"
  },
  "buttons": {
    "signUp": "Registrieren",
    "subscribePlan": "Plan abonnieren",
    "currentPlan": "Aktueller Plan",
    "comingSoon": "Demn√§chst verf√ºgbar",
    "downgradeToFree": "Auf Kostenlos herabstufen",
    "downgradeToCreator": "Auf Creator herabstufen",
    "contactSales": "Vertrieb kontaktieren"
  },
  "plans": {
    "free": {
      "name": "Kostenlos",
      "description": "Ideal zum Testen von Tools und f√ºr leichte Arbeiten",
      "features": [
        "Videos ohne Wasserzeichen herunterladen",
        "1 Stunde kostenlose Untertitelverarbeitung",
        "SRT-Dateien exportieren"
      ]
    },
    "creator": {
      "name": "Creator",
      "description": "Ideal f√ºr kleine Creators mit regelm√§√üiger Untertitelung und leichter Synchronisation",
      "plusTitle": "Alles in Kostenlos, plus:",
      "features": [
        "Lippensynchronisation",
        "Stapelverarbeitung",
        "5 Stunden kostenlose Untertitelverarbeitung",
        "Bis zu 30 Minuten pro Aufgabe"
      ]
    },
    "pro": {
      "name": "Pro",
      "description": "Demn√§chst verf√ºgbar ‚Äî Entwickelt f√ºr Creators mit hohem Volumen",
      "plusTitle": "Alles in Creator, plus:",
      "features": [
        "Stimmversch√∂nerung & Rauschunterdr√ºckung",
        "Priorit√§tswarteschlange",
        "Bis zu 60 Min. pro Aufgabe",
        "Unbegrenzte Untertitelminuten"
      ]
    },
    "enterprise": {
      "name": "Enterprise",
      "description": "F√ºr Teams, Studios und Unternehmens-Workflows",
      "customPricing": "Individuell",
      "unlimited": "Unbegrenzt üêö",
      "tailoredSupport": "& ma√ügeschneiderter Support",
      "plusTitle": "Alles in Pro, plus:",
      "features": [
        "Dedizierter Account-Manager",
        "On-Premise-Bereitstellungsoptionen",
        "API-Zugriff & Nutzungsanalyse",
        "Individuelle Integrationen & SLA",
        "Unbegrenzte Verarbeitungsstunden"
      ]
    }
  },
  "table": {
    "header": {
      "feature": "Funktion / Limit"
    },
    "rows": {
      "videoDownloadWithWatermark": "Video-Download mit Wasserzeichen",
      "videoDownloadWithoutWatermark": "Video-Download ohne Wasserzeichen",
      "downloadSrt": "SRT-Datei herunterladen",
      "voiceBeautification": "Stimmversch√∂nerung & Rauschunterdr√ºckung",
      "lipSync": "Lippensynchronisation",
      "subtitleTools": "Untertitel-Tools (hinzuf√ºgen/entfernen, keine √úbersetzung)",
      "batchProcessing": "Stapelverarbeitung",
      "maxVideoLength": "Max. Videol√§nge pro Aufgabe",
      "monthlyCredits": "Monatliche kostenlose Credits",
      "priorityQueue": "Priorit√§tswarteschlange / Schnellere Verarbeitung",
      "creditTopUp": "Credit-Aufladung"
    },
    "values": {
      "free": "Kostenlos",
      "unlimited": "Unbegrenzt",
      "oneHourPerMonth": "1 Std./Monat",
      "fiveHoursPerMonth": "5 Std./Monat",
      "fiveMinutes": "5 Min.",
      "thirtyMinutes": "30 Min.",
      "sixtyMinutes": "60 Min."
    }
  }
},
"aeVsComfyUi": {
  "title": "AE vs ComfyUI ‚Äì Animation neu definiert (Teil 3)",
  "heading": "üé® AE vs ComfyUI",
  "intro1": "Wir werden oft gefragt: Warum nicht einfach After Effects (AE) verwenden? Oder warum ComfyUI? Beide sind wichtig ‚Äî AE bietet pr√§zise Kontrolle, ComfyUI erm√∂glicht generative Kreativit√§t.",
  "intro2": "AE bietet zeitbasierte Pr√§zision sowie Kontrolle √ºber √úberg√§nge, Licht und Effekte. ComfyUI bringt AI-native Workflows, die Diffusion, Text und multimodale Orchestrierung kombinieren.",
  "table": {
    "colAE": "AE",
    "colComfy": "ComfyUI",
    "row1a": "Pr√§zise VFX- und Bewegungssteuerung",
    "row1b": "AI-native Videogenerierung",
    "row2a": "Timeline-basiertes Editing",
    "row2b": "Workflow-/Node-basiertes Rendering",
    "row3a": "Manueller oder pluginbasierter Workflow",
    "row3b": "Diffusion + LLM + multimodale Orchestrierung"
  },
  "outro": "In unserem Workflow √ºbernimmt ComfyUI die AI-Generierung und Iteration, w√§hrend AE den finalen Look verfeinert ‚Äî √úberg√§nge, Overlays und Compositing."
},
"video_translation_eval": {
  "title": "Bewertung von KI-gest√ºtzter Video√ºbersetzung",
  "subtitle": "Relevante Qualit√§tsmetriken",
  "intro": "Die √úbersetzung von Videos √ºber Sprachgrenzen hinweg erfordert mehr als nur Worte ‚Äì sie umfasst Transkription, √úbersetzung, Sprachsynthese, Timing und mehr. Curify nutzt ein strukturiertes Bewertungssystem, um h√∂chste Qualit√§t sicherzustellen.",
  "section1_title": "1. Transkriptionsqualit√§t",
  "section1_engine": "Engine: WhisperX",
  "section1_metrics": ["Wortfehlerrate (WER)", "Interpunktions-F1 (f√ºr Lesbarkeit und Ausdruck)"],
  "section2_title": "2. √úbersetzungsqualit√§t",
  "section2_engine": "Engines: Helsinki, MarianMT",
  "section2_metrics": ["BLEU (Standard-Metrik)", "COMET / chrF++ (semantische √Ñhnlichkeit)", "Manuelle Bewertung: Lesbarkeit & Genauigkeit"],
  "section3_title": "3. Sprachsynthesequalit√§t",
  "section3_engine": "Engines: XTTS / YourTTS",
  "section3_metrics": ["MOS-Bewertung: Nat√ºrlichkeit, √Ñhnlichkeit, Ausdruck", "Genauigkeit der Sprechererkennung"],
  "section4_title": "4. Timing & Lippensynchronisation",
  "section4_metrics": ["Unterschiede in Segmentdauer", "Wav2Lip-Synchronwert", "Zeitliche Abweichung"],
  "section5_title": "5. Semantische Erhaltung",
  "section5_method": "Wir verwenden gro√üe Sprachmodelle (wie GPT-4), um zu pr√ºfen, ob Tonfall, Emotion und Bedeutung erhalten bleiben. Beispiel-Prompt:",
  "section5_prompt": "Vergleiche das chinesische Transkript mit der englischen Sprachversion. Stimmen Ton, Absicht und Inhalt √ºberein? Bewerte mit 1‚Äì5 und begr√ºnde.",
  "section6_title": "6. Nutzerfeedback & GTM-Validierung",
  "section6_metrics": ["Stimmqualit√§t passend zum Produkttyp", "Erh√∂hte Zuschauerbindung bei lokalisierten Videos", "Nutzerbereitschaft zur Tool-Nutzung"],
  "closing": "Bei Curify geht es um mehr als √úbersetzung ‚Äî wir bewahren Geschichte, Emotion und Klarheit. M√∂chtest du deine Inhalte weltweit verbreiten? Melde dich bei uns.",
  "available_locales": "Verf√ºgbar in: [EN] [ZH] [ES] [DE]"
},
  "storyboardToPipeline": {
  "title": "Von Storyboards zu KI-Pipelines: Animation neu definieren (Teil 1)",
  "intro": {
    "p1": "Die meisten Leute denken, KI-Video bedeutet ‚ÄûText rein, Clip raus‚Äú. Aber wenn du filmisches, regisseur√§hnliches Kontrollniveau erreichen willst, ist das ein ganz anderes Spiel.",
    "p2": "In der traditionellen Animation z√§hlt jedes Detail ‚Äî Charakterdesign, Bewegungsfluss, Timing und Szenen√ºberg√§nge. Unser Ziel ist es, dass KI dieses Pr√§zisionsniveau erreicht.",
    "p3": "Heutige Animation ist sowohl Kunst als auch eine strukturierte Orchestrierungsaufgabe. Wir denken wie Regisseure, bauen aber wie Ingenieure.",
    "p4": "Deshalb entwickeln wir <strong>Kontrollierte Generierungspipelines</strong> anstelle von Ein-Klick-Generierung. Diese Pipelines verbinden Struktur und Kreativit√§t:",
    "pipelineItems": [
      "Storyboard-zu-Video: JSON-basierte Szenenspezifikationen mit IDs, Timing und Kamerametadaten",
      "ComfyUI-basierte Workflows: Knotengraph-DAGs mit versionierten Checkpoints, LoRA-Stacks und Seeds",
      "Zeitliche und multimodale Steuerung: Gemeinsame Szenen-IDs √ºber Bilder, Bewegung, Audio und Untertitel"
    ],
    "p5": "Jetzt schauen wir uns ein einfaches Beispiel an, um zu zeigen, wie KI-Pipelines in der Praxis funktionieren.",
    "technicalNotes": [
      "Alle Stufen lesen/schreiben typisierte Artefakte (JSON/CSV, PNG-Sequenzen, WAV/MP3, MP4, .aep)",
      "Pipelines werden √ºber Python/CLI orchestriert (z.B. ComfyUI-API, ffmpeg, TTS-APIs)",
      "Jeder Durchlauf ist durch gespeicherte Konfiguration reproduzierbar (Modell, Sampler, Seed, Prompts, Dauer)"
    ]
  },
  "pipeline": {
    "title": "KI-Videogenerierungspipeline",
    "description": "Die KI-Videogenerierungspipeline wandelt Textanweisungen durch strukturierte Stufen in fertige Videos um, mit expliziten Ein- und Ausgaben sowie Konfigurationen.",
    "prompt": "1. Prompt (rohe Idee ‚Üí strukturierte JSON-Spezifikation)",
    "storyboard": "2. Storyboard (Szenen-/Einstellungstabelle mit Timing, Kamera und Beschreibung)",
    "images": "3. Bilder (pro Einstellung generierte Keyframes via Stable Diffusion/ComfyUI)",
    "animation": "4. Animation (Bildsequenzen ‚Üí Bewegung, Parallaxe und Effekte)",
    "voiceOver": "5. Sprachausgabe (TTS + Synchronisationsdaten)",
    "finalVideo": "6. Endg√ºltiges Video (ffmpeg-Komposition: Video + Audio + Untertitel)",
    "features": [
      "JSON-zuerst-Design: Jede Szene ist adressierbar und skriptierbar (scene_id, shot_id)",
      "ComfyUI-basierte Workflows: Modulare, reproduzierbare, komponierbare DAGs f√ºr Bild-/Videogenerierung",
      "Zeitliche und multimodale Steuerung: Konsistente Seeds, Charakter-Embeddings und Timing √ºber alle Modalit√§ten hinweg"
    ],
    "exampleIntro": "Jetzt schauen wir uns ein einfaches Beispiel an, um zu zeigen, wie KI-Pipelines in der Praxis funktionieren.",
    "artifacts": {
      "promptSpec": "prompt_run_001.json",
      "storyboardTable": "storyboard_v1.csv",
      "imageOutputDir": "renders/szene_{scene_id}/einstellung_{shot_id}/frame_####.png",
      "audioOutput": "audio/sprachausgabe_final.wav",
      "subtitleFile": "untertitel/storyboard_v1.srt",
      "finalVideoFile": "exports/storyboard_v1_final.mp4"
    }
  },
  "steps": {
    "step1": {
      "title": "Schritt 1: Beginne mit einem einfachen Prompt",
      "example": "Ein M√§dchen steht an einem Mitternachtsbahnhof, der Wind weht durch ihr Haar.",
      "expandedPrompt": "Mit Hilfe von GPT oder einer lokalen LLM erweitern wir dies zu einem strukturierten JSON-Objekt mit globalem Stil, Charakterdefinitionen und Szenenaufschl√ºsselung.",
      "technicalDetails": {
        "llmFields": [
          "global_style: Kunststil, Kamerasprache, Farbpalette",
          "characters: Name, Alter, Aussehen, Outfit, emotionaler Zustand",
          "szenen: [{ scene_id, shot_id, beschreibung, kameratyp, dauer_sekunden }]"
        ],
        "outputFile": "prompt_run_001.json",
        "exampleStack": "Python-Skript, das die OpenAI/LLM-API aufruft und JSON auf die Festplatte schreibt"
      }
    },
    "step2": {
      "title": "Schritt 2: Konvertiere den Prompt in eine Storyboard-Tabelle",
      "description": "Die JSON-Spezifikation wird in eine Storyboard-Tabelle (CSV oder Notion) umgewandelt, die sowohl f√ºr Menschen als auch f√ºr die Pipeline lesbar ist.",
      "technicalDetails": {
        "columns": [
          "scene_id", "shot_id", "startzeit", "endzeit", "dauer_sekunden",
          "kameratyp", "visuelle_beschreibung", "charakter_zustand", "bewegungshinweise"
        ],
        "storage": "storyboard_v1.csv (wird als einzige Wahrheitsquelle f√ºr nachfolgende Schritte verwendet)",
        "automation": "Python/Node.js-Skript transformiert prompt_run_001.json ‚Üí storyboard_v1.csv"
      }
    },
    "step3": {
      "title": "Schritt 3: Generiere die Bilder",
      "points": [
        "üé® Verwende <strong>Stable Diffusion</strong> oder <strong>ComfyUI</strong>, um jede Szenenbeschreibung in ein hochaufl√∂sendes Bild zu verwandeln.",
        "Halte den Stil konsistent, indem du dasselbe LoRA-Modell, denselben Kunststil und denselben Seed verwendest."
      ],
      "technicalDetails": {
        "modelConfig": {
          "checkpoint": "sd_xl_base_1.0.safetensors",
          "vae": "sdxl_vae.safetensors",
          "sampler": "euler_a",
          "steps": 25,
          "cfgScale": 6.5,
          "resolution": "1024x576",
          "loraStack": [
            "character_girl_v2.safetensors",
            "style_cinematic_blue_hour.safetensors"
          ]
        },
        "consistency": {
          "seedStrategy": "fixed_per_scene",
          "seedExample": "seed = hash(scene_id + charakter_name)",
          "namingConvention": "renders/szene_{scene_id}/einstellung_{shot_id}/kf_0001.png"
        }
      }
    },
    "step4": {
      "title": "Schritt 4: F√ºge Bewegung und Atmosph√§re in After Effects hinzu",
      "points": [
        "Importiere die Bilder in <strong>Adobe After Effects</strong>",
        "Wende Keyframe-Animationen an: Schwenks, Zooms, Nebeleffekte, Leuchteffekte",
        "F√ºge Umgebungsger√§usche oder filmische √úberg√§nge hinzu"
      ],
      "technicalDetails": {
        "input": "renders/szene_{scene_id}/einstellung_{shot_id}/kf_0001.png (plus optionale Tiefen-/Alphakan√§le)",
        "projectFile": "ae/storyboard_v1.aep",
        "automation": [
          "Verwende AE-Skripte/ExtendScript oder JSX, um automatisch Kompositionen pro scene_id zu erstellen",
          "Mappe `dauer_sekunden` aus storyboard_v1.csv ‚Üí Kompositionsdauer",
          "Generiere bei Bedarf Zwischenbilder √ºber AE-Plugins oder videobewusste Diffusionstools"
        ],
        "output": "ae_renders/szene_{scene_id}_einstellung_{shot_id}_anim.mp4"
      }
    },
    "step5": {
      "title": "Schritt 5: F√ºge Stimme und Untertitel hinzu",
      "points": [
        "Verwende <strong>XTTS</strong> oder <strong>ElevenLabs</strong> f√ºr nat√ºrliche Sprachausgaben",
        "F√ºr Abk√ºrzungen (wie API, NBA) generiere englische Ausschnitte separat und f√ºge sie sp√§ter ein",
        "F√ºge Untertitel mit `.srt`- oder `.json`-Dateien hinzu, die mit der Stimme synchronisiert sind"
      ],
      "technicalDetails": {
        "scriptSource": "Dialog und Erz√§hlung aus prompt_run_001.json + storyboard_v1.csv",
        "ttsConfig": {
          "engine": "XTTS oder ElevenLabs",
          "voiceId": "cinematic_female_de",
          "sampleRate": 44100,
          "format": "wav"
        },
        "outputs": {
          "voiceFile": "audio/storyboard_v1_sprachausgabe.wav",
          "subtitleFile": "untertitel/storyboard_v1.srt"
        },
        "syncStrategy": "Synchronisiere `startzeit`/`endzeit` aus storyboard_v1.csv mit Untertitelmarken; stelle sicher, dass die Gesamtaudiodauer ‚âà der endg√ºltigen Zeitleistendauer entspricht"
      }
    },
    "step6": {
      "title": "Schritt 6: Finale Komposition mit FFMPEG",
      "description": "Verwende FFMPEG, um alle Teile zu einem Video zusammenzuf√ºgen:",
      "technicalDetails": {
        "inputs": {
          "video": "ae_renders/storyboard_v1_timeline.mp4",
          "audio": "audio/storyboard_v1_sprachausgabe.wav",
          "subtitles": "untertitel/storyboard_v1.srt"
        },
        "ffmpegExample": "ffmpeg -i storyboard_v1_timeline.mp4 -i storyboard_v1_sprachausgabe.wav -c:v libx264 -c:a aac -shortest -vf subtitles=untertitel/storyboard_v1.srt exports/storyboard_v1_final.mp4",
        "output": "exports/storyboard_v1_final.mp4 (H.264, 24 fps, AAC-Audio)"
      }
    }
  },
  "whatYouNeed": "üìÅ Was du brauchst",
  "whatYouNeedTechnical": [
    "GPU mit mindestens 12 GB VRAM f√ºr Stable Diffusion / ComfyUI",
    "Python-Umgebung f√ºr JSON/CSV-Transformationen und Automatisierungsskripte",
    "ComfyUI mit den erforderlichen benutzerdefinierten Nodes und Workflows installiert",
    "Adobe After Effects oder ein √§hnliches Compositing-Programm f√ºr Bewegung und Effekte",
    "XTTS / ElevenLabs API-Zugang f√ºr die Sprachsynthese",
    "ffmpeg installiert und √ºber die Kommandozeile verf√ºgbar"
  ],
  "cta": "üöÄ Bereit, dein Storyboard mit KI zum Leben zu erwecken?<br /><strong>Wir stellen dir ein umfassendes Starter-Kit</strong> mit Beispielen, Vorlagen und Tools zur Verf√ºgung, um direkt loszulegen."
},

"SceneDetection": {
  "tags": {
    "computerVision": "Computer Vision",
    "deepLearning": "Deep Learning",
    "realTimeAnalysis": "Echtzeit-Analyse"
  },
  "hero": {
    "title": "Videos in Storyboards mit KI umwandeln",
    "subtitle": "Wie wir eine fortschrittliche Pipeline entwickelt haben, die stundenlanges Filmmaterial in Minuten in strukturierte, durchsuchbare Storyboards verwandelt."
  },
  "introduction": {
    "paragraph1": "Stell dir vor, du l√§dst stundenlanges Rohmaterial hoch und erh√§ltst innerhalb von Minuten eine <strong>detaillierte, szene-f√ºr-Szene-Aufschl√ºsselung</strong> deines gesamten Videos. Genau das bietet unser KI-gest√ºtztes Szenenerkennungssystem.",
    "paragraph2": "Diese mit modernsten Python-Bibliotheken und Deep-Learning-Modellen erstellte Pipeline erkennt nicht nur Szenenwechsel ‚Äì sie versteht den Inhalt, identifiziert Schl√ºsselelemente und strukturiert alles zu einem umfassenden Storyboard."
  },
  "imageAlt": "Die Szenenerkennungs-Pipeline in Aktion, die Schl√ºsselmomente identifiziert und strukturierte Storyboards erzeugt",
  "protip": "F√ºr optimale Ergebnisse sollte dein Video klare visuelle Trennungen zwischen den Szenen aufweisen. Das System funktioniert am besten mit gut ausgeleuchteten Aufnahmen und minimaler Bewegungsunsch√§rfe. Erw√§ge, in deinem Videoschnittprogramm Kapitelmarken oder Szenenwechsel hinzuzuf√ºgen, um die Erkennungsgenauigkeit zu verbessern."
}
}